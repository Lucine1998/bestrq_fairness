2023-12-01 11:43:13,417 - speechbrain.core - INFO - Beginning experiment!
2023-12-01 11:43:13,417 - speechbrain.core - INFO - Experiment folder: results/best_hyperbranchconformer/2000
2023-12-01 11:43:17,109 - speechbrain.utils.superpowers - DEBUG - appdirs==1.4.4
attrs==23.1.0
black==19.10b0
certifi==2023.11.17
cfgv==3.4.0
charset-normalizer==3.3.2
click==8.0.4
cmake==3.27.7
distlib==0.3.7
entrypoints==0.3
filelock==3.13.1
flake8==3.7.9
fsspec==2023.10.0
huggingface-hub==0.19.4
HyperPyYAML==1.2.2
identify==2.5.32
idna==3.6
iniconfig==2.0.0
Jinja2==3.1.2
joblib==1.3.2
lit==17.0.6
MarkupSafe==2.1.3
mccabe==0.6.1
mpmath==1.3.0
networkx==3.2.1
nodeenv==1.8.0
numpy==1.26.2
nvidia-cublas-cu11==11.10.3.66
nvidia-cublas-cu12==12.1.3.1
nvidia-cuda-cupti-cu11==11.7.101
nvidia-cuda-cupti-cu12==12.1.105
nvidia-cuda-nvrtc-cu11==11.7.99
nvidia-cuda-nvrtc-cu12==12.1.105
nvidia-cuda-runtime-cu11==11.7.99
nvidia-cuda-runtime-cu12==12.1.105
nvidia-cudnn-cu11==8.5.0.96
nvidia-cudnn-cu12==8.9.2.26
nvidia-cufft-cu11==10.9.0.58
nvidia-cufft-cu12==11.0.2.54
nvidia-curand-cu11==10.2.10.91
nvidia-curand-cu12==10.3.2.106
nvidia-cusolver-cu11==11.4.0.1
nvidia-cusolver-cu12==11.4.5.107
nvidia-cusparse-cu11==11.7.4.91
nvidia-cusparse-cu12==12.1.0.106
nvidia-nccl-cu11==2.14.3
nvidia-nccl-cu12==2.18.1
nvidia-nvjitlink-cu12==12.3.101
nvidia-nvtx-cu11==11.7.91
nvidia-nvtx-cu12==12.1.105
packaging==23.2
pandas==2.1.3
pathspec==0.11.2
platformdirs==4.0.0
pluggy==1.3.0
pre-commit==3.5.0
pycodestyle==2.5.0
pyflakes==2.1.1
pytest==7.4.0
python-dateutil==2.8.2
pytz==2023.3.post1
PyYAML==6.0.1
regex==2023.10.3
requests==2.31.0
ruamel.yaml==0.18.5
ruamel.yaml.clib==0.2.8
safetensors==0.4.1
scipy==1.11.4
sentencepiece==0.1.99
six==1.16.0
-e /gpfsdswork/projects/rech/nkp/uaj64gk/bestrqexp/speechbrain
sympy==1.12
tokenizers==0.15.0
toml==0.10.2
torch==2.0.1
torchaudio==2.0.2
tqdm==4.66.1
transformers==4.35.2
triton==2.0.0
typed-ast==1.5.5
typing_extensions==4.8.0
tzdata==2023.3
urllib3==2.1.0
virtualenv==20.24.7
yamllint==1.23.0

ERROR: Error [Errno 2] No such file or directory: 'git' while executing command git config --get-regexp 'remote\..*\.url'
WARNING: cannot determine version of editable source in /gpfsdswork/projects/rech/nkp/uaj64gk/bestrqexp/speechbrain (git command not found in path)

2023-12-01 11:43:21,768 - speechbrain.dataio.sampler - INFO - Batch quantisation in latent space
2023-12-01 11:43:21,768 - speechbrain.dataio.sampler - DEBUG - Latent bucket boundary - buckets: ['1.62', '2.19', '2.66', '3.09', '3.49', '3.88', '4.27', '4.65', '5.02', '5.41', '5.79', '6.18', '6.58', '6.99', '7.40', '7.83', '8.27', '8.72', '9.19', '9.68', '10.18', '10.70', '11.25', '11.82', '12.41', '13.04', '13.70', '14.39', '15.12', '15.90', '16.73', '17.61', '18.55', '19.57', '20.67', '21.86', '23.16', '24.59', '26.17', '27.94', '29.93', '32.21', '34.84', '37.94', '41.68', '46.34', '52.40', '60.82', '73.93', '100.00'] - length multipliers: ['1.35', '1.22', '1.16', '1.13', '1.11', '1.10', '1.09', '1.08', '1.08', '1.07', '1.07', '1.06', '1.06', '1.06', '1.06', '1.06', '1.05', '1.05', '1.05', '1.05', '1.05', '1.05', '1.05', '1.05', '1.05', '1.05', '1.05', '1.05', '1.05', '1.05', '1.05', '1.05', '1.05', '1.06', '1.06', '1.06', '1.06', '1.06', '1.07', '1.07', '1.08', '1.08', '1.09', '1.10', '1.11', '1.13', '1.16', '1.22', '1.35']
2023-12-01 11:43:21,769 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-01 11:43:22,474 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 0 with boundary 0.0-1.6 and batch_size 61: Num Examples 0.0, Num Full Batches 0.000, Pad Factor 0.000.
2023-12-01 11:43:22,474 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 1 with boundary 1.6-2.2 and batch_size 45: Num Examples 906.0, Num Full Batches 19.000, Pad Factor 8.810.
2023-12-01 11:43:22,474 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 2 with boundary 2.2-2.7 and batch_size 37: Num Examples 3456.0, Num Full Batches 84.000, Pad Factor 19.315.
2023-12-01 11:43:22,477 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 3 with boundary 2.7-3.1 and batch_size 32: Num Examples 3364.0, Num Full Batches 96.000, Pad Factor 14.604.
2023-12-01 11:43:22,477 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 4 with boundary 3.1-3.5 and batch_size 28: Num Examples 3292.0, Num Full Batches 108.000, Pad Factor 12.168.
2023-12-01 11:43:22,477 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 5 with boundary 3.5-3.9 and batch_size 25: Num Examples 3156.0, Num Full Batches 116.000, Pad Factor 10.443.
2023-12-01 11:43:22,477 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 6 with boundary 3.9-4.3 and batch_size 23: Num Examples 3158.0, Num Full Batches 128.000, Pad Factor 9.328.
2023-12-01 11:43:22,477 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 7 with boundary 4.3-4.6 and batch_size 21: Num Examples 3035.0, Num Full Batches 135.000, Pad Factor 8.411.
2023-12-01 11:43:22,477 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 8 with boundary 4.6-5.0 and batch_size 19: Num Examples 3010.0, Num Full Batches 145.000, Pad Factor 7.650.
2023-12-01 11:43:22,477 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 9 with boundary 5.0-5.4 and batch_size 18: Num Examples 3119.0, Num Full Batches 162.000, Pad Factor 7.284.
2023-12-01 11:43:22,477 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 10 with boundary 5.4-5.8 and batch_size 17: Num Examples 3126.0, Num Full Batches 175.000, Pad Factor 6.786.
2023-12-01 11:43:22,477 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 11 with boundary 5.8-6.2 and batch_size 16: Num Examples 3051.0, Num Full Batches 182.000, Pad Factor 6.432.
2023-12-01 11:43:22,477 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 12 with boundary 6.2-6.6 and batch_size 15: Num Examples 3091.0, Num Full Batches 197.000, Pad Factor 6.192.
2023-12-01 11:43:22,477 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 13 with boundary 6.6-7.0 and batch_size 14: Num Examples 3048.0, Num Full Batches 206.000, Pad Factor 5.893.
2023-12-01 11:43:22,477 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 14 with boundary 7.0-7.4 and batch_size 13: Num Examples 3288.0, Num Full Batches 236.000, Pad Factor 5.700.
2023-12-01 11:43:22,477 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 15 with boundary 7.4-7.8 and batch_size 12: Num Examples 3300.0, Num Full Batches 251.000, Pad Factor 5.514.
2023-12-01 11:43:22,477 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 16 with boundary 7.8-8.3 and batch_size 12: Num Examples 3438.0, Num Full Batches 276.000, Pad Factor 5.406.
2023-12-01 11:43:22,477 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 17 with boundary 8.3-8.7 and batch_size 11: Num Examples 3599.0, Num Full Batches 305.000, Pad Factor 5.299.
2023-12-01 11:43:22,477 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 18 with boundary 8.7-9.2 and batch_size 10: Num Examples 3901.0, Num Full Batches 349.000, Pad Factor 5.189.
2023-12-01 11:43:22,477 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 19 with boundary 9.2-9.7 and batch_size 10: Num Examples 4113.0, Num Full Batches 388.000, Pad Factor 5.087.
2023-12-01 11:43:22,477 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 20 with boundary 9.7-10.2 and batch_size 9: Num Examples 4692.0, Num Full Batches 465.000, Pad Factor 4.987.
2023-12-01 11:43:22,477 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 21 with boundary 10.2-10.7 and batch_size 9: Num Examples 5324.0, Num Full Batches 556.000, Pad Factor 4.978.
2023-12-01 11:43:22,477 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 22 with boundary 10.7-11.2 and batch_size 8: Num Examples 6379.0, Num Full Batches 700.000, Pad Factor 4.917.
2023-12-01 11:43:22,477 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 23 with boundary 11.2-11.8 and batch_size 8: Num Examples 8176.0, Num Full Batches 943.000, Pad Factor 4.894.
2023-12-01 11:43:22,477 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 24 with boundary 11.8-12.4 and batch_size 8: Num Examples 11428.0, Num Full Batches 1386.000, Pad Factor 4.865.
2023-12-01 11:43:22,477 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 25 with boundary 12.4-13.0 and batch_size 7: Num Examples 16056.0, Num Full Batches 2045.000, Pad Factor 4.866.
2023-12-01 11:43:22,478 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 26 with boundary 13.0-13.7 and batch_size 7: Num Examples 23408.0, Num Full Batches 3133.000, Pad Factor 4.893.
2023-12-01 11:43:22,478 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 27 with boundary 13.7-14.4 and batch_size 6: Num Examples 33287.0, Num Full Batches 4679.000, Pad Factor 4.874.
2023-12-01 11:43:22,478 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 28 with boundary 14.4-15.1 and batch_size 6: Num Examples 43150.0, Num Full Batches 6370.000, Pad Factor 4.946.
2023-12-01 11:43:22,478 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 29 with boundary 15.1-15.9 and batch_size 6: Num Examples 46934.0, Num Full Batches 7275.000, Pad Factor 4.968.
2023-12-01 11:43:22,478 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 30 with boundary 15.9-16.7 and batch_size 5: Num Examples 18846.0, Num Full Batches 3051.000, Pad Factor 5.095.
2023-12-01 11:43:22,478 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 31 with boundary 16.7-17.6 and batch_size 5: Num Examples 2283.0, Num Full Batches 385.000, Pad Factor 5.001.
2023-12-01 11:43:22,478 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 32 with boundary 17.6-18.6 and batch_size 5: Num Examples 24.0, Num Full Batches 4.000, Pad Factor 4.747.
2023-12-01 11:43:22,478 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 33 with boundary 18.6-19.6 and batch_size 5: Num Examples 23.0, Num Full Batches 4.000, Pad Factor 4.870.
2023-12-01 11:43:22,478 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 34 with boundary 19.6-20.7 and batch_size 4: Num Examples 26.0, Num Full Batches 5.000, Pad Factor 5.180.
2023-12-01 11:43:22,478 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 35 with boundary 20.7-21.9 and batch_size 4: Num Examples 15.0, Num Full Batches 3.000, Pad Factor 4.735.
2023-12-01 11:43:22,478 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 36 with boundary 21.9-23.2 and batch_size 4: Num Examples 11.0, Num Full Batches 2.000, Pad Factor 4.155.
2023-12-01 11:43:22,478 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 37 with boundary 23.2-24.6 and batch_size 4: Num Examples 7.0, Num Full Batches 1.000, Pad Factor 4.739.
2023-12-01 11:43:22,478 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 38 with boundary 24.6-26.2 and batch_size 3: Num Examples 6.0, Num Full Batches 1.000, Pad Factor 4.438.
2023-12-01 11:43:22,478 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 39 with boundary 26.2-27.9 and batch_size 3: Num Examples 4.0, Num Full Batches 1.000, Pad Factor 6.346.
2023-12-01 11:43:22,478 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 40 with boundary 27.9-29.9 and batch_size 3: Num Examples 1.0, Num Full Batches 0.000, Pad Factor 0.000.
2023-12-01 11:43:22,478 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 41 with boundary 29.9-32.2 and batch_size 3: Num Examples 0.0, Num Full Batches 0.000, Pad Factor 0.000.
2023-12-01 11:43:22,478 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 42 with boundary 32.2-34.8 and batch_size 2: Num Examples 0.0, Num Full Batches 0.000, Pad Factor 0.000.
2023-12-01 11:43:22,478 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 43 with boundary 34.8-37.9 and batch_size 2: Num Examples 0.0, Num Full Batches 0.000, Pad Factor 0.000.
2023-12-01 11:43:22,478 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 44 with boundary 37.9-41.7 and batch_size 2: Num Examples 0.0, Num Full Batches 0.000, Pad Factor 0.000.
2023-12-01 11:43:22,478 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 45 with boundary 41.7-46.3 and batch_size 2: Num Examples 0.0, Num Full Batches 0.000, Pad Factor 0.000.
2023-12-01 11:43:22,478 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 46 with boundary 46.3-52.4 and batch_size 1: Num Examples 0.0, Num Full Batches 0.000, Pad Factor 0.000.
2023-12-01 11:43:22,478 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 47 with boundary 52.4-60.8 and batch_size 1: Num Examples 0.0, Num Full Batches 0.000, Pad Factor 0.000.
2023-12-01 11:43:22,478 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 48 with boundary 60.8-73.9 and batch_size 1: Num Examples 0.0, Num Full Batches 0.000, Pad Factor 0.000.
2023-12-01 11:43:22,478 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 49 with boundary 73.9-100.0 and batch_size 1: Num Examples 0.0, Num Full Batches 0.000, Pad Factor 0.000.
2023-12-01 11:43:22,480 - speechbrain.core - INFO - Info: test_only arg overridden by command line input to: False
2023-12-01 11:43:22,480 - speechbrain.core - INFO - Info: debug arg overridden by command line input to: False
2023-12-01 11:43:22,480 - speechbrain.core - INFO - Info: debug_batches arg overridden by command line input to: 2
2023-12-01 11:43:22,480 - speechbrain.core - INFO - Info: debug_epochs arg overridden by command line input to: 2
2023-12-01 11:43:22,480 - speechbrain.core - INFO - Info: debug_persistently arg overridden by command line input to: False
2023-12-01 11:43:22,480 - speechbrain.core - INFO - Info: device arg overridden by command line input to: cuda:0
2023-12-01 11:43:22,480 - speechbrain.core - INFO - Info: data_parallel_backend arg overridden by command line input to: False
2023-12-01 11:43:22,480 - speechbrain.core - INFO - Info: distributed_backend arg overridden by command line input to: nccl
2023-12-01 11:43:22,480 - speechbrain.core - INFO - Info: find_unused_parameters arg overridden by command line input to: True
2023-12-01 11:43:22,480 - speechbrain.core - INFO - Info: jit arg overridden by command line input to: False
2023-12-01 11:43:22,480 - speechbrain.core - INFO - Info: compile arg overridden by command line input to: False
2023-12-01 11:43:22,480 - speechbrain.core - INFO - Info: auto_mix_prec arg from hparam file is used
2023-12-01 11:43:22,480 - speechbrain.core - INFO - Info: bfloat16_mix_prec arg from hparam file is used
2023-12-01 11:43:22,480 - speechbrain.core - INFO - Info: max_grad_norm arg from hparam file is used
2023-12-01 11:43:22,480 - speechbrain.core - INFO - Info: optimizer_step_limit arg from hparam file is used
2023-12-01 11:43:22,480 - speechbrain.core - INFO - Info: tqdm_colored_bar arg overridden by command line input to: False
2023-12-01 11:43:22,480 - speechbrain.core - INFO - Info: remove_vector_weight_decay arg overridden by command line input to: False
2023-12-01 11:43:22,548 - speechbrain.core - INFO - 46.5M trainable parameters in BestRQBrain
2023-12-01 11:43:22,596 - speechbrain.utils.checkpoints - INFO - Would load a checkpoint here, but none found yet.
2023-12-01 11:43:22,596 - speechbrain.utils.epoch_loop - INFO - Going into epoch 1
2023-12-01 11:43:22,597 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-01 11:43:23,462 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-01 11:44:47,226 - speechbrain.utils.train_logger - INFO - steps: 500, lr: 1.60e-05, avg_loss: 7.53
2023-12-01 11:46:06,924 - speechbrain.utils.train_logger - INFO - steps: 1000, lr: 3.20e-05, avg_loss: 6.80, run_time: 79.69
2023-12-01 11:47:26,654 - speechbrain.utils.train_logger - INFO - steps: 1500, lr: 4.80e-05, avg_loss: 6.38, run_time: 79.74
2023-12-01 11:48:46,348 - speechbrain.utils.train_logger - INFO - steps: 2000, lr: 6.40e-05, avg_loss: 6.08, run_time: 79.70
2023-12-01 11:50:05,810 - speechbrain.utils.train_logger - INFO - steps: 2500, lr: 8.00e-05, avg_loss: 5.83, run_time: 79.48
2023-12-01 11:51:25,411 - speechbrain.utils.train_logger - INFO - steps: 3000, lr: 9.60e-05, avg_loss: 5.63, run_time: 79.60
2023-12-01 11:52:45,006 - speechbrain.utils.train_logger - INFO - steps: 3500, lr: 1.12e-04, avg_loss: 5.47, run_time: 79.54
2023-12-01 11:54:04,675 - speechbrain.utils.train_logger - INFO - steps: 4000, lr: 1.28e-04, avg_loss: 5.34, run_time: 79.72
2023-12-01 11:55:24,170 - speechbrain.utils.train_logger - INFO - steps: 4500, lr: 1.44e-04, avg_loss: 5.22, run_time: 79.47
2023-12-01 11:56:36,659 - speechbrain.utils.train_logger - INFO - epoch: 1, steps: 4832, lr: 1.55e-04 - train loss: 5.15 - valid loss: 4.87, valid accuracy: 1.45e-01
2023-12-01 11:56:37,301 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/best_hyperbranchconformer/2000/save/CKPT+2023-12-01+11-56-36+00
2023-12-01 11:56:37,304 - speechbrain.utils.epoch_loop - INFO - Going into epoch 2
2023-12-01 11:56:37,305 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-01 11:56:38,239 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-01 11:57:06,364 - speechbrain.utils.train_logger - INFO - steps: 5000, lr: 1.60e-04, avg_loss: 4.24, run_time: 1.02e+02
2023-12-01 11:58:26,837 - speechbrain.utils.train_logger - INFO - steps: 5500, lr: 1.76e-04, avg_loss: 4.21, run_time: 80.44
2023-12-01 11:59:46,722 - speechbrain.utils.train_logger - INFO - steps: 6000, lr: 1.92e-04, avg_loss: 4.18, run_time: 79.88
2023-12-01 12:01:07,087 - speechbrain.utils.train_logger - INFO - steps: 6500, lr: 2.08e-04, avg_loss: 4.16, run_time: 80.38
2023-12-01 12:02:27,286 - speechbrain.utils.train_logger - INFO - steps: 7000, lr: 2.24e-04, avg_loss: 4.15, run_time: 80.16
2023-12-01 12:03:47,414 - speechbrain.utils.train_logger - INFO - steps: 7500, lr: 2.40e-04, avg_loss: 4.13, run_time: 80.15
2023-12-01 12:05:07,450 - speechbrain.utils.train_logger - INFO - steps: 8000, lr: 2.56e-04, avg_loss: 4.12, run_time: 80.04
2023-12-01 12:06:27,336 - speechbrain.utils.train_logger - INFO - steps: 8500, lr: 2.72e-04, avg_loss: 4.10, run_time: 79.87
2023-12-01 12:07:47,118 - speechbrain.utils.train_logger - INFO - steps: 9000, lr: 2.88e-04, avg_loss: 4.09, run_time: 79.75
2023-12-01 12:09:06,767 - speechbrain.utils.train_logger - INFO - steps: 9500, lr: 3.04e-04, avg_loss: 4.08, run_time: 79.72
2023-12-01 12:09:52,012 - speechbrain.utils.train_logger - INFO - epoch: 2, steps: 9664, lr: 3.09e-04 - train loss: 4.07 - valid loss: 4.41, valid accuracy: 1.71e-01
2023-12-01 12:09:52,660 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/best_hyperbranchconformer/2000/save/CKPT+2023-12-01+12-09-52+00
2023-12-01 12:09:52,664 - speechbrain.utils.epoch_loop - INFO - Going into epoch 3
2023-12-01 12:09:52,666 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-01 12:09:53,592 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-01 12:10:48,555 - speechbrain.utils.train_logger - INFO - steps: 10000, lr: 3.20e-04, avg_loss: 3.94, run_time: 1.02e+02
2023-12-01 12:12:09,666 - speechbrain.utils.train_logger - INFO - steps: 10500, lr: 3.36e-04, avg_loss: 3.94, run_time: 81.13
2023-12-01 12:13:29,860 - speechbrain.utils.train_logger - INFO - steps: 11000, lr: 3.52e-04, avg_loss: 3.93, run_time: 80.19
2023-12-01 12:14:50,023 - speechbrain.utils.train_logger - INFO - steps: 11500, lr: 3.68e-04, avg_loss: 3.93, run_time: 80.16
2023-12-01 12:16:10,374 - speechbrain.utils.train_logger - INFO - steps: 12000, lr: 3.84e-04, avg_loss: 3.92, run_time: 80.35
2023-12-01 12:17:30,475 - speechbrain.utils.train_logger - INFO - steps: 12500, lr: 4.00e-04, avg_loss: 3.92, run_time: 80.10
2023-12-01 12:18:50,521 - speechbrain.utils.train_logger - INFO - steps: 13000, lr: 4.16e-04, avg_loss: 3.91, run_time: 80.05
2023-12-01 12:20:10,569 - speechbrain.utils.train_logger - INFO - steps: 13500, lr: 4.32e-04, avg_loss: 3.91, run_time: 80.06
2023-12-01 12:21:30,585 - speechbrain.utils.train_logger - INFO - steps: 14000, lr: 4.48e-04, avg_loss: 3.90, run_time: 79.97
2023-12-01 12:23:09,210 - speechbrain.utils.train_logger - INFO - epoch: 3, steps: 14496, lr: 4.64e-04 - train loss: 3.89 - valid loss: 4.29, valid accuracy: 1.78e-01
2023-12-01 12:23:09,903 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/best_hyperbranchconformer/2000/save/CKPT+2023-12-01+12-23-09+00
2023-12-01 12:23:09,911 - speechbrain.utils.epoch_loop - INFO - Going into epoch 4
2023-12-01 12:23:09,913 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-01 12:23:10,947 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-01 12:23:12,766 - speechbrain.utils.train_logger - INFO - steps: 14500, lr: 4.64e-04, avg_loss: 3.56, run_time: 1.02e+02
2023-12-01 12:24:33,243 - speechbrain.utils.train_logger - INFO - steps: 15000, lr: 4.80e-04, avg_loss: 3.85, run_time: 80.48
2023-12-01 12:25:53,266 - speechbrain.utils.train_logger - INFO - steps: 15500, lr: 4.96e-04, avg_loss: 3.83, run_time: 80.03
2023-12-01 12:27:13,490 - speechbrain.utils.train_logger - INFO - steps: 16000, lr: 5.12e-04, avg_loss: 3.83, run_time: 80.20
2023-12-01 12:28:33,968 - speechbrain.utils.train_logger - INFO - steps: 16500, lr: 5.28e-04, avg_loss: 3.83, run_time: 80.48
2023-12-01 12:29:54,192 - speechbrain.utils.train_logger - INFO - steps: 17000, lr: 5.44e-04, avg_loss: 3.82, run_time: 80.22
2023-12-01 12:31:14,298 - speechbrain.utils.train_logger - INFO - steps: 17500, lr: 5.60e-04, avg_loss: 3.82, run_time: 80.08
2023-12-01 12:32:34,543 - speechbrain.utils.train_logger - INFO - steps: 18000, lr: 5.76e-04, avg_loss: 3.82, run_time: 80.26
2023-12-01 12:33:54,512 - speechbrain.utils.train_logger - INFO - steps: 18500, lr: 5.92e-04, avg_loss: 3.81, run_time: 79.96
2023-12-01 12:35:14,615 - speechbrain.utils.train_logger - INFO - steps: 19000, lr: 6.08e-04, avg_loss: 3.81, run_time: 80.12
2023-12-01 12:36:26,666 - speechbrain.utils.train_logger - INFO - epoch: 4, steps: 19328, lr: 6.18e-04 - train loss: 3.81 - valid loss: 4.20, valid accuracy: 1.84e-01
2023-12-01 12:36:27,368 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/best_hyperbranchconformer/2000/save/CKPT+2023-12-01+12-36-26+00
2023-12-01 12:36:27,381 - speechbrain.utils.epoch_loop - INFO - Going into epoch 5
2023-12-01 12:36:27,382 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-01 12:36:28,236 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-01 12:36:57,207 - speechbrain.utils.train_logger - INFO - steps: 19500, lr: 6.24e-04, avg_loss: 3.79, run_time: 1.03e+02
2023-12-01 12:38:18,140 - speechbrain.utils.train_logger - INFO - steps: 20000, lr: 6.40e-04, avg_loss: 3.77, run_time: 80.91
2023-12-01 12:39:38,484 - speechbrain.utils.train_logger - INFO - steps: 20500, lr: 6.56e-04, avg_loss: 3.77, run_time: 80.37
2023-12-01 12:40:59,211 - speechbrain.utils.train_logger - INFO - steps: 21000, lr: 6.72e-04, avg_loss: 3.77, run_time: 80.72
2023-12-01 12:42:19,715 - speechbrain.utils.train_logger - INFO - steps: 21500, lr: 6.88e-04, avg_loss: 3.76, run_time: 80.52
2023-12-01 12:43:40,634 - speechbrain.utils.train_logger - INFO - steps: 22000, lr: 7.04e-04, avg_loss: 3.76, run_time: 80.91
2023-12-01 12:45:01,244 - speechbrain.utils.train_logger - INFO - steps: 22500, lr: 7.20e-04, avg_loss: 3.76, run_time: 80.59
2023-12-01 12:46:21,788 - speechbrain.utils.train_logger - INFO - steps: 23000, lr: 7.36e-04, avg_loss: 3.75, run_time: 80.55
2023-12-01 12:47:42,578 - speechbrain.utils.train_logger - INFO - steps: 23500, lr: 7.52e-04, avg_loss: 3.75, run_time: 80.80
2023-12-01 12:49:07,312 - speechbrain.utils.train_logger - INFO - steps: 24000, lr: 7.68e-04, avg_loss: 3.75, run_time: 84.74
2023-12-01 12:49:54,094 - speechbrain.utils.train_logger - INFO - epoch: 5, steps: 24160, lr: 7.73e-04 - train loss: 3.75 - valid loss: 4.20, valid accuracy: 1.87e-01
2023-12-01 12:49:54,946 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/best_hyperbranchconformer/2000/save/CKPT+2023-12-01+12-49-54+00
2023-12-01 12:49:54,966 - speechbrain.utils.epoch_loop - INFO - Going into epoch 6
2023-12-01 12:49:54,968 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-01 12:49:55,821 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-01 12:50:53,121 - speechbrain.utils.train_logger - INFO - steps: 24500, lr: 7.84e-04, avg_loss: 3.75, run_time: 1.06e+02
2023-12-01 12:52:15,107 - speechbrain.utils.train_logger - INFO - steps: 25000, lr: 8.00e-04, avg_loss: 3.73, run_time: 81.98
2023-12-01 12:53:36,134 - speechbrain.utils.train_logger - INFO - steps: 25500, lr: 7.92e-04, avg_loss: 3.73, run_time: 81.03
2023-12-01 12:54:56,559 - speechbrain.utils.train_logger - INFO - steps: 26000, lr: 7.84e-04, avg_loss: 3.72, run_time: 80.44
2023-12-01 12:56:17,890 - speechbrain.utils.train_logger - INFO - steps: 26500, lr: 7.77e-04, avg_loss: 3.72, run_time: 81.32
2023-12-01 12:57:38,800 - speechbrain.utils.train_logger - INFO - steps: 27000, lr: 7.70e-04, avg_loss: 3.72, run_time: 80.92
2023-12-01 12:58:59,818 - speechbrain.utils.train_logger - INFO - steps: 27500, lr: 7.63e-04, avg_loss: 3.72, run_time: 81.02
2023-12-01 13:00:20,472 - speechbrain.utils.train_logger - INFO - steps: 28000, lr: 7.56e-04, avg_loss: 3.71, run_time: 80.64
2023-12-01 13:01:41,017 - speechbrain.utils.train_logger - INFO - steps: 28500, lr: 7.49e-04, avg_loss: 3.71, run_time: 80.54
2023-12-01 13:03:20,248 - speechbrain.utils.train_logger - INFO - epoch: 6, steps: 28992, lr: 7.43e-04 - train loss: 3.71 - valid loss: 4.19, valid accuracy: 1.86e-01
2023-12-01 13:03:21,078 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/best_hyperbranchconformer/2000/save/CKPT+2023-12-01+13-03-20+00
2023-12-01 13:03:21,105 - speechbrain.utils.epoch_loop - INFO - Going into epoch 7
2023-12-01 13:03:21,107 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-01 13:03:21,930 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-01 13:03:24,705 - speechbrain.utils.train_logger - INFO - steps: 29000, lr: 7.43e-04, avg_loss: 3.74, run_time: 1.04e+02
2023-12-01 13:04:45,157 - speechbrain.utils.train_logger - INFO - steps: 29500, lr: 7.36e-04, avg_loss: 3.66, run_time: 80.46
2023-12-01 13:06:10,182 - speechbrain.utils.train_logger - INFO - steps: 30000, lr: 7.30e-04, avg_loss: 3.66, run_time: 85.03
2023-12-01 13:07:30,870 - speechbrain.utils.train_logger - INFO - steps: 30500, lr: 7.24e-04, avg_loss: 3.67, run_time: 80.67
2023-12-01 13:08:51,581 - speechbrain.utils.train_logger - INFO - steps: 31000, lr: 7.18e-04, avg_loss: 3.66, run_time: 80.71
2023-12-01 13:10:12,100 - speechbrain.utils.train_logger - INFO - steps: 31500, lr: 7.13e-04, avg_loss: 3.67, run_time: 80.52
2023-12-01 13:11:32,611 - speechbrain.utils.train_logger - INFO - steps: 32000, lr: 7.07e-04, avg_loss: 3.67, run_time: 80.51
2023-12-01 13:12:53,322 - speechbrain.utils.train_logger - INFO - steps: 32500, lr: 7.02e-04, avg_loss: 3.66, run_time: 80.72
2023-12-01 13:14:13,516 - speechbrain.utils.train_logger - INFO - steps: 33000, lr: 6.96e-04, avg_loss: 3.66, run_time: 80.18
2023-12-01 13:15:34,083 - speechbrain.utils.train_logger - INFO - steps: 33500, lr: 6.91e-04, avg_loss: 3.66, run_time: 80.57
2023-12-01 13:16:46,344 - speechbrain.utils.train_logger - INFO - epoch: 7, steps: 33824, lr: 6.88e-04 - train loss: 3.66 - valid loss: 4.11, valid accuracy: 1.94e-01
2023-12-01 13:16:47,045 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/best_hyperbranchconformer/2000/save/CKPT+2023-12-01+13-16-46+00
2023-12-01 13:16:47,082 - speechbrain.utils.epoch_loop - INFO - Going into epoch 8
2023-12-01 13:16:47,084 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-01 13:16:48,039 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-01 13:17:18,384 - speechbrain.utils.train_logger - INFO - steps: 34000, lr: 6.86e-04, avg_loss: 3.62, run_time: 1.04e+02
2023-12-01 13:18:39,078 - speechbrain.utils.train_logger - INFO - steps: 34500, lr: 6.81e-04, avg_loss: 3.64, run_time: 80.70
2023-12-01 13:19:59,863 - speechbrain.utils.train_logger - INFO - steps: 35000, lr: 6.76e-04, avg_loss: 3.64, run_time: 80.77
2023-12-01 13:21:20,965 - speechbrain.utils.train_logger - INFO - steps: 35500, lr: 6.71e-04, avg_loss: 3.64, run_time: 81.10
2023-12-01 13:22:42,134 - speechbrain.utils.train_logger - INFO - steps: 36000, lr: 6.67e-04, avg_loss: 3.64, run_time: 81.17
2023-12-01 13:24:03,411 - speechbrain.utils.train_logger - INFO - steps: 36500, lr: 6.62e-04, avg_loss: 3.64, run_time: 81.27
2023-12-01 13:25:23,940 - speechbrain.utils.train_logger - INFO - steps: 37000, lr: 6.58e-04, avg_loss: 3.64, run_time: 80.52
2023-12-01 13:26:44,457 - speechbrain.utils.train_logger - INFO - steps: 37500, lr: 6.53e-04, avg_loss: 3.63, run_time: 80.54
2023-12-01 13:28:13,415 - speechbrain.utils.train_logger - INFO - steps: 38000, lr: 6.49e-04, avg_loss: 3.63, run_time: 88.96
2023-12-01 13:29:34,076 - speechbrain.utils.train_logger - INFO - steps: 38500, lr: 6.45e-04, avg_loss: 3.63, run_time: 80.68
2023-12-01 13:30:20,854 - speechbrain.utils.train_logger - INFO - epoch: 8, steps: 38656, lr: 6.43e-04 - train loss: 3.63 - valid loss: 4.09, valid accuracy: 1.97e-01
2023-12-01 13:30:21,558 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/best_hyperbranchconformer/2000/save/CKPT+2023-12-01+13-30-20+00
2023-12-01 13:30:21,605 - speechbrain.utils.epoch_loop - INFO - Going into epoch 9
2023-12-01 13:30:21,607 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-01 13:30:22,554 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-01 13:31:19,630 - speechbrain.utils.train_logger - INFO - steps: 39000, lr: 6.41e-04, avg_loss: 3.62, run_time: 1.06e+02
2023-12-01 13:32:40,740 - speechbrain.utils.train_logger - INFO - steps: 39500, lr: 6.36e-04, avg_loss: 3.61, run_time: 81.12
2023-12-01 13:34:03,125 - speechbrain.utils.train_logger - INFO - steps: 40000, lr: 6.32e-04, avg_loss: 3.62, run_time: 82.38
2023-12-01 13:35:27,994 - speechbrain.utils.train_logger - INFO - steps: 40500, lr: 6.29e-04, avg_loss: 3.62, run_time: 84.88
2023-12-01 13:36:48,737 - speechbrain.utils.train_logger - INFO - steps: 41000, lr: 6.25e-04, avg_loss: 3.61, run_time: 80.73
2023-12-01 13:38:09,405 - speechbrain.utils.train_logger - INFO - steps: 41500, lr: 6.21e-04, avg_loss: 3.62, run_time: 80.68
2023-12-01 13:39:30,141 - speechbrain.utils.train_logger - INFO - steps: 42000, lr: 6.17e-04, avg_loss: 3.62, run_time: 80.72
2023-12-01 13:40:55,583 - speechbrain.utils.train_logger - INFO - steps: 42500, lr: 6.14e-04, avg_loss: 3.61, run_time: 85.43
2023-12-01 13:42:20,226 - speechbrain.utils.train_logger - INFO - steps: 43000, lr: 6.10e-04, avg_loss: 3.61, run_time: 84.67
2023-12-01 13:43:59,529 - speechbrain.utils.train_logger - INFO - epoch: 9, steps: 43488, lr: 6.07e-04 - train loss: 3.61 - valid loss: 4.05, valid accuracy: 1.98e-01
2023-12-01 13:44:00,222 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/best_hyperbranchconformer/2000/save/CKPT+2023-12-01+13-43-59+00
2023-12-01 13:44:00,281 - speechbrain.utils.epoch_loop - INFO - Going into epoch 10
2023-12-01 13:44:00,282 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-01 13:44:01,022 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-01 13:44:04,413 - speechbrain.utils.train_logger - INFO - steps: 43500, lr: 6.06e-04, avg_loss: 3.64, run_time: 1.04e+02
2023-12-01 13:45:24,941 - speechbrain.utils.train_logger - INFO - steps: 44000, lr: 6.03e-04, avg_loss: 3.58, run_time: 80.52
2023-12-01 13:46:45,102 - speechbrain.utils.train_logger - INFO - steps: 44500, lr: 6.00e-04, avg_loss: 3.59, run_time: 80.18
2023-12-01 13:48:05,457 - speechbrain.utils.train_logger - INFO - steps: 45000, lr: 5.96e-04, avg_loss: 3.58, run_time: 80.32
2023-12-01 13:49:25,548 - speechbrain.utils.train_logger - INFO - steps: 45500, lr: 5.93e-04, avg_loss: 3.58, run_time: 80.08
2023-12-01 13:50:46,458 - speechbrain.utils.train_logger - INFO - steps: 46000, lr: 5.90e-04, avg_loss: 3.58, run_time: 80.93
2023-12-01 13:52:07,259 - speechbrain.utils.train_logger - INFO - steps: 46500, lr: 5.87e-04, avg_loss: 3.58, run_time: 80.82
2023-12-01 13:53:28,188 - speechbrain.utils.train_logger - INFO - steps: 47000, lr: 5.83e-04, avg_loss: 3.58, run_time: 80.92
2023-12-01 13:54:48,965 - speechbrain.utils.train_logger - INFO - steps: 47500, lr: 5.80e-04, avg_loss: 3.58, run_time: 80.77
2023-12-01 13:56:09,915 - speechbrain.utils.train_logger - INFO - steps: 48000, lr: 5.77e-04, avg_loss: 3.58, run_time: 80.96
2023-12-01 13:57:27,433 - speechbrain.utils.train_logger - INFO - epoch: 10, steps: 48320, lr: 5.75e-04 - train loss: 3.58 - valid loss: 4.05, valid accuracy: 2.01e-01
2023-12-01 13:57:28,199 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/best_hyperbranchconformer/2000/save/CKPT+2023-12-01+13-57-27+00
2023-12-01 13:57:28,272 - speechbrain.utils.epoch_loop - INFO - Going into epoch 11
2023-12-01 13:57:28,274 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-01 13:57:29,115 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-01 13:57:59,819 - speechbrain.utils.train_logger - INFO - steps: 48500, lr: 5.74e-04, avg_loss: 3.56, run_time: 1.10e+02
2023-12-01 13:59:20,721 - speechbrain.utils.train_logger - INFO - steps: 49000, lr: 5.71e-04, avg_loss: 3.57, run_time: 80.89
2023-12-01 14:00:41,407 - speechbrain.utils.train_logger - INFO - steps: 49500, lr: 5.69e-04, avg_loss: 3.58, run_time: 80.68
2023-12-01 14:02:01,855 - speechbrain.utils.train_logger - INFO - steps: 50000, lr: 5.66e-04, avg_loss: 3.58, run_time: 80.47
2023-12-01 14:03:22,495 - speechbrain.utils.train_logger - INFO - steps: 50500, lr: 5.63e-04, avg_loss: 3.58, run_time: 80.62
2023-12-01 14:04:47,212 - speechbrain.utils.train_logger - INFO - steps: 51000, lr: 5.60e-04, avg_loss: 3.57, run_time: 84.73
2023-12-01 14:06:07,358 - speechbrain.utils.train_logger - INFO - steps: 51500, lr: 5.57e-04, avg_loss: 3.57, run_time: 80.14
2023-12-01 14:07:28,434 - speechbrain.utils.train_logger - INFO - steps: 52000, lr: 5.55e-04, avg_loss: 3.58, run_time: 81.08
2023-12-01 14:08:49,210 - speechbrain.utils.train_logger - INFO - steps: 52500, lr: 5.52e-04, avg_loss: 3.57, run_time: 80.79
2023-12-01 14:10:09,894 - speechbrain.utils.train_logger - INFO - steps: 53000, lr: 5.49e-04, avg_loss: 3.57, run_time: 80.70
2023-12-01 14:10:55,078 - speechbrain.utils.train_logger - INFO - epoch: 11, steps: 53152, lr: 5.49e-04 - train loss: 3.57 - valid loss: 4.06, valid accuracy: 1.98e-01
2023-12-01 14:10:55,887 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/best_hyperbranchconformer/2000/save/CKPT+2023-12-01+14-10-55+00
2023-12-01 14:10:55,997 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/best_hyperbranchconformer/2000/save/CKPT+2023-12-01+11-56-36+00
2023-12-01 14:10:55,997 - speechbrain.utils.epoch_loop - INFO - Going into epoch 12
2023-12-01 14:10:55,999 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-01 14:10:56,829 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-01 14:11:54,808 - speechbrain.utils.train_logger - INFO - steps: 53500, lr: 5.47e-04, avg_loss: 3.56, run_time: 1.05e+02
2023-12-01 14:13:19,676 - speechbrain.utils.train_logger - INFO - steps: 54000, lr: 5.44e-04, avg_loss: 3.57, run_time: 84.88
2023-12-01 14:14:41,228 - speechbrain.utils.train_logger - INFO - steps: 54500, lr: 5.42e-04, avg_loss: 3.57, run_time: 81.55
2023-12-01 14:16:02,322 - speechbrain.utils.train_logger - INFO - steps: 55000, lr: 5.39e-04, avg_loss: 3.57, run_time: 81.07
2023-12-01 14:17:22,892 - speechbrain.utils.train_logger - INFO - steps: 55500, lr: 5.37e-04, avg_loss: 3.57, run_time: 80.57
2023-12-01 14:18:44,001 - speechbrain.utils.train_logger - INFO - steps: 56000, lr: 5.35e-04, avg_loss: 3.57, run_time: 81.14
2023-12-01 14:20:05,495 - speechbrain.utils.train_logger - INFO - steps: 56500, lr: 5.32e-04, avg_loss: 3.57, run_time: 81.49
2023-12-01 14:21:26,122 - speechbrain.utils.train_logger - INFO - steps: 57000, lr: 5.30e-04, avg_loss: 3.57, run_time: 80.61
2023-12-01 14:22:46,849 - speechbrain.utils.train_logger - INFO - steps: 57500, lr: 5.28e-04, avg_loss: 3.57, run_time: 80.74
2023-12-01 14:24:26,431 - speechbrain.utils.train_logger - INFO - epoch: 12, steps: 57984, lr: 5.25e-04 - train loss: 3.57 - valid loss: 4.01, valid accuracy: 2.04e-01
2023-12-01 14:24:27,106 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/best_hyperbranchconformer/2000/save/CKPT+2023-12-01+14-24-26+00
2023-12-01 14:24:27,222 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/best_hyperbranchconformer/2000/save/CKPT+2023-12-01+12-09-52+00
2023-12-01 14:24:27,223 - speechbrain.utils.epoch_loop - INFO - Going into epoch 13
2023-12-01 14:24:27,224 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-01 14:24:28,209 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-01 14:24:32,303 - speechbrain.utils.train_logger - INFO - steps: 58000, lr: 5.25e-04, avg_loss: 3.55, run_time: 1.05e+02
2023-12-01 14:25:53,359 - speechbrain.utils.train_logger - INFO - steps: 58500, lr: 5.23e-04, avg_loss: 3.56, run_time: 81.07
2023-12-01 14:27:13,704 - speechbrain.utils.train_logger - INFO - steps: 59000, lr: 5.21e-04, avg_loss: 3.55, run_time: 80.34
2023-12-01 14:28:34,376 - speechbrain.utils.train_logger - INFO - steps: 59500, lr: 5.19e-04, avg_loss: 3.55, run_time: 80.65
2023-12-01 14:29:55,961 - speechbrain.utils.train_logger - INFO - steps: 60000, lr: 5.16e-04, avg_loss: 3.55, run_time: 81.60
2023-12-01 14:31:17,672 - speechbrain.utils.train_logger - INFO - steps: 60500, lr: 5.14e-04, avg_loss: 3.55, run_time: 81.69
2023-12-01 14:32:38,482 - speechbrain.utils.train_logger - INFO - steps: 61000, lr: 5.12e-04, avg_loss: 3.55, run_time: 80.83
2023-12-01 14:33:59,451 - speechbrain.utils.train_logger - INFO - steps: 61500, lr: 5.10e-04, avg_loss: 3.55, run_time: 80.96
2023-12-01 14:35:20,387 - speechbrain.utils.train_logger - INFO - steps: 62000, lr: 5.08e-04, avg_loss: 3.55, run_time: 80.93
2023-12-01 14:36:41,362 - speechbrain.utils.train_logger - INFO - steps: 62500, lr: 5.06e-04, avg_loss: 3.55, run_time: 80.99
2023-12-01 14:37:52,778 - speechbrain.utils.train_logger - INFO - epoch: 13, steps: 62816, lr: 5.05e-04 - train loss: 3.55 - valid loss: 4.03, valid accuracy: 2.04e-01
2023-12-01 14:37:53,472 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/best_hyperbranchconformer/2000/save/CKPT+2023-12-01+14-37-52+00
2023-12-01 14:37:53,584 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/best_hyperbranchconformer/2000/save/CKPT+2023-12-01+12-23-09+00
2023-12-01 14:37:53,584 - speechbrain.utils.epoch_loop - INFO - Going into epoch 14
2023-12-01 14:37:53,585 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-01 14:37:54,580 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-01 14:38:25,843 - speechbrain.utils.train_logger - INFO - steps: 63000, lr: 5.04e-04, avg_loss: 3.54, run_time: 1.04e+02
2023-12-01 14:39:46,070 - speechbrain.utils.train_logger - INFO - steps: 63500, lr: 5.02e-04, avg_loss: 3.53, run_time: 80.24
2023-12-01 14:41:06,964 - speechbrain.utils.train_logger - INFO - steps: 64000, lr: 5.00e-04, avg_loss: 3.54, run_time: 80.86
2023-12-01 14:42:27,143 - speechbrain.utils.train_logger - INFO - steps: 64500, lr: 4.98e-04, avg_loss: 3.54, run_time: 80.21
2023-12-01 14:43:47,410 - speechbrain.utils.train_logger - INFO - steps: 65000, lr: 4.96e-04, avg_loss: 3.54, run_time: 80.26
2023-12-01 14:45:07,837 - speechbrain.utils.train_logger - INFO - steps: 65500, lr: 4.94e-04, avg_loss: 3.54, run_time: 80.41
2023-12-01 14:46:28,073 - speechbrain.utils.train_logger - INFO - steps: 66000, lr: 4.92e-04, avg_loss: 3.54, run_time: 80.27
2023-12-01 14:47:52,799 - speechbrain.utils.train_logger - INFO - steps: 66500, lr: 4.91e-04, avg_loss: 3.54, run_time: 84.70
2023-12-01 14:49:13,476 - speechbrain.utils.train_logger - INFO - steps: 67000, lr: 4.89e-04, avg_loss: 3.54, run_time: 80.69
2023-12-01 14:50:38,227 - speechbrain.utils.train_logger - INFO - steps: 67500, lr: 4.87e-04, avg_loss: 3.54, run_time: 84.75
2023-12-01 14:51:27,363 - speechbrain.utils.train_logger - INFO - epoch: 14, steps: 67648, lr: 4.86e-04 - train loss: 3.54 - valid loss: 4.01, valid accuracy: 2.04e-01
2023-12-01 14:51:28,039 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/best_hyperbranchconformer/2000/save/CKPT+2023-12-01+14-51-27+00
2023-12-01 14:51:28,158 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/best_hyperbranchconformer/2000/save/CKPT+2023-12-01+12-36-26+00
2023-12-01 14:51:28,159 - speechbrain.utils.epoch_loop - INFO - Going into epoch 15
2023-12-01 14:51:28,161 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-01 14:51:29,120 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-01 14:52:27,147 - speechbrain.utils.train_logger - INFO - steps: 68000, lr: 4.85e-04, avg_loss: 3.53, run_time: 1.09e+02
2023-12-01 14:53:48,049 - speechbrain.utils.train_logger - INFO - steps: 68500, lr: 4.83e-04, avg_loss: 3.53, run_time: 80.90
2023-12-01 14:55:08,651 - speechbrain.utils.train_logger - INFO - steps: 69000, lr: 4.82e-04, avg_loss: 3.53, run_time: 80.62
2023-12-01 14:56:29,628 - speechbrain.utils.train_logger - INFO - steps: 69500, lr: 4.80e-04, avg_loss: 3.53, run_time: 80.97
2023-12-01 14:57:51,780 - speechbrain.utils.train_logger - INFO - steps: 70000, lr: 4.78e-04, avg_loss: 3.53, run_time: 82.15
2023-12-01 14:59:16,873 - speechbrain.utils.train_logger - INFO - steps: 70500, lr: 4.76e-04, avg_loss: 3.52, run_time: 85.07
2023-12-01 15:00:37,400 - speechbrain.utils.train_logger - INFO - steps: 71000, lr: 4.75e-04, avg_loss: 3.52, run_time: 80.54
2023-12-01 15:01:58,410 - speechbrain.utils.train_logger - INFO - steps: 71500, lr: 4.73e-04, avg_loss: 3.53, run_time: 81.01
2023-12-01 15:03:20,103 - speechbrain.utils.train_logger - INFO - steps: 72000, lr: 4.71e-04, avg_loss: 3.52, run_time: 81.70
2023-12-01 15:04:59,547 - speechbrain.utils.train_logger - INFO - epoch: 15, steps: 72480, lr: 4.70e-04 - train loss: 3.52 - valid loss: 4.01, valid accuracy: 2.03e-01
2023-12-01 15:05:00,255 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/best_hyperbranchconformer/2000/save/CKPT+2023-12-01+15-04-59+00
2023-12-01 15:05:00,445 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/best_hyperbranchconformer/2000/save/CKPT+2023-12-01+12-49-54+00
2023-12-01 15:05:00,445 - speechbrain.utils.epoch_loop - INFO - Going into epoch 16
2023-12-01 15:05:00,446 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-01 15:05:01,218 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-01 15:05:06,341 - speechbrain.utils.train_logger - INFO - steps: 72500, lr: 4.70e-04, avg_loss: 3.53, run_time: 1.06e+02
2023-12-01 15:06:27,513 - speechbrain.utils.train_logger - INFO - steps: 73000, lr: 4.68e-04, avg_loss: 3.52, run_time: 81.16
2023-12-01 15:07:47,845 - speechbrain.utils.train_logger - INFO - steps: 73500, lr: 4.67e-04, avg_loss: 3.52, run_time: 80.36
2023-12-01 15:09:08,089 - speechbrain.utils.train_logger - INFO - steps: 74000, lr: 4.65e-04, avg_loss: 3.52, run_time: 80.24
2023-12-01 15:10:28,559 - speechbrain.utils.train_logger - INFO - steps: 74500, lr: 4.63e-04, avg_loss: 3.52, run_time: 80.48
2023-12-01 15:11:48,952 - speechbrain.utils.train_logger - INFO - steps: 75000, lr: 4.62e-04, avg_loss: 3.52, run_time: 80.37
2023-12-01 15:13:16,186 - speechbrain.utils.train_logger - INFO - steps: 75500, lr: 4.60e-04, avg_loss: 3.52, run_time: 87.25
2023-12-01 15:14:38,064 - speechbrain.utils.train_logger - INFO - steps: 76000, lr: 4.59e-04, avg_loss: 3.52, run_time: 81.86
2023-12-01 15:16:00,447 - speechbrain.utils.train_logger - INFO - steps: 76500, lr: 4.57e-04, avg_loss: 3.52, run_time: 82.39
2023-12-01 15:17:25,617 - speechbrain.utils.train_logger - INFO - steps: 77000, lr: 4.56e-04, avg_loss: 3.52, run_time: 85.19
2023-12-01 15:18:40,422 - speechbrain.utils.train_logger - INFO - epoch: 16, steps: 77312, lr: 4.55e-04 - train loss: 3.52 - valid loss: 3.93, valid accuracy: 2.09e-01
2023-12-01 15:18:41,091 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/best_hyperbranchconformer/2000/save/CKPT+2023-12-01+15-18-40+00
2023-12-01 15:18:41,231 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/best_hyperbranchconformer/2000/save/CKPT+2023-12-01+13-03-20+00
2023-12-01 15:18:41,232 - speechbrain.utils.epoch_loop - INFO - Going into epoch 17
2023-12-01 15:18:41,233 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-01 15:18:42,071 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-01 15:19:15,825 - speechbrain.utils.train_logger - INFO - steps: 77500, lr: 4.54e-04, avg_loss: 3.54, run_time: 1.10e+02
2023-12-01 15:20:36,736 - speechbrain.utils.train_logger - INFO - steps: 78000, lr: 4.53e-04, avg_loss: 3.53, run_time: 80.89
2023-12-01 15:22:02,712 - speechbrain.utils.train_logger - INFO - steps: 78500, lr: 4.51e-04, avg_loss: 3.52, run_time: 86.00
2023-12-01 15:23:26,230 - speechbrain.utils.train_logger - INFO - steps: 79000, lr: 4.50e-04, avg_loss: 3.52, run_time: 83.50
2023-12-01 15:24:54,871 - speechbrain.utils.train_logger - INFO - steps: 79500, lr: 4.49e-04, avg_loss: 3.52, run_time: 88.64
2023-12-01 15:26:17,007 - speechbrain.utils.train_logger - INFO - steps: 80000, lr: 4.47e-04, avg_loss: 3.52, run_time: 82.15
2023-12-01 15:27:38,242 - speechbrain.utils.train_logger - INFO - steps: 80500, lr: 4.46e-04, avg_loss: 3.52, run_time: 81.22
2023-12-01 15:29:04,659 - speechbrain.utils.train_logger - INFO - steps: 81000, lr: 4.44e-04, avg_loss: 3.52, run_time: 86.42
2023-12-01 15:30:26,787 - speechbrain.utils.train_logger - INFO - steps: 81500, lr: 4.43e-04, avg_loss: 3.52, run_time: 82.08
2023-12-01 15:31:48,513 - speechbrain.utils.train_logger - INFO - steps: 82000, lr: 4.42e-04, avg_loss: 3.52, run_time: 81.77
2023-12-01 15:32:34,035 - speechbrain.utils.train_logger - INFO - epoch: 17, steps: 82144, lr: 4.41e-04 - train loss: 3.52 - valid loss: 3.96, valid accuracy: 2.06e-01
2023-12-01 15:32:34,764 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/best_hyperbranchconformer/2000/save/CKPT+2023-12-01+15-32-34+00
2023-12-01 15:32:34,966 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/best_hyperbranchconformer/2000/save/CKPT+2023-12-01+13-16-46+00
2023-12-01 15:32:34,966 - speechbrain.utils.epoch_loop - INFO - Going into epoch 18
2023-12-01 15:32:34,968 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-01 15:32:35,931 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-01 15:33:35,050 - speechbrain.utils.train_logger - INFO - steps: 82500, lr: 4.40e-04, avg_loss: 3.52, run_time: 1.07e+02
2023-12-01 15:34:55,736 - speechbrain.utils.train_logger - INFO - steps: 83000, lr: 4.39e-04, avg_loss: 3.52, run_time: 80.68
2023-12-01 15:36:16,587 - speechbrain.utils.train_logger - INFO - steps: 83500, lr: 4.38e-04, avg_loss: 3.51, run_time: 80.83
2023-12-01 15:37:37,356 - speechbrain.utils.train_logger - INFO - steps: 84000, lr: 4.36e-04, avg_loss: 3.51, run_time: 80.79
2023-12-01 15:38:58,308 - speechbrain.utils.train_logger - INFO - steps: 84500, lr: 4.35e-04, avg_loss: 3.51, run_time: 80.94
2023-12-01 15:40:19,261 - speechbrain.utils.train_logger - INFO - steps: 85000, lr: 4.34e-04, avg_loss: 3.51, run_time: 80.97
2023-12-01 15:41:41,596 - speechbrain.utils.train_logger - INFO - steps: 85500, lr: 4.33e-04, avg_loss: 3.51, run_time: 82.32
2023-12-01 15:43:06,980 - speechbrain.utils.train_logger - INFO - steps: 86000, lr: 4.31e-04, avg_loss: 3.51, run_time: 85.38
2023-12-01 15:44:27,407 - speechbrain.utils.train_logger - INFO - steps: 86500, lr: 4.30e-04, avg_loss: 3.51, run_time: 80.44
2023-12-01 15:46:06,645 - speechbrain.utils.train_logger - INFO - epoch: 18, steps: 86976, lr: 4.29e-04 - train loss: 3.51 - valid loss: 3.97, valid accuracy: 2.05e-01
2023-12-01 15:46:07,459 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/best_hyperbranchconformer/2000/save/CKPT+2023-12-01+15-46-06+00
2023-12-01 15:46:07,607 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/best_hyperbranchconformer/2000/save/CKPT+2023-12-01+13-30-20+00
2023-12-01 15:46:07,607 - speechbrain.utils.epoch_loop - INFO - Going into epoch 19
2023-12-01 15:46:07,609 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-01 15:46:08,579 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-01 15:46:13,919 - speechbrain.utils.train_logger - INFO - steps: 87000, lr: 4.29e-04, avg_loss: 3.54, run_time: 1.07e+02
2023-12-01 15:47:34,546 - speechbrain.utils.train_logger - INFO - steps: 87500, lr: 4.28e-04, avg_loss: 3.50, run_time: 80.61
2023-12-01 15:48:55,781 - speechbrain.utils.train_logger - INFO - steps: 88000, lr: 4.26e-04, avg_loss: 3.50, run_time: 81.24
2023-12-01 15:50:16,951 - speechbrain.utils.train_logger - INFO - steps: 88500, lr: 4.25e-04, avg_loss: 3.51, run_time: 81.16
2023-12-01 15:51:37,544 - speechbrain.utils.train_logger - INFO - steps: 89000, lr: 4.24e-04, avg_loss: 3.51, run_time: 80.59
2023-12-01 15:52:58,561 - speechbrain.utils.train_logger - INFO - steps: 89500, lr: 4.23e-04, avg_loss: 3.50, run_time: 81.05
2023-12-01 15:54:19,457 - speechbrain.utils.train_logger - INFO - steps: 90000, lr: 4.22e-04, avg_loss: 3.50, run_time: 80.87
2023-12-01 15:55:40,859 - speechbrain.utils.train_logger - INFO - steps: 90500, lr: 4.20e-04, avg_loss: 3.50, run_time: 81.40
2023-12-01 15:57:05,427 - speechbrain.utils.train_logger - INFO - steps: 91000, lr: 4.19e-04, avg_loss: 3.50, run_time: 84.57
2023-12-01 15:58:26,229 - speechbrain.utils.train_logger - INFO - steps: 91500, lr: 4.18e-04, avg_loss: 3.50, run_time: 80.82
2023-12-01 15:59:38,298 - speechbrain.utils.train_logger - INFO - epoch: 19, steps: 91808, lr: 4.17e-04 - train loss: 3.51 - valid loss: 4.01, valid accuracy: 2.04e-01
2023-12-01 15:59:39,002 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/best_hyperbranchconformer/2000/save/CKPT+2023-12-01+15-59-38+00
2023-12-01 15:59:39,175 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/best_hyperbranchconformer/2000/save/CKPT+2023-12-01+13-43-59+00
2023-12-01 15:59:39,176 - speechbrain.utils.epoch_loop - INFO - Going into epoch 20
2023-12-01 15:59:39,177 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-01 15:59:40,060 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-01 16:00:13,108 - speechbrain.utils.train_logger - INFO - steps: 92000, lr: 4.17e-04, avg_loss: 3.49, run_time: 1.07e+02
2023-12-01 16:01:34,692 - speechbrain.utils.train_logger - INFO - steps: 92500, lr: 4.16e-04, avg_loss: 3.50, run_time: 81.59
2023-12-01 16:02:59,360 - speechbrain.utils.train_logger - INFO - steps: 93000, lr: 4.15e-04, avg_loss: 3.50, run_time: 84.66
2023-12-01 16:04:20,829 - speechbrain.utils.train_logger - INFO - steps: 93500, lr: 4.14e-04, avg_loss: 3.50, run_time: 81.45
2023-12-01 16:05:42,689 - speechbrain.utils.train_logger - INFO - steps: 94000, lr: 4.13e-04, avg_loss: 3.50, run_time: 81.89
2023-12-01 16:07:03,660 - speechbrain.utils.train_logger - INFO - steps: 94500, lr: 4.11e-04, avg_loss: 3.50, run_time: 80.98
2023-12-01 16:08:24,607 - speechbrain.utils.train_logger - INFO - steps: 95000, lr: 4.10e-04, avg_loss: 3.50, run_time: 80.95
2023-12-01 16:09:46,911 - speechbrain.utils.train_logger - INFO - steps: 95500, lr: 4.09e-04, avg_loss: 3.50, run_time: 82.30
2023-12-01 16:11:08,130 - speechbrain.utils.train_logger - INFO - steps: 96000, lr: 4.08e-04, avg_loss: 3.50, run_time: 81.16
2023-12-01 16:12:28,982 - speechbrain.utils.train_logger - INFO - steps: 96500, lr: 4.07e-04, avg_loss: 3.50, run_time: 80.90
2023-12-01 16:13:12,692 - speechbrain.utils.train_logger - INFO - epoch: 20, steps: 96640, lr: 4.07e-04 - train loss: 3.50 - valid loss: 3.95, valid accuracy: 2.09e-01
2023-12-01 16:13:13,502 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/best_hyperbranchconformer/2000/save/CKPT+2023-12-01+16-13-12+00
2023-12-01 16:13:13,724 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/best_hyperbranchconformer/2000/save/CKPT+2023-12-01+13-57-27+00
2023-12-01 16:13:13,725 - speechbrain.utils.epoch_loop - INFO - Going into epoch 21
2023-12-01 16:13:13,726 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-01 16:13:14,457 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-01 16:14:14,508 - speechbrain.utils.train_logger - INFO - steps: 97000, lr: 4.06e-04, avg_loss: 3.52, run_time: 1.06e+02
2023-12-01 16:15:36,693 - speechbrain.utils.train_logger - INFO - steps: 97500, lr: 4.05e-04, avg_loss: 3.50, run_time: 82.19
2023-12-01 16:16:57,963 - speechbrain.utils.train_logger - INFO - steps: 98000, lr: 4.04e-04, avg_loss: 3.50, run_time: 81.27
2023-12-01 16:18:18,517 - speechbrain.utils.train_logger - INFO - steps: 98500, lr: 4.03e-04, avg_loss: 3.49, run_time: 80.54
2023-12-01 16:19:39,543 - speechbrain.utils.train_logger - INFO - steps: 99000, lr: 4.02e-04, avg_loss: 3.49, run_time: 81.04
2023-12-01 16:20:59,947 - speechbrain.utils.train_logger - INFO - steps: 99500, lr: 4.01e-04, avg_loss: 3.50, run_time: 80.38
2023-12-01 16:22:20,324 - speechbrain.utils.train_logger - INFO - steps: 100000, lr: 4.00e-04, avg_loss: 3.50, run_time: 80.38
2023-12-01 16:23:41,126 - speechbrain.utils.train_logger - INFO - steps: 100500, lr: 3.99e-04, avg_loss: 3.50, run_time: 80.82
2023-12-01 16:25:01,278 - speechbrain.utils.train_logger - INFO - steps: 101000, lr: 3.98e-04, avg_loss: 3.50, run_time: 80.13
2023-12-01 16:26:37,213 - speechbrain.utils.train_logger - INFO - epoch: 21, steps: 101472, lr: 3.97e-04 - train loss: 3.50 - valid loss: 3.98, valid accuracy: 2.06e-01
2023-12-01 16:26:37,902 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/best_hyperbranchconformer/2000/save/CKPT+2023-12-01+16-26-37+00
2023-12-01 16:26:38,108 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/best_hyperbranchconformer/2000/save/CKPT+2023-12-01+14-10-55+00
