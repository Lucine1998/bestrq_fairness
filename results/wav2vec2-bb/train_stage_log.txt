epoch: 1, steps: 1032, lr: 1.72e-05 - train loss: 2.09e+04 - valid loss: 3.77e+03, valid accuracy: 0.035592369735240936
epoch: 2, steps: 2064, lr: 3.44e-05 - train loss: 1.91e+04 - valid loss: 3.29e+03, valid accuracy: 0.13747338950634003
epoch: 3, steps: 3096, lr: 5.16e-05 - train loss: 1.71e+04 - valid loss: 2.91e+03, valid accuracy: 0.22940123081207275
epoch: 4, steps: 4128, lr: 6.88e-05 - train loss: 1.55e+04 - valid loss: 2.73e+03, valid accuracy: 0.2740342319011688
epoch: 5, steps: 5160, lr: 8.60e-05 - train loss: 1.45e+04 - valid loss: 2.62e+03, valid accuracy: 0.29568347334861755
epoch: 6, steps: 6192, lr: 1.03e-04 - train loss: 1.40e+04 - valid loss: 2.52e+03, valid accuracy: 0.3154851198196411
epoch: 7, steps: 7224, lr: 1.20e-04 - train loss: 1.36e+04 - valid loss: 2.42e+03, valid accuracy: 0.3328488767147064
epoch: 8, steps: 8256, lr: 1.38e-04 - train loss: 1.32e+04 - valid loss: 2.36e+03, valid accuracy: 0.34626632928848267
epoch: 9, steps: 9288, lr: 1.55e-04 - train loss: 1.28e+04 - valid loss: 2.26e+03, valid accuracy: 0.3664059638977051
epoch: 10, steps: 10320, lr: 1.72e-04 - train loss: 1.25e+04 - valid loss: 2.19e+03, valid accuracy: 0.3816741406917572
epoch: 11, steps: 11352, lr: 1.89e-04 - train loss: 1.21e+04 - valid loss: 2.11e+03, valid accuracy: 0.4023001492023468
epoch: 12, steps: 12384, lr: 2.06e-04 - train loss: 1.19e+04 - valid loss: 2.06e+03, valid accuracy: 0.4150657057762146
epoch: 13, steps: 13416, lr: 2.24e-04 - train loss: 1.16e+04 - valid loss: 2.01e+03, valid accuracy: 0.4263211488723755
epoch: 14, steps: 14448, lr: 2.41e-04 - train loss: 1.14e+04 - valid loss: 1.96e+03, valid accuracy: 0.4402047395706177
epoch: 15, steps: 15480, lr: 2.58e-04 - train loss: 1.12e+04 - valid loss: 1.91e+03, valid accuracy: 0.4514952600002289
epoch: 16, steps: 16512, lr: 2.75e-04 - train loss: 1.11e+04 - valid loss: 1.88e+03, valid accuracy: 0.45960375666618347
epoch: 17, steps: 17544, lr: 2.92e-04 - train loss: 1.09e+04 - valid loss: 1.84e+03, valid accuracy: 0.4687255024909973
epoch: 18, steps: 18576, lr: 3.10e-04 - train loss: 1.08e+04 - valid loss: 1.82e+03, valid accuracy: 0.4743043780326843
epoch: 19, steps: 19608, lr: 3.27e-04 - train loss: 1.06e+04 - valid loss: 1.79e+03, valid accuracy: 0.485379695892334
epoch: 20, steps: 20640, lr: 3.44e-04 - train loss: 1.05e+04 - valid loss: 1.75e+03, valid accuracy: 0.49232718348503113
epoch: 21, steps: 21672, lr: 3.61e-04 - train loss: 1.04e+04 - valid loss: 1.73e+03, valid accuracy: 0.4965061545372009
epoch: 21, steps: 21672, lr: 3.61e-04 - train loss: 1.04e+04 - valid loss: 1.71e+03, valid accuracy: 0.5006877779960632
epoch: 22, steps: 22704, lr: 3.78e-04 - train loss: 1.03e+04 - valid loss: 1.71e+03, valid accuracy: 0.5029563903808594
epoch: 23, steps: 23736, lr: 3.96e-04 - train loss: 1.02e+04 - valid loss: 1.70e+03, valid accuracy: 0.507034182548523
epoch: 24, steps: 24768, lr: 4.13e-04 - train loss: 1.00e+04 - valid loss: 1.66e+03, valid accuracy: 0.518433690071106
epoch: 25, steps: 25800, lr: 4.30e-04 - train loss: 9.97e+03 - valid loss: 1.65e+03, valid accuracy: 0.5175066590309143
epoch: 26, steps: 26832, lr: 4.47e-04 - train loss: 9.88e+03 - valid loss: 1.61e+03, valid accuracy: 0.5297413468360901
epoch: 27, steps: 27864, lr: 4.64e-04 - train loss: 9.80e+03 - valid loss: 1.61e+03, valid accuracy: 0.5307101011276245
epoch: 28, steps: 28896, lr: 4.82e-04 - train loss: 9.72e+03 - valid loss: 1.64e+03, valid accuracy: 0.5231669545173645
epoch: 29, steps: 29928, lr: 4.99e-04 - train loss: 9.65e+03 - valid loss: 1.60e+03, valid accuracy: 0.5330967903137207
epoch: 30, steps: 30960, lr: 4.18e-04 - train loss: 9.51e+03 - valid loss: 1.56e+03, valid accuracy: 0.5454800724983215
epoch: 31, steps: 31992, lr: 4.16e-04 - train loss: 9.41e+03 - valid loss: 1.53e+03, valid accuracy: 0.5523933172225952
epoch: 32, steps: 33024, lr: 4.14e-04 - train loss: 9.36e+03 - valid loss: 1.53e+03, valid accuracy: 0.5518187284469604
epoch: 33, steps: 34056, lr: 4.12e-04 - train loss: 9.31e+03 - valid loss: 1.51e+03, valid accuracy: 0.5574503540992737
epoch: 34, steps: 35088, lr: 4.10e-04 - train loss: 9.27e+03 - valid loss: 1.50e+03, valid accuracy: 0.5606652498245239
epoch: 35, steps: 36120, lr: 4.08e-04 - train loss: 9.18e+03 - valid loss: 1.50e+03, valid accuracy: 0.5601680278778076
epoch: 36, steps: 37152, lr: 4.06e-04 - train loss: 9.15e+03 - valid loss: 1.48e+03, valid accuracy: 0.5656757950782776
epoch: 37, steps: 38184, lr: 4.04e-04 - train loss: 9.12e+03 - valid loss: 1.48e+03, valid accuracy: 0.5664849281311035
epoch: 38, steps: 39216, lr: 4.02e-04 - train loss: 9.05e+03 - valid loss: 1.46e+03, valid accuracy: 0.5694761872291565
epoch: 39, steps: 40248, lr: 4.00e-04 - train loss: 9.02e+03 - valid loss: 1.46e+03, valid accuracy: 0.5709752440452576
epoch: 40, steps: 41280, lr: 3.98e-04 - train loss: 8.98e+03 - valid loss: 1.46e+03, valid accuracy: 0.5692022442817688
epoch: 41, steps: 42312, lr: 3.96e-04 - train loss: 8.92e+03 - valid loss: 1.45e+03, valid accuracy: 0.5713870525360107
epoch: 42, steps: 43344, lr: 3.94e-04 - train loss: 8.91e+03 - valid loss: 1.44e+03, valid accuracy: 0.5774747729301453
epoch: 43, steps: 44376, lr: 3.92e-04 - train loss: 8.87e+03 - valid loss: 1.44e+03, valid accuracy: 0.5772039890289307
epoch: 44, steps: 45408, lr: 3.90e-04 - train loss: 8.82e+03 - valid loss: 1.41e+03, valid accuracy: 0.5856547355651855
epoch: 45, steps: 46440, lr: 3.88e-04 - train loss: 8.79e+03 - valid loss: 1.41e+03, valid accuracy: 0.5848395228385925
epoch: 46, steps: 47472, lr: 3.87e-04 - train loss: 8.75e+03 - valid loss: 1.41e+03, valid accuracy: 0.5837655663490295
epoch: 47, steps: 48504, lr: 3.85e-04 - train loss: 8.73e+03 - valid loss: 1.41e+03, valid accuracy: 0.5868180990219116
