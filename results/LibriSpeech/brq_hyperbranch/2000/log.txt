2023-12-01 23:17:49,754 - speechbrain.core - INFO - Beginning experiment!
2023-12-01 23:17:49,755 - speechbrain.core - INFO - Experiment folder: results/LibriSpeech/brq_hyperbranch/2000
2023-12-01 23:17:50,405 - speechbrain.utils.superpowers - DEBUG - appdirs==1.4.4
attrs==23.1.0
black==19.10b0
certifi==2023.11.17
cfgv==3.4.0
charset-normalizer==3.3.2
click==8.0.4
cmake==3.27.7
distlib==0.3.7
entrypoints==0.3
filelock==3.13.1
flake8==3.7.9
fsspec==2023.10.0
huggingface-hub==0.19.4
HyperPyYAML==1.2.2
identify==2.5.32
idna==3.6
iniconfig==2.0.0
Jinja2==3.1.2
joblib==1.3.2
lit==17.0.6
MarkupSafe==2.1.3
mccabe==0.6.1
mpmath==1.3.0
networkx==3.2.1
nodeenv==1.8.0
numpy==1.26.2
nvidia-cublas-cu11==11.10.3.66
nvidia-cublas-cu12==12.1.3.1
nvidia-cuda-cupti-cu11==11.7.101
nvidia-cuda-cupti-cu12==12.1.105
nvidia-cuda-nvrtc-cu11==11.7.99
nvidia-cuda-nvrtc-cu12==12.1.105
nvidia-cuda-runtime-cu11==11.7.99
nvidia-cuda-runtime-cu12==12.1.105
nvidia-cudnn-cu11==8.5.0.96
nvidia-cudnn-cu12==8.9.2.26
nvidia-cufft-cu11==10.9.0.58
nvidia-cufft-cu12==11.0.2.54
nvidia-curand-cu11==10.2.10.91
nvidia-curand-cu12==10.3.2.106
nvidia-cusolver-cu11==11.4.0.1
nvidia-cusolver-cu12==11.4.5.107
nvidia-cusparse-cu11==11.7.4.91
nvidia-cusparse-cu12==12.1.0.106
nvidia-nccl-cu11==2.14.3
nvidia-nccl-cu12==2.18.1
nvidia-nvjitlink-cu12==12.3.101
nvidia-nvtx-cu11==11.7.91
nvidia-nvtx-cu12==12.1.105
packaging==23.2
pandas==2.1.3
pathspec==0.11.2
platformdirs==4.0.0
pluggy==1.3.0
pre-commit==3.5.0
pycodestyle==2.5.0
pyflakes==2.1.1
pytest==7.4.0
python-dateutil==2.8.2
pytz==2023.3.post1
PyYAML==6.0.1
regex==2023.10.3
requests==2.31.0
ruamel.yaml==0.18.5
ruamel.yaml.clib==0.2.8
safetensors==0.4.1
scipy==1.11.4
sentencepiece==0.1.99
six==1.16.0
-e git+https://github.com/whettenr/speechbrain.git@b545d914c7e1677cae6d8fe030a00f7594b78475#egg=speechbrain
sympy==1.12
tokenizers==0.15.0
toml==0.10.2
torch==2.0.1
torchaudio==2.0.2
tqdm==4.66.1
transformers==4.35.2
triton==2.0.0
typed-ast==1.5.5
typing_extensions==4.8.0
tzdata==2023.3
urllib3==2.1.0
virtualenv==20.24.7
yamllint==1.23.0


2023-12-01 23:17:50,420 - speechbrain.utils.superpowers - DEBUG - b938680


2023-12-01 23:17:50,848 - speechbrain.dataio.encoder - DEBUG - Would load categorical encoding from results/LibriSpeech/brq_hyperbranch/2000/save/label_encoder.txt, but file doesn't exist yet.
2023-12-01 23:17:51,330 - speechbrain.dataio.encoder - INFO - Moving label 'T' from index 0, because '<blank>' was put at its place.
2023-12-01 23:17:51,332 - speechbrain.dataio.encoder - INFO - Load called, but CTCTextEncoder is not empty. Loaded data will overwrite everything. This is normal if there is e.g. an unk label defined at init.
2023-12-01 23:17:51,335 - speechbrain.dataio.encoder - DEBUG - Loaded categorical encoding from results/LibriSpeech/brq_hyperbranch/2000/save/label_encoder.txt
2023-12-01 23:17:51,336 - speechbrain.core - INFO - Info: auto_mix_prec arg from hparam file is used
2023-12-01 23:17:51,339 - speechbrain.core - INFO - Info: ckpt_interval_minutes arg from hparam file is used
2023-12-01 23:17:53,494 - speechbrain.core - INFO - 42.1M trainable parameters in ASR
2023-12-01 23:17:53,495 - speechbrain.utils.parameter_transfer - DEBUG - Collecting files (or symlinks) for pretraining in results/LibriSpeech/brq_hyperbranch/2000/save.
2023-12-01 23:17:53,522 - speechbrain.pretrained.fetching - INFO - Destination model.ckpt: local file in /gpfswork/rech/nkp/uaj64gk/bestrqexp/jz/brqhb/CKPT+2023-12-01+16-26-37+00/model.ckpt.
2023-12-01 23:17:53,534 - speechbrain.utils.parameter_transfer - INFO - Set local path in self.paths[weighted_ssl_model] = results/LibriSpeech/brq_hyperbranch/2000/save/weighted_ssl_model.ckpt
2023-12-01 23:17:53,534 - speechbrain.pretrained.fetching - INFO - Destination normalizer.ckpt: local file in /gpfswork/rech/nkp/uaj64gk/bestrqexp/jz/brqhb/CKPT+2023-12-01+16-26-37+00/normalizer.ckpt.
2023-12-01 23:17:53,542 - speechbrain.utils.parameter_transfer - INFO - Set local path in self.paths[normalize] = results/LibriSpeech/brq_hyperbranch/2000/save/normalize.ckpt
2023-12-01 23:17:53,554 - speechbrain.utils.parameter_transfer - INFO - Loading pretrained files for: weighted_ssl_model, normalize
2023-12-01 23:17:53,554 - speechbrain.utils.parameter_transfer - INFO - Redirecting (loading from local path): results/LibriSpeech/brq_hyperbranch/2000/save/weighted_ssl_model.ckpt -> results/LibriSpeech/brq_hyperbranch/2000/save/weighted_ssl_model.ckpt
2023-12-01 23:17:53,556 - speechbrain.utils.parameter_transfer - INFO - Redirecting (loading from local path): results/LibriSpeech/brq_hyperbranch/2000/save/normalize.ckpt -> results/LibriSpeech/brq_hyperbranch/2000/save/normalize.ckpt
2023-12-01 23:17:54,909 - speechbrain.core - ERROR - Exception:
Traceback (most recent call last):
  File "/gpfswork/rech/nkp/uaj64gk/bestrqexp/benchmark/benchmarks/MP3S/LibriSpeech/LSTM/train_brq.py", line 371, in <module>
    hparams["pretrainer"].load_collected(asr_brain.device)
  File "/gpfsdswork/projects/rech/nkp/uaj64gk/bestrqexp/speechbrain/speechbrain/utils/parameter_transfer.py", line 314, in load_collected
    self._call_load_hooks(paramfiles, device)
  File "/gpfsdswork/projects/rech/nkp/uaj64gk/bestrqexp/speechbrain/speechbrain/utils/parameter_transfer.py", line 331, in _call_load_hooks
    default_hook(obj, loadpath, device=device)
  File "/gpfsdswork/projects/rech/nkp/uaj64gk/bestrqexp/speechbrain/speechbrain/utils/checkpoints.py", line 150, in torch_parameter_transfer
    incompatible_keys = obj.load_state_dict(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/linkhome/rech/genzjn01/uaj64gk/.local/lib/python3.11/site-packages/torch/nn/modules/module.py", line 2041, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for ModuleList:
	size mismatch for 1.transformer.custom_tgt_module.layers.0.emb.Embedding.weight: copying a param with shape torch.Size([5000, 512]) from checkpoint, the shape in current model is torch.Size([30, 512]).
2023-12-02 09:23:18,762 - speechbrain.core - INFO - Beginning experiment!
2023-12-02 09:23:18,784 - speechbrain.core - INFO - Experiment folder: results/LibriSpeech/brq_hyperbranch/2000
2023-12-02 09:23:21,971 - speechbrain.utils.superpowers - DEBUG - appdirs==1.4.4
attrs==23.1.0
black==19.10b0
certifi==2023.11.17
cfgv==3.4.0
charset-normalizer==3.3.2
click==8.0.4
cmake==3.27.7
distlib==0.3.7
entrypoints==0.3
filelock==3.13.1
flake8==3.7.9
fsspec==2023.10.0
huggingface-hub==0.19.4
HyperPyYAML==1.2.2
identify==2.5.32
idna==3.6
iniconfig==2.0.0
Jinja2==3.1.2
joblib==1.3.2
lit==17.0.6
MarkupSafe==2.1.3
mccabe==0.6.1
mpmath==1.3.0
networkx==3.2.1
nodeenv==1.8.0
numpy==1.26.2
nvidia-cublas-cu11==11.10.3.66
nvidia-cublas-cu12==12.1.3.1
nvidia-cuda-cupti-cu11==11.7.101
nvidia-cuda-cupti-cu12==12.1.105
nvidia-cuda-nvrtc-cu11==11.7.99
nvidia-cuda-nvrtc-cu12==12.1.105
nvidia-cuda-runtime-cu11==11.7.99
nvidia-cuda-runtime-cu12==12.1.105
nvidia-cudnn-cu11==8.5.0.96
nvidia-cudnn-cu12==8.9.2.26
nvidia-cufft-cu11==10.9.0.58
nvidia-cufft-cu12==11.0.2.54
nvidia-curand-cu11==10.2.10.91
nvidia-curand-cu12==10.3.2.106
nvidia-cusolver-cu11==11.4.0.1
nvidia-cusolver-cu12==11.4.5.107
nvidia-cusparse-cu11==11.7.4.91
nvidia-cusparse-cu12==12.1.0.106
nvidia-nccl-cu11==2.14.3
nvidia-nccl-cu12==2.18.1
nvidia-nvjitlink-cu12==12.3.101
nvidia-nvtx-cu11==11.7.91
nvidia-nvtx-cu12==12.1.105
packaging==23.2
pandas==2.1.3
pathspec==0.11.2
platformdirs==4.0.0
pluggy==1.3.0
pre-commit==3.5.0
pycodestyle==2.5.0
pyflakes==2.1.1
pytest==7.4.0
python-dateutil==2.8.2
pytz==2023.3.post1
PyYAML==6.0.1
regex==2023.10.3
requests==2.31.0
ruamel.yaml==0.18.5
ruamel.yaml.clib==0.2.8
safetensors==0.4.1
scipy==1.11.4
sentencepiece==0.1.99
six==1.16.0
-e git+https://github.com/whettenr/speechbrain.git@b545d914c7e1677cae6d8fe030a00f7594b78475#egg=speechbrain
sympy==1.12
tokenizers==0.15.0
toml==0.10.2
torch==2.0.1
torchaudio==2.0.2
tqdm==4.66.1
transformers==4.35.2
triton==2.0.0
typed-ast==1.5.5
typing_extensions==4.8.0
tzdata==2023.3
urllib3==2.1.0
virtualenv==20.24.7
yamllint==1.23.0


2023-12-02 09:23:22,000 - speechbrain.utils.superpowers - DEBUG - 51e9a7c


2023-12-02 09:23:22,537 - speechbrain.dataio.encoder - DEBUG - Loaded categorical encoding from results/LibriSpeech/brq_hyperbranch/2000/save/label_encoder.txt
2023-12-02 09:23:22,538 - speechbrain.dataio.encoder - INFO - Load called, but CTCTextEncoder is not empty. Loaded data will overwrite everything. This is normal if there is e.g. an unk label defined at init.
2023-12-02 09:23:22,538 - speechbrain.dataio.encoder - DEBUG - Loaded categorical encoding from results/LibriSpeech/brq_hyperbranch/2000/save/label_encoder.txt
2023-12-02 09:23:22,538 - speechbrain.core - INFO - Info: auto_mix_prec arg from hparam file is used
2023-12-02 09:23:22,538 - speechbrain.core - INFO - Info: ckpt_interval_minutes arg from hparam file is used
2023-12-02 09:23:30,381 - speechbrain.core - INFO - 42.1M trainable parameters in ASR
2023-12-02 09:23:30,382 - speechbrain.utils.parameter_transfer - DEBUG - Collecting files (or symlinks) for pretraining in results/LibriSpeech/brq_hyperbranch/2000/save.
2023-12-02 09:23:30,391 - speechbrain.pretrained.fetching - INFO - Fetch model.ckpt: Using existing file/symlink in results/LibriSpeech/brq_hyperbranch/2000/save/weighted_ssl_model.ckpt.
2023-12-02 09:23:30,391 - speechbrain.utils.parameter_transfer - INFO - Set local path in self.paths[weighted_ssl_model] = results/LibriSpeech/brq_hyperbranch/2000/save/weighted_ssl_model.ckpt
2023-12-02 09:23:30,401 - speechbrain.pretrained.fetching - INFO - Fetch normalizer.ckpt: Using existing file/symlink in results/LibriSpeech/brq_hyperbranch/2000/save/normalize.ckpt.
2023-12-02 09:23:30,402 - speechbrain.utils.parameter_transfer - INFO - Set local path in self.paths[normalize] = results/LibriSpeech/brq_hyperbranch/2000/save/normalize.ckpt
2023-12-02 09:23:30,402 - speechbrain.utils.parameter_transfer - INFO - Loading pretrained files for: weighted_ssl_model, normalize
2023-12-02 09:23:30,402 - speechbrain.utils.parameter_transfer - INFO - Redirecting (loading from local path): results/LibriSpeech/brq_hyperbranch/2000/save/weighted_ssl_model.ckpt -> results/LibriSpeech/brq_hyperbranch/2000/save/weighted_ssl_model.ckpt
2023-12-02 09:23:30,402 - speechbrain.utils.parameter_transfer - INFO - Redirecting (loading from local path): results/LibriSpeech/brq_hyperbranch/2000/save/normalize.ckpt -> results/LibriSpeech/brq_hyperbranch/2000/save/normalize.ckpt
2023-12-02 09:23:31,669 - speechbrain.utils.checkpoints - WARNING - During parameter transfer to ModuleList(
  (0): ConvolutionFrontEnd(
    (convblock_0): ConvBlock(
      (convs): Sequential(
        (conv_0): Conv2d(
          (conv): Conv2d(1, 128, kernel_size=(3, 3), stride=(2, 2))
        )
        (norm_0): LayerNorm(
          (norm): LayerNorm((40, 128), eps=1e-05, elementwise_affine=True)
        )
        (act_0): LeakyReLU(negative_slope=0.01)
        (dropout_0): Dropout(p=0.1, inplace=False)
      )
    )
    (convblock_1): ConvBlock(
      (convs): Sequential(
        (conv_0): Conv2d(
          (conv): Conv2d(128, 32, kernel_size=(3, 3), stride=(2, 2))
        )
        (norm_0): LayerNorm(
          (norm): LayerNorm((20, 32), eps=1e-05, elementwise_affine=True)
        )
        (act_0): LeakyReLU(negative_slope=0.01)
        (dropout_0): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (1): WeightedEncoderWrapper(
    (transformer): TransformerASR(
      (positional_encoding): PositionalEncoding()
      (encoder): BranchformerEncoder(
        (layers): ModuleList(
          (0-11): 12 x BranchformerEncoderLayer(
            (mha_layer): HyperMixing(
              (hyper): HyperNetwork(
                (w1_gen): ParallelMLPs(
                  (activation): GELU(approximate='none')
                )
                (w2_gen): ParallelMLPs(
                  (activation): GELU(approximate='none')
                )
              )
              (activation): GELU(approximate='none')
              (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (positional_encoding): PositionalEncoding()
            )
            (convolution_branch): ConvolutionBranch(
              (pre_channel_proj): Linear(in_features=512, out_features=3072, bias=True)
              (post_channel_proj): Linear(in_features=1536, out_features=512, bias=True)
              (activation): GELU(approximate='none')
              (csgu): ConvolutionalSpatialGatingUnit(
                (activation): Identity()
                (norm): LayerNorm(
                  (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
                )
                (conv): Conv1d(
                  (conv): Conv1d(1536, 1536, kernel_size=(31,), stride=(1,), groups=1536)
                )
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (merge_proj): Linear(in_features=1024, out_features=512, bias=True)
            (norm_mhsa): LayerNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (norm_conv): LayerNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (norm): LayerNorm(
          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        )
      )
      (custom_src_module): ModuleList(
        (layers): ModuleList(
          (0): Linear(
            (w): Linear(in_features=640, out_features=512, bias=True)
          )
          (1): Dropout(p=0.1, inplace=False)
        )
      )
      (custom_tgt_module): ModuleList(
        (layers): ModuleList(
          (0): NormalizedEmbedding(
            (emb): Embedding(
              (Embedding): Embedding(5000, 512)
            )
          )
        )
      )
    )
  )
  (2): RandomProjectionQuantizer()
  (3): Linear(
    (w): Linear(in_features=512, out_features=8192, bias=True)
  )
) loading from results/LibriSpeech/brq_hyperbranch/2000/save/weighted_ssl_model.ckpt, the transferred parameters did not have parameters for the key: 1.weights
2023-12-02 09:23:31,676 - speechbrain.utils.checkpoints - INFO - Would load a checkpoint here, but none found yet.
2023-12-02 09:23:31,676 - speechbrain.utils.epoch_loop - INFO - Going into epoch 1
2023-12-02 09:24:53,254 - speechbrain.core - ERROR - Exception:
Traceback (most recent call last):
  File "/gpfswork/rech/nkp/uaj64gk/bestrqexp/benchmark/benchmarks/MP3S/LibriSpeech/LSTM/train_brq.py", line 376, in <module>
    asr_brain.fit(
  File "/gpfsdswork/projects/rech/nkp/uaj64gk/bestrqexp/speechbrain/speechbrain/core.py", line 1366, in fit
    self._fit_train(train_set=train_set, epoch=epoch, enable=enable)
  File "/gpfsdswork/projects/rech/nkp/uaj64gk/bestrqexp/speechbrain/speechbrain/core.py", line 1187, in _fit_train
    for batch in t:
  File "/linkhome/rech/genzjn01/uaj64gk/.local/lib/python3.11/site-packages/tqdm/std.py", line 1182, in __iter__
    for obj in iterable:
  File "/linkhome/rech/genzjn01/uaj64gk/.local/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 633, in __next__
    data = self._next_data()
           ^^^^^^^^^^^^^^^^^
  File "/linkhome/rech/genzjn01/uaj64gk/.local/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 677, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/linkhome/rech/genzjn01/uaj64gk/.local/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/linkhome/rech/genzjn01/uaj64gk/.local/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
            ~~~~~~~~~~~~^^^^^
  File "/gpfsdswork/projects/rech/nkp/uaj64gk/bestrqexp/speechbrain/speechbrain/dataio/dataset.py", line 167, in __getitem__
    return self.pipeline.compute_outputs({"id": data_id, **data_point})
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfsdswork/projects/rech/nkp/uaj64gk/bestrqexp/speechbrain/speechbrain/utils/data_pipeline.py", line 464, in compute_outputs
    return self._compute(data, self._exec_order, self.output_mapping)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfsdswork/projects/rech/nkp/uaj64gk/bestrqexp/speechbrain/speechbrain/utils/data_pipeline.py", line 496, in _compute
    values = item(*args)  # Call the DynamicItem to produce output
             ^^^^^^^^^^^
  File "/gpfsdswork/projects/rech/nkp/uaj64gk/bestrqexp/speechbrain/speechbrain/utils/data_pipeline.py", line 72, in __call__
    return self.func(*args)
           ^^^^^^^^^^^^^^^^
  File "/gpfswork/rech/nkp/uaj64gk/bestrqexp/benchmark/benchmarks/MP3S/LibriSpeech/LSTM/train_brq.py", line 247, in audio_pipeline
    sig = sb.dataio.dataio.read_audio(wav)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfsdswork/projects/rech/nkp/uaj64gk/bestrqexp/speechbrain/speechbrain/dataio/dataio.py", line 275, in read_audio
    audio, _ = torchaudio.load(waveforms_obj)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/linkhome/rech/genzjn01/uaj64gk/.local/lib/python3.11/site-packages/torchaudio/backend/sox_io_backend.py", line 251, in load
    ret = torch.ops.torchaudio.sox_io_load_audio_file(
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/linkhome/rech/genzjn01/uaj64gk/.local/lib/python3.11/site-packages/torch/_ops.py", line 502, in __call__
    return self._op(*args, **kwargs or {})
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
2023-12-02 09:25:12,312 - speechbrain.core - INFO - Beginning experiment!
2023-12-02 09:25:12,312 - speechbrain.core - INFO - Experiment folder: results/LibriSpeech/brq_hyperbranch/2000
2023-12-02 09:25:12,934 - speechbrain.utils.superpowers - DEBUG - appdirs==1.4.4
attrs==23.1.0
black==19.10b0
certifi==2023.11.17
cfgv==3.4.0
charset-normalizer==3.3.2
click==8.0.4
cmake==3.27.7
distlib==0.3.7
entrypoints==0.3
filelock==3.13.1
flake8==3.7.9
fsspec==2023.10.0
huggingface-hub==0.19.4
HyperPyYAML==1.2.2
identify==2.5.32
idna==3.6
iniconfig==2.0.0
Jinja2==3.1.2
joblib==1.3.2
lit==17.0.6
MarkupSafe==2.1.3
mccabe==0.6.1
mpmath==1.3.0
networkx==3.2.1
nodeenv==1.8.0
numpy==1.26.2
nvidia-cublas-cu11==11.10.3.66
nvidia-cublas-cu12==12.1.3.1
nvidia-cuda-cupti-cu11==11.7.101
nvidia-cuda-cupti-cu12==12.1.105
nvidia-cuda-nvrtc-cu11==11.7.99
nvidia-cuda-nvrtc-cu12==12.1.105
nvidia-cuda-runtime-cu11==11.7.99
nvidia-cuda-runtime-cu12==12.1.105
nvidia-cudnn-cu11==8.5.0.96
nvidia-cudnn-cu12==8.9.2.26
nvidia-cufft-cu11==10.9.0.58
nvidia-cufft-cu12==11.0.2.54
nvidia-curand-cu11==10.2.10.91
nvidia-curand-cu12==10.3.2.106
nvidia-cusolver-cu11==11.4.0.1
nvidia-cusolver-cu12==11.4.5.107
nvidia-cusparse-cu11==11.7.4.91
nvidia-cusparse-cu12==12.1.0.106
nvidia-nccl-cu11==2.14.3
nvidia-nccl-cu12==2.18.1
nvidia-nvjitlink-cu12==12.3.101
nvidia-nvtx-cu11==11.7.91
nvidia-nvtx-cu12==12.1.105
packaging==23.2
pandas==2.1.3
pathspec==0.11.2
platformdirs==4.0.0
pluggy==1.3.0
pre-commit==3.5.0
pycodestyle==2.5.0
pyflakes==2.1.1
pytest==7.4.0
python-dateutil==2.8.2
pytz==2023.3.post1
PyYAML==6.0.1
regex==2023.10.3
requests==2.31.0
ruamel.yaml==0.18.5
ruamel.yaml.clib==0.2.8
safetensors==0.4.1
scipy==1.11.4
sentencepiece==0.1.99
six==1.16.0
-e git+https://github.com/whettenr/speechbrain.git@b545d914c7e1677cae6d8fe030a00f7594b78475#egg=speechbrain
sympy==1.12
tokenizers==0.15.0
toml==0.10.2
torch==2.0.1
torchaudio==2.0.2
tqdm==4.66.1
transformers==4.35.2
triton==2.0.0
typed-ast==1.5.5
typing_extensions==4.8.0
tzdata==2023.3
urllib3==2.1.0
virtualenv==20.24.7
yamllint==1.23.0


2023-12-02 09:25:12,948 - speechbrain.utils.superpowers - DEBUG - 51e9a7c


2023-12-02 09:25:13,402 - speechbrain.dataio.encoder - DEBUG - Loaded categorical encoding from results/LibriSpeech/brq_hyperbranch/2000/save/label_encoder.txt
2023-12-02 09:25:13,402 - speechbrain.dataio.encoder - INFO - Load called, but CTCTextEncoder is not empty. Loaded data will overwrite everything. This is normal if there is e.g. an unk label defined at init.
2023-12-02 09:25:13,402 - speechbrain.dataio.encoder - DEBUG - Loaded categorical encoding from results/LibriSpeech/brq_hyperbranch/2000/save/label_encoder.txt
2023-12-02 09:25:13,403 - speechbrain.core - INFO - Info: auto_mix_prec arg from hparam file is used
2023-12-02 09:25:13,403 - speechbrain.core - INFO - Info: ckpt_interval_minutes arg from hparam file is used
2023-12-02 09:25:15,445 - speechbrain.core - INFO - 42.1M trainable parameters in ASR
2023-12-02 09:25:15,445 - speechbrain.utils.parameter_transfer - DEBUG - Collecting files (or symlinks) for pretraining in results/LibriSpeech/brq_hyperbranch/2000/save.
2023-12-02 09:25:15,445 - speechbrain.pretrained.fetching - INFO - Fetch model.ckpt: Using existing file/symlink in results/LibriSpeech/brq_hyperbranch/2000/save/weighted_ssl_model.ckpt.
2023-12-02 09:25:15,446 - speechbrain.utils.parameter_transfer - INFO - Set local path in self.paths[weighted_ssl_model] = results/LibriSpeech/brq_hyperbranch/2000/save/weighted_ssl_model.ckpt
2023-12-02 09:25:15,446 - speechbrain.pretrained.fetching - INFO - Fetch normalizer.ckpt: Using existing file/symlink in results/LibriSpeech/brq_hyperbranch/2000/save/normalize.ckpt.
2023-12-02 09:25:15,447 - speechbrain.utils.parameter_transfer - INFO - Set local path in self.paths[normalize] = results/LibriSpeech/brq_hyperbranch/2000/save/normalize.ckpt
2023-12-02 09:25:15,447 - speechbrain.utils.parameter_transfer - INFO - Loading pretrained files for: weighted_ssl_model, normalize
2023-12-02 09:25:15,447 - speechbrain.utils.parameter_transfer - INFO - Redirecting (loading from local path): results/LibriSpeech/brq_hyperbranch/2000/save/weighted_ssl_model.ckpt -> results/LibriSpeech/brq_hyperbranch/2000/save/weighted_ssl_model.ckpt
2023-12-02 09:25:15,447 - speechbrain.utils.parameter_transfer - INFO - Redirecting (loading from local path): results/LibriSpeech/brq_hyperbranch/2000/save/normalize.ckpt -> results/LibriSpeech/brq_hyperbranch/2000/save/normalize.ckpt
2023-12-02 09:25:16,611 - speechbrain.utils.checkpoints - WARNING - During parameter transfer to ModuleList(
  (0): ConvolutionFrontEnd(
    (convblock_0): ConvBlock(
      (convs): Sequential(
        (conv_0): Conv2d(
          (conv): Conv2d(1, 128, kernel_size=(3, 3), stride=(2, 2))
        )
        (norm_0): LayerNorm(
          (norm): LayerNorm((40, 128), eps=1e-05, elementwise_affine=True)
        )
        (act_0): LeakyReLU(negative_slope=0.01)
        (dropout_0): Dropout(p=0.1, inplace=False)
      )
    )
    (convblock_1): ConvBlock(
      (convs): Sequential(
        (conv_0): Conv2d(
          (conv): Conv2d(128, 32, kernel_size=(3, 3), stride=(2, 2))
        )
        (norm_0): LayerNorm(
          (norm): LayerNorm((20, 32), eps=1e-05, elementwise_affine=True)
        )
        (act_0): LeakyReLU(negative_slope=0.01)
        (dropout_0): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (1): WeightedEncoderWrapper(
    (transformer): TransformerASR(
      (positional_encoding): PositionalEncoding()
      (encoder): BranchformerEncoder(
        (layers): ModuleList(
          (0-11): 12 x BranchformerEncoderLayer(
            (mha_layer): HyperMixing(
              (hyper): HyperNetwork(
                (w1_gen): ParallelMLPs(
                  (activation): GELU(approximate='none')
                )
                (w2_gen): ParallelMLPs(
                  (activation): GELU(approximate='none')
                )
              )
              (activation): GELU(approximate='none')
              (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (positional_encoding): PositionalEncoding()
            )
            (convolution_branch): ConvolutionBranch(
              (pre_channel_proj): Linear(in_features=512, out_features=3072, bias=True)
              (post_channel_proj): Linear(in_features=1536, out_features=512, bias=True)
              (activation): GELU(approximate='none')
              (csgu): ConvolutionalSpatialGatingUnit(
                (activation): Identity()
                (norm): LayerNorm(
                  (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
                )
                (conv): Conv1d(
                  (conv): Conv1d(1536, 1536, kernel_size=(31,), stride=(1,), groups=1536)
                )
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (merge_proj): Linear(in_features=1024, out_features=512, bias=True)
            (norm_mhsa): LayerNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (norm_conv): LayerNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (norm): LayerNorm(
          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        )
      )
      (custom_src_module): ModuleList(
        (layers): ModuleList(
          (0): Linear(
            (w): Linear(in_features=640, out_features=512, bias=True)
          )
          (1): Dropout(p=0.1, inplace=False)
        )
      )
      (custom_tgt_module): ModuleList(
        (layers): ModuleList(
          (0): NormalizedEmbedding(
            (emb): Embedding(
              (Embedding): Embedding(5000, 512)
            )
          )
        )
      )
    )
  )
  (2): RandomProjectionQuantizer()
  (3): Linear(
    (w): Linear(in_features=512, out_features=8192, bias=True)
  )
) loading from results/LibriSpeech/brq_hyperbranch/2000/save/weighted_ssl_model.ckpt, the transferred parameters did not have parameters for the key: 1.weights
2023-12-02 09:25:16,614 - speechbrain.utils.checkpoints - INFO - Would load a checkpoint here, but none found yet.
2023-12-02 09:25:16,614 - speechbrain.utils.epoch_loop - INFO - Going into epoch 1
2023-12-02 09:26:21,747 - speechbrain.core - ERROR - Exception:
Traceback (most recent call last):
  File "/gpfswork/rech/nkp/uaj64gk/bestrqexp/benchmark/benchmarks/MP3S/LibriSpeech/LSTM/train_brq.py", line 376, in <module>
    asr_brain.fit(
  File "/gpfsdswork/projects/rech/nkp/uaj64gk/bestrqexp/speechbrain/speechbrain/core.py", line 1366, in fit
    self._fit_train(train_set=train_set, epoch=epoch, enable=enable)
  File "/gpfsdswork/projects/rech/nkp/uaj64gk/bestrqexp/speechbrain/speechbrain/core.py", line 1193, in _fit_train
    loss = self.fit_batch(batch)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/gpfswork/rech/nkp/uaj64gk/bestrqexp/benchmark/benchmarks/MP3S/LibriSpeech/LSTM/train_brq.py", line 92, in fit_batch
    loss.backward()
  File "/linkhome/rech/genzjn01/uaj64gk/.local/lib/python3.11/site-packages/torch/_tensor.py", line 487, in backward
    torch.autograd.backward(
  File "/linkhome/rech/genzjn01/uaj64gk/.local/lib/python3.11/site-packages/torch/autograd/__init__.py", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
2023-12-02 09:28:10,510 - speechbrain.core - INFO - Beginning experiment!
2023-12-02 09:28:10,551 - speechbrain.core - INFO - Experiment folder: results/LibriSpeech/brq_hyperbranch/2000
2023-12-02 09:28:13,928 - speechbrain.utils.superpowers - DEBUG - appdirs==1.4.4
attrs==23.1.0
black==19.10b0
certifi==2023.11.17
cfgv==3.4.0
charset-normalizer==3.3.2
click==8.0.4
cmake==3.27.7
distlib==0.3.7
entrypoints==0.3
filelock==3.13.1
flake8==3.7.9
fsspec==2023.10.0
huggingface-hub==0.19.4
HyperPyYAML==1.2.2
identify==2.5.32
idna==3.6
iniconfig==2.0.0
Jinja2==3.1.2
joblib==1.3.2
lit==17.0.6
MarkupSafe==2.1.3
mccabe==0.6.1
mpmath==1.3.0
networkx==3.2.1
nodeenv==1.8.0
numpy==1.26.2
nvidia-cublas-cu11==11.10.3.66
nvidia-cublas-cu12==12.1.3.1
nvidia-cuda-cupti-cu11==11.7.101
nvidia-cuda-cupti-cu12==12.1.105
nvidia-cuda-nvrtc-cu11==11.7.99
nvidia-cuda-nvrtc-cu12==12.1.105
nvidia-cuda-runtime-cu11==11.7.99
nvidia-cuda-runtime-cu12==12.1.105
nvidia-cudnn-cu11==8.5.0.96
nvidia-cudnn-cu12==8.9.2.26
nvidia-cufft-cu11==10.9.0.58
nvidia-cufft-cu12==11.0.2.54
nvidia-curand-cu11==10.2.10.91
nvidia-curand-cu12==10.3.2.106
nvidia-cusolver-cu11==11.4.0.1
nvidia-cusolver-cu12==11.4.5.107
nvidia-cusparse-cu11==11.7.4.91
nvidia-cusparse-cu12==12.1.0.106
nvidia-nccl-cu11==2.14.3
nvidia-nccl-cu12==2.18.1
nvidia-nvjitlink-cu12==12.3.101
nvidia-nvtx-cu11==11.7.91
nvidia-nvtx-cu12==12.1.105
packaging==23.2
pandas==2.1.3
pathspec==0.11.2
platformdirs==4.0.0
pluggy==1.3.0
pre-commit==3.5.0
pycodestyle==2.5.0
pyflakes==2.1.1
pytest==7.4.0
python-dateutil==2.8.2
pytz==2023.3.post1
PyYAML==6.0.1
regex==2023.10.3
requests==2.31.0
ruamel.yaml==0.18.5
ruamel.yaml.clib==0.2.8
safetensors==0.4.1
scipy==1.11.4
sentencepiece==0.1.99
six==1.16.0
-e /gpfsdswork/projects/rech/nkp/uaj64gk/bestrqexp/speechbrain
sympy==1.12
tokenizers==0.15.0
toml==0.10.2
torch==2.0.1
torchaudio==2.0.2
tqdm==4.66.1
transformers==4.35.2
triton==2.0.0
typed-ast==1.5.5
typing_extensions==4.8.0
tzdata==2023.3
urllib3==2.1.0
virtualenv==20.24.7
yamllint==1.23.0

ERROR: Error [Errno 2] No such file or directory: 'git' while executing command git config --get-regexp 'remote\..*\.url'
WARNING: cannot determine version of editable source in /gpfsdswork/projects/rech/nkp/uaj64gk/bestrqexp/speechbrain (git command not found in path)

2023-12-02 09:28:14,655 - speechbrain.dataio.encoder - DEBUG - Loaded categorical encoding from results/LibriSpeech/brq_hyperbranch/2000/save/label_encoder.txt
2023-12-02 09:28:14,655 - speechbrain.dataio.encoder - INFO - Load called, but CTCTextEncoder is not empty. Loaded data will overwrite everything. This is normal if there is e.g. an unk label defined at init.
2023-12-02 09:28:14,656 - speechbrain.dataio.encoder - DEBUG - Loaded categorical encoding from results/LibriSpeech/brq_hyperbranch/2000/save/label_encoder.txt
2023-12-02 09:28:14,656 - speechbrain.core - INFO - Info: auto_mix_prec arg from hparam file is used
2023-12-02 09:28:14,656 - speechbrain.core - INFO - Info: ckpt_interval_minutes arg from hparam file is used
2023-12-02 09:28:20,702 - speechbrain.core - INFO - 42.1M trainable parameters in ASR
2023-12-02 09:28:20,702 - speechbrain.utils.parameter_transfer - DEBUG - Collecting files (or symlinks) for pretraining in results/LibriSpeech/brq_hyperbranch/2000/save.
2023-12-02 09:28:20,765 - speechbrain.pretrained.fetching - INFO - Fetch model.ckpt: Using existing file/symlink in results/LibriSpeech/brq_hyperbranch/2000/save/weighted_ssl_model.ckpt.
2023-12-02 09:28:20,766 - speechbrain.utils.parameter_transfer - INFO - Set local path in self.paths[weighted_ssl_model] = results/LibriSpeech/brq_hyperbranch/2000/save/weighted_ssl_model.ckpt
2023-12-02 09:28:20,782 - speechbrain.pretrained.fetching - INFO - Fetch normalizer.ckpt: Using existing file/symlink in results/LibriSpeech/brq_hyperbranch/2000/save/normalize.ckpt.
2023-12-02 09:28:20,783 - speechbrain.utils.parameter_transfer - INFO - Set local path in self.paths[normalize] = results/LibriSpeech/brq_hyperbranch/2000/save/normalize.ckpt
2023-12-02 09:28:20,783 - speechbrain.utils.parameter_transfer - INFO - Loading pretrained files for: weighted_ssl_model, normalize
2023-12-02 09:28:20,783 - speechbrain.utils.parameter_transfer - INFO - Redirecting (loading from local path): results/LibriSpeech/brq_hyperbranch/2000/save/weighted_ssl_model.ckpt -> results/LibriSpeech/brq_hyperbranch/2000/save/weighted_ssl_model.ckpt
2023-12-02 09:28:20,783 - speechbrain.utils.parameter_transfer - INFO - Redirecting (loading from local path): results/LibriSpeech/brq_hyperbranch/2000/save/normalize.ckpt -> results/LibriSpeech/brq_hyperbranch/2000/save/normalize.ckpt
2023-12-02 09:28:21,887 - speechbrain.utils.checkpoints - WARNING - During parameter transfer to ModuleList(
  (0): ConvolutionFrontEnd(
    (convblock_0): ConvBlock(
      (convs): Sequential(
        (conv_0): Conv2d(
          (conv): Conv2d(1, 128, kernel_size=(3, 3), stride=(2, 2))
        )
        (norm_0): LayerNorm(
          (norm): LayerNorm((40, 128), eps=1e-05, elementwise_affine=True)
        )
        (act_0): LeakyReLU(negative_slope=0.01)
        (dropout_0): Dropout(p=0.1, inplace=False)
      )
    )
    (convblock_1): ConvBlock(
      (convs): Sequential(
        (conv_0): Conv2d(
          (conv): Conv2d(128, 32, kernel_size=(3, 3), stride=(2, 2))
        )
        (norm_0): LayerNorm(
          (norm): LayerNorm((20, 32), eps=1e-05, elementwise_affine=True)
        )
        (act_0): LeakyReLU(negative_slope=0.01)
        (dropout_0): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (1): WeightedEncoderWrapper(
    (transformer): TransformerASR(
      (positional_encoding): PositionalEncoding()
      (encoder): BranchformerEncoder(
        (layers): ModuleList(
          (0-11): 12 x BranchformerEncoderLayer(
            (mha_layer): HyperMixing(
              (hyper): HyperNetwork(
                (w1_gen): ParallelMLPs(
                  (activation): GELU(approximate='none')
                )
                (w2_gen): ParallelMLPs(
                  (activation): GELU(approximate='none')
                )
              )
              (activation): GELU(approximate='none')
              (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (positional_encoding): PositionalEncoding()
            )
            (convolution_branch): ConvolutionBranch(
              (pre_channel_proj): Linear(in_features=512, out_features=3072, bias=True)
              (post_channel_proj): Linear(in_features=1536, out_features=512, bias=True)
              (activation): GELU(approximate='none')
              (csgu): ConvolutionalSpatialGatingUnit(
                (activation): Identity()
                (norm): LayerNorm(
                  (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
                )
                (conv): Conv1d(
                  (conv): Conv1d(1536, 1536, kernel_size=(31,), stride=(1,), groups=1536)
                )
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (merge_proj): Linear(in_features=1024, out_features=512, bias=True)
            (norm_mhsa): LayerNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (norm_conv): LayerNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (norm): LayerNorm(
          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        )
      )
      (custom_src_module): ModuleList(
        (layers): ModuleList(
          (0): Linear(
            (w): Linear(in_features=640, out_features=512, bias=True)
          )
          (1): Dropout(p=0.1, inplace=False)
        )
      )
      (custom_tgt_module): ModuleList(
        (layers): ModuleList(
          (0): NormalizedEmbedding(
            (emb): Embedding(
              (Embedding): Embedding(5000, 512)
            )
          )
        )
      )
    )
  )
  (2): RandomProjectionQuantizer()
  (3): Linear(
    (w): Linear(in_features=512, out_features=8192, bias=True)
  )
) loading from results/LibriSpeech/brq_hyperbranch/2000/save/weighted_ssl_model.ckpt, the transferred parameters did not have parameters for the key: 1.weights
2023-12-02 09:28:21,906 - speechbrain.utils.checkpoints - INFO - Would load a checkpoint here, but none found yet.
2023-12-02 09:28:21,907 - speechbrain.utils.epoch_loop - INFO - Going into epoch 1
2023-12-02 09:51:53,426 - speechbrain.utils.train_logger - INFO - epoch: 1, lr_model: 2.00e-04 - train loss: 1.01 - valid loss: 7.33e-01, valid CER: 17.84, valid WER: 54.46
2023-12-02 09:51:56,296 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/LibriSpeech/brq_hyperbranch/2000/save/CKPT+2023-12-02+09-51-53+00
2023-12-02 09:51:56,310 - speechbrain.utils.epoch_loop - INFO - Going into epoch 2
2023-12-02 10:13:29,790 - speechbrain.utils.train_logger - INFO - epoch: 2, lr_model: 2.00e-04 - train loss: 6.61e-01 - valid loss: 6.26e-01, valid CER: 15.64, valid WER: 48.50
2023-12-02 10:13:31,126 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/LibriSpeech/brq_hyperbranch/2000/save/CKPT+2023-12-02+10-13-29+00
2023-12-02 10:13:31,190 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/LibriSpeech/brq_hyperbranch/2000/save/CKPT+2023-12-02+09-51-53+00
2023-12-02 10:13:31,191 - speechbrain.utils.epoch_loop - INFO - Going into epoch 3
2023-12-02 10:34:20,429 - speechbrain.utils.train_logger - INFO - epoch: 3, lr_model: 2.00e-04 - train loss: 5.68e-01 - valid loss: 5.77e-01, valid CER: 14.25, valid WER: 45.01
2023-12-02 10:34:21,374 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/LibriSpeech/brq_hyperbranch/2000/save/CKPT+2023-12-02+10-34-20+00
2023-12-02 10:34:21,387 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/LibriSpeech/brq_hyperbranch/2000/save/CKPT+2023-12-02+10-13-29+00
2023-12-02 10:34:21,388 - speechbrain.utils.epoch_loop - INFO - Going into epoch 4
2023-12-02 10:54:59,057 - speechbrain.utils.train_logger - INFO - epoch: 4, lr_model: 2.00e-04 - train loss: 5.12e-01 - valid loss: 5.53e-01, valid CER: 13.19, valid WER: 42.33
2023-12-02 10:55:00,048 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/LibriSpeech/brq_hyperbranch/2000/save/CKPT+2023-12-02+10-54-59+00
2023-12-02 10:55:00,063 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/LibriSpeech/brq_hyperbranch/2000/save/CKPT+2023-12-02+10-34-20+00
2023-12-02 10:55:00,063 - speechbrain.utils.epoch_loop - INFO - Going into epoch 5
2023-12-02 11:15:37,241 - speechbrain.utils.train_logger - INFO - epoch: 5, lr_model: 2.00e-04 - train loss: 4.71e-01 - valid loss: 5.34e-01, valid CER: 12.87, valid WER: 41.47
2023-12-02 11:15:38,179 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/LibriSpeech/brq_hyperbranch/2000/save/CKPT+2023-12-02+11-15-37+00
2023-12-02 11:15:38,207 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/LibriSpeech/brq_hyperbranch/2000/save/CKPT+2023-12-02+10-54-59+00
2023-12-02 11:15:38,207 - speechbrain.utils.epoch_loop - INFO - Going into epoch 6
2023-12-02 11:36:14,132 - speechbrain.utils.train_logger - INFO - epoch: 6, lr_model: 2.00e-04 - train loss: 4.39e-01 - valid loss: 5.17e-01, valid CER: 12.35, valid WER: 39.91
2023-12-02 11:36:15,212 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/LibriSpeech/brq_hyperbranch/2000/save/CKPT+2023-12-02+11-36-14+00
2023-12-02 11:36:15,230 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/LibriSpeech/brq_hyperbranch/2000/save/CKPT+2023-12-02+11-15-37+00
2023-12-02 11:36:15,230 - speechbrain.utils.epoch_loop - INFO - Going into epoch 7
2023-12-02 11:56:53,456 - speechbrain.utils.train_logger - INFO - epoch: 7, lr_model: 2.00e-04 - train loss: 4.13e-01 - valid loss: 5.03e-01, valid CER: 12.18, valid WER: 39.22
2023-12-02 11:56:54,428 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/LibriSpeech/brq_hyperbranch/2000/save/CKPT+2023-12-02+11-56-53+00
2023-12-02 11:56:54,464 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/LibriSpeech/brq_hyperbranch/2000/save/CKPT+2023-12-02+11-36-14+00
2023-12-02 11:56:54,464 - speechbrain.utils.epoch_loop - INFO - Going into epoch 8
2023-12-02 12:17:31,991 - speechbrain.nnet.schedulers - INFO - Changing lr from 0.0002 to 0.00016
2023-12-02 12:17:32,002 - speechbrain.nnet.schedulers - INFO - Changing lr from 0.01 to 0.009
2023-12-02 12:17:32,003 - speechbrain.utils.train_logger - INFO - epoch: 8, lr_model: 2.00e-04 - train loss: 3.91e-01 - valid loss: 5.02e-01, valid CER: 12.00, valid WER: 39.05
2023-12-02 12:17:32,960 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/LibriSpeech/brq_hyperbranch/2000/save/CKPT+2023-12-02+12-17-32+00
2023-12-02 12:17:32,986 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/LibriSpeech/brq_hyperbranch/2000/save/CKPT+2023-12-02+11-56-53+00
2023-12-02 12:17:32,986 - speechbrain.utils.epoch_loop - INFO - Going into epoch 9
2023-12-02 12:38:11,544 - speechbrain.utils.train_logger - INFO - epoch: 9, lr_model: 1.60e-04 - train loss: 3.57e-01 - valid loss: 4.96e-01, valid CER: 11.32, valid WER: 37.25
2023-12-02 12:38:12,615 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/LibriSpeech/brq_hyperbranch/2000/save/CKPT+2023-12-02+12-38-11+00
2023-12-02 12:38:12,643 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/LibriSpeech/brq_hyperbranch/2000/save/CKPT+2023-12-02+12-17-32+00
2023-12-02 12:38:12,643 - speechbrain.utils.epoch_loop - INFO - Going into epoch 10
2023-12-02 12:58:51,364 - speechbrain.utils.train_logger - INFO - epoch: 10, lr_model: 1.60e-04 - train loss: 3.36e-01 - valid loss: 4.90e-01, valid CER: 11.27, valid WER: 36.83
2023-12-02 12:58:52,372 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/LibriSpeech/brq_hyperbranch/2000/save/CKPT+2023-12-02+12-58-51+00
2023-12-02 12:58:52,401 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/LibriSpeech/brq_hyperbranch/2000/save/CKPT+2023-12-02+12-38-11+00
2023-12-02 12:58:52,401 - speechbrain.utils.epoch_loop - INFO - Going into epoch 11
2023-12-02 13:19:28,430 - speechbrain.utils.train_logger - INFO - epoch: 11, lr_model: 1.60e-04 - train loss: 3.20e-01 - valid loss: 4.82e-01, valid CER: 11.41, valid WER: 36.93
2023-12-02 13:19:29,379 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/LibriSpeech/brq_hyperbranch/2000/save/CKPT+2023-12-02+13-19-28+00
2023-12-02 13:19:29,408 - speechbrain.utils.epoch_loop - INFO - Going into epoch 12
2023-12-02 13:40:04,442 - speechbrain.nnet.schedulers - INFO - Changing lr from 0.00016 to 0.00013
2023-12-02 13:40:04,462 - speechbrain.nnet.schedulers - INFO - Changing lr from 0.009 to 0.0081
2023-12-02 13:40:04,463 - speechbrain.utils.train_logger - INFO - epoch: 12, lr_model: 1.60e-04 - train loss: 3.08e-01 - valid loss: 4.82e-01, valid CER: 11.16, valid WER: 36.27
2023-12-02 13:40:05,406 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/LibriSpeech/brq_hyperbranch/2000/save/CKPT+2023-12-02+13-40-04+00
2023-12-02 13:40:05,454 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/LibriSpeech/brq_hyperbranch/2000/save/CKPT+2023-12-02+13-19-28+00
2023-12-02 13:40:05,455 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/LibriSpeech/brq_hyperbranch/2000/save/CKPT+2023-12-02+12-58-51+00
2023-12-02 13:40:05,455 - speechbrain.utils.epoch_loop - INFO - Going into epoch 13
2023-12-02 14:00:40,723 - speechbrain.utils.train_logger - INFO - epoch: 13, lr_model: 1.28e-04 - train loss: 2.84e-01 - valid loss: 4.79e-01, valid CER: 11.06, valid WER: 35.76
2023-12-02 14:00:41,699 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/LibriSpeech/brq_hyperbranch/2000/save/CKPT+2023-12-02+14-00-40+00
2023-12-02 14:00:41,760 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/LibriSpeech/brq_hyperbranch/2000/save/CKPT+2023-12-02+13-40-04+00
2023-12-02 14:00:41,760 - speechbrain.utils.epoch_loop - INFO - Going into epoch 14
2023-12-02 14:21:18,030 - speechbrain.nnet.schedulers - INFO - Changing lr from 0.00013 to 0.0001
2023-12-02 14:21:18,051 - speechbrain.nnet.schedulers - INFO - Changing lr from 0.0081 to 0.0073
2023-12-02 14:21:18,052 - speechbrain.utils.train_logger - INFO - epoch: 14, lr_model: 1.28e-04 - train loss: 2.70e-01 - valid loss: 4.79e-01, valid CER: 10.94, valid WER: 35.78
2023-12-02 14:21:19,007 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/LibriSpeech/brq_hyperbranch/2000/save/CKPT+2023-12-02+14-21-18+00
2023-12-02 14:21:19,043 - speechbrain.utils.epoch_loop - INFO - Going into epoch 15
2023-12-02 14:41:55,332 - speechbrain.nnet.schedulers - INFO - Changing lr from 0.0001 to 8.2e-05
2023-12-02 14:41:55,367 - speechbrain.nnet.schedulers - INFO - Changing lr from 0.0073 to 0.0066
2023-12-02 14:41:55,367 - speechbrain.utils.train_logger - INFO - epoch: 15, lr_model: 1.02e-04 - train loss: 2.50e-01 - valid loss: 4.79e-01, valid CER: 10.62, valid WER: 34.59
2023-12-02 14:41:56,388 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/LibriSpeech/brq_hyperbranch/2000/save/CKPT+2023-12-02+14-41-55+00
2023-12-02 14:41:56,445 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/LibriSpeech/brq_hyperbranch/2000/save/CKPT+2023-12-02+14-00-40+00
2023-12-02 14:41:56,446 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/LibriSpeech/brq_hyperbranch/2000/save/CKPT+2023-12-02+14-21-18+00
2023-12-02 14:41:56,446 - speechbrain.utils.epoch_loop - INFO - Going into epoch 16
2023-12-02 15:02:33,390 - speechbrain.utils.train_logger - INFO - epoch: 16, lr_model: 8.19e-05 - train loss: 2.29e-01 - valid loss: 4.73e-01, valid CER: 10.52, valid WER: 34.54
2023-12-02 15:02:34,323 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/LibriSpeech/brq_hyperbranch/2000/save/CKPT+2023-12-02+15-02-33+00
2023-12-02 15:02:34,378 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/LibriSpeech/brq_hyperbranch/2000/save/CKPT+2023-12-02+14-41-55+00
2023-12-02 15:02:34,378 - speechbrain.utils.epoch_loop - INFO - Going into epoch 17
2023-12-02 15:23:08,556 - speechbrain.nnet.schedulers - INFO - Changing lr from 8.2e-05 to 6.6e-05
2023-12-02 15:23:08,573 - speechbrain.nnet.schedulers - INFO - Changing lr from 0.0066 to 0.0059
2023-12-02 15:23:08,573 - speechbrain.utils.train_logger - INFO - epoch: 17, lr_model: 8.19e-05 - train loss: 2.18e-01 - valid loss: 4.77e-01, valid CER: 10.33, valid WER: 34.17
2023-12-02 15:23:09,600 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/LibriSpeech/brq_hyperbranch/2000/save/CKPT+2023-12-02+15-23-08+00
2023-12-02 15:23:09,646 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/LibriSpeech/brq_hyperbranch/2000/save/CKPT+2023-12-02+15-02-33+00
2023-12-02 15:23:09,646 - speechbrain.utils.epoch_loop - INFO - Going into epoch 18
2023-12-02 15:43:43,686 - speechbrain.nnet.schedulers - INFO - Changing lr from 6.6e-05 to 5.2e-05
2023-12-02 15:43:43,705 - speechbrain.nnet.schedulers - INFO - Changing lr from 0.0059 to 0.0053
2023-12-02 15:43:43,706 - speechbrain.utils.train_logger - INFO - epoch: 18, lr_model: 6.55e-05 - train loss: 2.04e-01 - valid loss: 4.81e-01, valid CER: 10.40, valid WER: 33.99
2023-12-02 15:43:44,686 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/LibriSpeech/brq_hyperbranch/2000/save/CKPT+2023-12-02+15-43-43+00
2023-12-02 15:43:44,754 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/LibriSpeech/brq_hyperbranch/2000/save/CKPT+2023-12-02+15-23-08+00
2023-12-02 15:43:44,754 - speechbrain.utils.epoch_loop - INFO - Going into epoch 19
