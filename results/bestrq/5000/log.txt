2023-12-06 13:19:37,577 - speechbrain.core - INFO - Beginning experiment!
2023-12-06 13:19:37,578 - speechbrain.core - INFO - Experiment folder: results/bestrq/5000
2023-12-06 13:19:43,340 - speechbrain.utils.superpowers - DEBUG - appdirs==1.4.4
attrs==23.1.0
black==19.10b0
certifi==2023.11.17
cfgv==3.4.0
charset-normalizer==3.3.2
click==8.0.4
cmake==3.27.7
distlib==0.3.7
entrypoints==0.3
filelock==3.13.1
flake8==3.7.9
fsspec==2023.10.0
huggingface-hub==0.19.4
HyperPyYAML==1.2.2
hypothesis==6.91.0
identify==2.5.32
idna==3.6
iniconfig==2.0.0
Jinja2==3.1.2
joblib==1.3.2
kenlm==0.2.0
lit==17.0.6
MarkupSafe==2.1.3
mccabe==0.6.1
mpmath==1.3.0
networkx==3.2.1
nodeenv==1.8.0
numpy==1.26.2
nvidia-cublas-cu11==11.10.3.66
nvidia-cublas-cu12==12.1.3.1
nvidia-cuda-cupti-cu11==11.7.101
nvidia-cuda-cupti-cu12==12.1.105
nvidia-cuda-nvrtc-cu11==11.7.99
nvidia-cuda-nvrtc-cu12==12.1.105
nvidia-cuda-runtime-cu11==11.7.99
nvidia-cuda-runtime-cu12==12.1.105
nvidia-cudnn-cu11==8.5.0.96
nvidia-cudnn-cu12==8.9.2.26
nvidia-cufft-cu11==10.9.0.58
nvidia-cufft-cu12==11.0.2.54
nvidia-curand-cu11==10.2.10.91
nvidia-curand-cu12==10.3.2.106
nvidia-cusolver-cu11==11.4.0.1
nvidia-cusolver-cu12==11.4.5.107
nvidia-cusparse-cu11==11.7.4.91
nvidia-cusparse-cu12==12.1.0.106
nvidia-nccl-cu11==2.14.3
nvidia-nccl-cu12==2.18.1
nvidia-nvjitlink-cu12==12.3.101
nvidia-nvtx-cu11==11.7.91
nvidia-nvtx-cu12==12.1.105
packaging==23.2
pandas==2.1.3
pathspec==0.11.2
platformdirs==4.0.0
pluggy==1.3.0
pre-commit==3.5.0
pycodestyle==2.5.0
pyctcdecode==0.5.0
pyflakes==2.1.1
pygtrie==2.5.0
pytest==7.4.0
python-dateutil==2.8.2
pytz==2023.3.post1
PyYAML==6.0.1
regex==2023.10.3
requests==2.31.0
ruamel.yaml==0.18.5
ruamel.yaml.clib==0.2.8
safetensors==0.4.1
scipy==1.11.4
sentencepiece==0.1.99
six==1.16.0
sortedcontainers==2.4.0
-e git+https://github.com/whettenr/speechbrain.git@b545d914c7e1677cae6d8fe030a00f7594b78475#egg=speechbrain
sympy==1.12
tokenizers==0.15.0
toml==0.10.2
torch==2.0.1
torchaudio==2.0.2
tqdm==4.66.1
transformers==4.35.2
triton==2.0.0
typed-ast==1.5.5
typing_extensions==4.8.0
tzdata==2023.3
urllib3==2.1.0
virtualenv==20.24.7
yamllint==1.23.0


2023-12-06 13:19:43,404 - speechbrain.utils.superpowers - DEBUG - a32be66


2023-12-06 13:19:46,189 - speechbrain.dataio.sampler - INFO - Batch quantisation in latent space
2023-12-06 13:19:46,190 - speechbrain.dataio.sampler - DEBUG - Latent bucket boundary - buckets: ['1.62', '2.19', '2.66', '3.09', '3.49', '3.88', '4.27', '4.65', '5.02', '5.41', '5.79', '6.18', '6.58', '6.99', '7.40', '7.83', '8.27', '8.72', '9.19', '9.68', '10.18', '10.70', '11.25', '11.82', '12.41', '13.04', '13.70', '14.39', '15.12', '15.90', '16.73', '17.61', '18.55', '19.57', '20.67', '21.86', '23.16', '24.59', '26.17', '27.94', '29.93', '32.21', '34.84', '37.94', '41.68', '46.34', '52.40', '60.82', '73.93', '100.00'] - length multipliers: ['1.35', '1.22', '1.16', '1.13', '1.11', '1.10', '1.09', '1.08', '1.08', '1.07', '1.07', '1.06', '1.06', '1.06', '1.06', '1.06', '1.05', '1.05', '1.05', '1.05', '1.05', '1.05', '1.05', '1.05', '1.05', '1.05', '1.05', '1.05', '1.05', '1.05', '1.05', '1.05', '1.05', '1.06', '1.06', '1.06', '1.06', '1.06', '1.07', '1.07', '1.08', '1.08', '1.09', '1.10', '1.11', '1.13', '1.16', '1.22', '1.35']
2023-12-06 13:19:46,190 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-06 13:19:46,805 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 0 with boundary 0.0-1.6 and batch_size 61: Num Examples 0.0, Num Full Batches 0.000, Pad Factor 0.000.
2023-12-06 13:19:46,805 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 1 with boundary 1.6-2.2 and batch_size 45: Num Examples 906.0, Num Full Batches 19.000, Pad Factor 8.810.
2023-12-06 13:19:46,805 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 2 with boundary 2.2-2.7 and batch_size 37: Num Examples 3456.0, Num Full Batches 84.000, Pad Factor 19.315.
2023-12-06 13:19:46,805 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 3 with boundary 2.7-3.1 and batch_size 32: Num Examples 3364.0, Num Full Batches 96.000, Pad Factor 14.604.
2023-12-06 13:19:46,810 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 4 with boundary 3.1-3.5 and batch_size 28: Num Examples 3292.0, Num Full Batches 108.000, Pad Factor 12.168.
2023-12-06 13:19:46,810 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 5 with boundary 3.5-3.9 and batch_size 25: Num Examples 3156.0, Num Full Batches 116.000, Pad Factor 10.443.
2023-12-06 13:19:46,810 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 6 with boundary 3.9-4.3 and batch_size 23: Num Examples 3158.0, Num Full Batches 128.000, Pad Factor 9.328.
2023-12-06 13:19:46,810 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 7 with boundary 4.3-4.6 and batch_size 21: Num Examples 3035.0, Num Full Batches 135.000, Pad Factor 8.411.
2023-12-06 13:19:46,810 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 8 with boundary 4.6-5.0 and batch_size 19: Num Examples 3010.0, Num Full Batches 145.000, Pad Factor 7.650.
2023-12-06 13:19:46,810 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 9 with boundary 5.0-5.4 and batch_size 18: Num Examples 3119.0, Num Full Batches 162.000, Pad Factor 7.284.
2023-12-06 13:19:46,810 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 10 with boundary 5.4-5.8 and batch_size 17: Num Examples 3126.0, Num Full Batches 175.000, Pad Factor 6.786.
2023-12-06 13:19:46,810 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 11 with boundary 5.8-6.2 and batch_size 16: Num Examples 3051.0, Num Full Batches 182.000, Pad Factor 6.432.
2023-12-06 13:19:46,810 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 12 with boundary 6.2-6.6 and batch_size 15: Num Examples 3091.0, Num Full Batches 197.000, Pad Factor 6.192.
2023-12-06 13:19:46,810 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 13 with boundary 6.6-7.0 and batch_size 14: Num Examples 3048.0, Num Full Batches 206.000, Pad Factor 5.893.
2023-12-06 13:19:46,810 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 14 with boundary 7.0-7.4 and batch_size 13: Num Examples 3288.0, Num Full Batches 236.000, Pad Factor 5.700.
2023-12-06 13:19:46,810 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 15 with boundary 7.4-7.8 and batch_size 12: Num Examples 3300.0, Num Full Batches 251.000, Pad Factor 5.514.
2023-12-06 13:19:46,810 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 16 with boundary 7.8-8.3 and batch_size 12: Num Examples 3438.0, Num Full Batches 276.000, Pad Factor 5.406.
2023-12-06 13:19:46,810 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 17 with boundary 8.3-8.7 and batch_size 11: Num Examples 3599.0, Num Full Batches 305.000, Pad Factor 5.299.
2023-12-06 13:19:46,810 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 18 with boundary 8.7-9.2 and batch_size 10: Num Examples 3901.0, Num Full Batches 349.000, Pad Factor 5.189.
2023-12-06 13:19:46,810 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 19 with boundary 9.2-9.7 and batch_size 10: Num Examples 4113.0, Num Full Batches 388.000, Pad Factor 5.087.
2023-12-06 13:19:46,810 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 20 with boundary 9.7-10.2 and batch_size 9: Num Examples 4692.0, Num Full Batches 465.000, Pad Factor 4.987.
2023-12-06 13:19:46,810 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 21 with boundary 10.2-10.7 and batch_size 9: Num Examples 5324.0, Num Full Batches 556.000, Pad Factor 4.978.
2023-12-06 13:19:46,810 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 22 with boundary 10.7-11.2 and batch_size 8: Num Examples 6379.0, Num Full Batches 700.000, Pad Factor 4.917.
2023-12-06 13:19:46,810 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 23 with boundary 11.2-11.8 and batch_size 8: Num Examples 8176.0, Num Full Batches 943.000, Pad Factor 4.894.
2023-12-06 13:19:46,810 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 24 with boundary 11.8-12.4 and batch_size 8: Num Examples 11428.0, Num Full Batches 1386.000, Pad Factor 4.865.
2023-12-06 13:19:46,810 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 25 with boundary 12.4-13.0 and batch_size 7: Num Examples 16056.0, Num Full Batches 2045.000, Pad Factor 4.866.
2023-12-06 13:19:46,810 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 26 with boundary 13.0-13.7 and batch_size 7: Num Examples 23408.0, Num Full Batches 3133.000, Pad Factor 4.893.
2023-12-06 13:19:46,810 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 27 with boundary 13.7-14.4 and batch_size 6: Num Examples 33287.0, Num Full Batches 4679.000, Pad Factor 4.874.
2023-12-06 13:19:46,810 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 28 with boundary 14.4-15.1 and batch_size 6: Num Examples 43150.0, Num Full Batches 6370.000, Pad Factor 4.946.
2023-12-06 13:19:46,810 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 29 with boundary 15.1-15.9 and batch_size 6: Num Examples 46934.0, Num Full Batches 7275.000, Pad Factor 4.968.
2023-12-06 13:19:46,811 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 30 with boundary 15.9-16.7 and batch_size 5: Num Examples 18846.0, Num Full Batches 3051.000, Pad Factor 5.095.
2023-12-06 13:19:46,811 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 31 with boundary 16.7-17.6 and batch_size 5: Num Examples 2283.0, Num Full Batches 385.000, Pad Factor 5.001.
2023-12-06 13:19:46,811 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 32 with boundary 17.6-18.6 and batch_size 5: Num Examples 24.0, Num Full Batches 4.000, Pad Factor 4.747.
2023-12-06 13:19:46,811 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 33 with boundary 18.6-19.6 and batch_size 5: Num Examples 23.0, Num Full Batches 4.000, Pad Factor 4.870.
2023-12-06 13:19:46,811 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 34 with boundary 19.6-20.7 and batch_size 4: Num Examples 26.0, Num Full Batches 5.000, Pad Factor 5.180.
2023-12-06 13:19:46,811 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 35 with boundary 20.7-21.9 and batch_size 4: Num Examples 15.0, Num Full Batches 3.000, Pad Factor 4.735.
2023-12-06 13:19:46,811 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 36 with boundary 21.9-23.2 and batch_size 4: Num Examples 11.0, Num Full Batches 2.000, Pad Factor 4.155.
2023-12-06 13:19:46,811 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 37 with boundary 23.2-24.6 and batch_size 4: Num Examples 7.0, Num Full Batches 1.000, Pad Factor 4.739.
2023-12-06 13:19:46,811 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 38 with boundary 24.6-26.2 and batch_size 3: Num Examples 6.0, Num Full Batches 1.000, Pad Factor 4.438.
2023-12-06 13:19:46,811 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 39 with boundary 26.2-27.9 and batch_size 3: Num Examples 4.0, Num Full Batches 1.000, Pad Factor 6.346.
2023-12-06 13:19:46,811 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 40 with boundary 27.9-29.9 and batch_size 3: Num Examples 1.0, Num Full Batches 0.000, Pad Factor 0.000.
2023-12-06 13:19:46,811 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 41 with boundary 29.9-32.2 and batch_size 3: Num Examples 0.0, Num Full Batches 0.000, Pad Factor 0.000.
2023-12-06 13:19:46,811 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 42 with boundary 32.2-34.8 and batch_size 2: Num Examples 0.0, Num Full Batches 0.000, Pad Factor 0.000.
2023-12-06 13:19:46,811 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 43 with boundary 34.8-37.9 and batch_size 2: Num Examples 0.0, Num Full Batches 0.000, Pad Factor 0.000.
2023-12-06 13:19:46,811 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 44 with boundary 37.9-41.7 and batch_size 2: Num Examples 0.0, Num Full Batches 0.000, Pad Factor 0.000.
2023-12-06 13:19:46,811 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 45 with boundary 41.7-46.3 and batch_size 2: Num Examples 0.0, Num Full Batches 0.000, Pad Factor 0.000.
2023-12-06 13:19:46,811 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 46 with boundary 46.3-52.4 and batch_size 1: Num Examples 0.0, Num Full Batches 0.000, Pad Factor 0.000.
2023-12-06 13:19:46,811 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 47 with boundary 52.4-60.8 and batch_size 1: Num Examples 0.0, Num Full Batches 0.000, Pad Factor 0.000.
2023-12-06 13:19:46,811 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 48 with boundary 60.8-73.9 and batch_size 1: Num Examples 0.0, Num Full Batches 0.000, Pad Factor 0.000.
2023-12-06 13:19:46,811 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 49 with boundary 73.9-100.0 and batch_size 1: Num Examples 0.0, Num Full Batches 0.000, Pad Factor 0.000.
2023-12-06 13:19:46,827 - speechbrain.core - INFO - Info: test_only arg overridden by command line input to: False
2023-12-06 13:19:46,827 - speechbrain.core - INFO - Info: debug arg overridden by command line input to: False
2023-12-06 13:19:46,827 - speechbrain.core - INFO - Info: debug_batches arg overridden by command line input to: 2
2023-12-06 13:19:46,828 - speechbrain.core - INFO - Info: debug_epochs arg overridden by command line input to: 2
2023-12-06 13:19:46,828 - speechbrain.core - INFO - Info: debug_persistently arg overridden by command line input to: False
2023-12-06 13:19:46,828 - speechbrain.core - INFO - Info: device arg overridden by command line input to: cuda:0
2023-12-06 13:19:46,828 - speechbrain.core - INFO - Info: data_parallel_backend arg overridden by command line input to: False
2023-12-06 13:19:46,828 - speechbrain.core - INFO - Info: distributed_backend arg overridden by command line input to: nccl
2023-12-06 13:19:46,828 - speechbrain.core - INFO - Info: find_unused_parameters arg overridden by command line input to: False
2023-12-06 13:19:46,828 - speechbrain.core - INFO - Info: jit arg overridden by command line input to: False
2023-12-06 13:19:46,828 - speechbrain.core - INFO - Info: compile arg overridden by command line input to: False
2023-12-06 13:19:46,828 - speechbrain.core - INFO - Info: auto_mix_prec arg from hparam file is used
2023-12-06 13:19:46,828 - speechbrain.core - INFO - Info: bfloat16_mix_prec arg from hparam file is used
2023-12-06 13:19:46,828 - speechbrain.core - INFO - Info: max_grad_norm arg from hparam file is used
2023-12-06 13:19:46,828 - speechbrain.core - INFO - Info: optimizer_step_limit arg from hparam file is used
2023-12-06 13:19:46,828 - speechbrain.core - INFO - Info: tqdm_colored_bar arg overridden by command line input to: False
2023-12-06 13:19:46,828 - speechbrain.core - INFO - Info: remove_vector_weight_decay arg overridden by command line input to: False
2023-12-06 13:19:51,349 - speechbrain.core - INFO - 143.3M trainable parameters in BestRQBrain
2023-12-06 13:19:51,351 - speechbrain.utils.checkpoints - INFO - Would load a checkpoint here, but none found yet.
2023-12-06 13:19:51,351 - speechbrain.utils.epoch_loop - INFO - Going into epoch 1
2023-12-06 13:20:51,343 - speechbrain.core - ERROR - Exception:
Traceback (most recent call last):
  File "/gpfsdswork/projects/rech/nkp/uaj64gk/bestrqexp/bestrq/train.py", line 381, in <module>
    main()
  File "/gpfsdswork/projects/rech/nkp/uaj64gk/bestrqexp/bestrq/train.py", line 371, in main
    brain.fit(
  File "/gpfsdswork/projects/rech/nkp/uaj64gk/bestrqexp/speechbrain/speechbrain/core.py", line 1366, in fit
    self._fit_train(train_set=train_set, epoch=epoch, enable=enable)
  File "/gpfsdswork/projects/rech/nkp/uaj64gk/bestrqexp/speechbrain/speechbrain/core.py", line 1193, in _fit_train
    loss = self.fit_batch(batch)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/gpfsdswork/projects/rech/nkp/uaj64gk/bestrqexp/bestrq/train.py", line 167, in fit_batch
    (loss / self.grad_accumulation_factor).backward()
  File "/linkhome/rech/genzjn01/uaj64gk/.local/lib/python3.11/site-packages/torch/_tensor.py", line 487, in backward
    torch.autograd.backward(
  File "/linkhome/rech/genzjn01/uaj64gk/.local/lib/python3.11/site-packages/torch/autograd/__init__.py", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
2023-12-06 13:28:45,808 - speechbrain.core - INFO - Beginning experiment!
2023-12-06 13:28:45,819 - speechbrain.core - INFO - Experiment folder: results/bestrq/5000
2023-12-06 13:28:50,099 - speechbrain.utils.superpowers - DEBUG - appdirs==1.4.4
attrs==23.1.0
black==19.10b0
certifi==2023.11.17
cfgv==3.4.0
charset-normalizer==3.3.2
click==8.0.4
cmake==3.27.7
distlib==0.3.7
entrypoints==0.3
filelock==3.13.1
flake8==3.7.9
fsspec==2023.10.0
huggingface-hub==0.19.4
HyperPyYAML==1.2.2
hypothesis==6.91.0
identify==2.5.32
idna==3.6
iniconfig==2.0.0
Jinja2==3.1.2
joblib==1.3.2
kenlm==0.2.0
lit==17.0.6
MarkupSafe==2.1.3
mccabe==0.6.1
mpmath==1.3.0
networkx==3.2.1
nodeenv==1.8.0
numpy==1.26.2
nvidia-cublas-cu11==11.10.3.66
nvidia-cublas-cu12==12.1.3.1
nvidia-cuda-cupti-cu11==11.7.101
nvidia-cuda-cupti-cu12==12.1.105
nvidia-cuda-nvrtc-cu11==11.7.99
nvidia-cuda-nvrtc-cu12==12.1.105
nvidia-cuda-runtime-cu11==11.7.99
nvidia-cuda-runtime-cu12==12.1.105
nvidia-cudnn-cu11==8.5.0.96
nvidia-cudnn-cu12==8.9.2.26
nvidia-cufft-cu11==10.9.0.58
nvidia-cufft-cu12==11.0.2.54
nvidia-curand-cu11==10.2.10.91
nvidia-curand-cu12==10.3.2.106
nvidia-cusolver-cu11==11.4.0.1
nvidia-cusolver-cu12==11.4.5.107
nvidia-cusparse-cu11==11.7.4.91
nvidia-cusparse-cu12==12.1.0.106
nvidia-nccl-cu11==2.14.3
nvidia-nccl-cu12==2.18.1
nvidia-nvjitlink-cu12==12.3.101
nvidia-nvtx-cu11==11.7.91
nvidia-nvtx-cu12==12.1.105
packaging==23.2
pandas==2.1.3
pathspec==0.11.2
platformdirs==4.0.0
pluggy==1.3.0
pre-commit==3.5.0
pycodestyle==2.5.0
pyctcdecode==0.5.0
pyflakes==2.1.1
pygtrie==2.5.0
pytest==7.4.0
python-dateutil==2.8.2
pytz==2023.3.post1
PyYAML==6.0.1
regex==2023.10.3
requests==2.31.0
ruamel.yaml==0.18.5
ruamel.yaml.clib==0.2.8
safetensors==0.4.1
scipy==1.11.4
sentencepiece==0.1.99
six==1.16.0
sortedcontainers==2.4.0
-e /gpfsdswork/projects/rech/nkp/uaj64gk/bestrqexp/speechbrain
sympy==1.12
tokenizers==0.15.0
toml==0.10.2
torch==2.0.1
torchaudio==2.0.2
tqdm==4.66.1
transformers==4.35.2
triton==2.0.0
typed-ast==1.5.5
typing_extensions==4.8.0
tzdata==2023.3
urllib3==2.1.0
virtualenv==20.24.7
yamllint==1.23.0

ERROR: Error [Errno 2] No such file or directory: 'git' while executing command git config --get-regexp 'remote\..*\.url'
WARNING: cannot determine version of editable source in /gpfsdswork/projects/rech/nkp/uaj64gk/bestrqexp/speechbrain (git command not found in path)

2023-12-06 13:28:54,822 - speechbrain.dataio.sampler - INFO - Batch quantisation in latent space
2023-12-06 13:28:54,823 - speechbrain.dataio.sampler - DEBUG - Latent bucket boundary - buckets: ['1.62', '2.19', '2.66', '3.09', '3.49', '3.88', '4.27', '4.65', '5.02', '5.41', '5.79', '6.18', '6.58', '6.99', '7.40', '7.83', '8.27', '8.72', '9.19', '9.68', '10.18', '10.70', '11.25', '11.82', '12.41', '13.04', '13.70', '14.39', '15.12', '15.90', '16.73', '17.61', '18.55', '19.57', '20.67', '21.86', '23.16', '24.59', '26.17', '27.94', '29.93', '32.21', '34.84', '37.94', '41.68', '46.34', '52.40', '60.82', '73.93', '100.00'] - length multipliers: ['1.35', '1.22', '1.16', '1.13', '1.11', '1.10', '1.09', '1.08', '1.08', '1.07', '1.07', '1.06', '1.06', '1.06', '1.06', '1.06', '1.05', '1.05', '1.05', '1.05', '1.05', '1.05', '1.05', '1.05', '1.05', '1.05', '1.05', '1.05', '1.05', '1.05', '1.05', '1.05', '1.05', '1.06', '1.06', '1.06', '1.06', '1.06', '1.07', '1.07', '1.08', '1.08', '1.09', '1.10', '1.11', '1.13', '1.16', '1.22', '1.35']
2023-12-06 13:28:54,823 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-06 13:28:55,512 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 0 with boundary 0.0-1.6 and batch_size 61: Num Examples 0.0, Num Full Batches 0.000, Pad Factor 0.000.
2023-12-06 13:28:55,513 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 1 with boundary 1.6-2.2 and batch_size 45: Num Examples 906.0, Num Full Batches 19.000, Pad Factor 8.810.
2023-12-06 13:28:55,513 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 2 with boundary 2.2-2.7 and batch_size 37: Num Examples 3456.0, Num Full Batches 84.000, Pad Factor 19.315.
2023-12-06 13:28:55,513 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 3 with boundary 2.7-3.1 and batch_size 32: Num Examples 3364.0, Num Full Batches 96.000, Pad Factor 14.604.
2023-12-06 13:28:55,513 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 4 with boundary 3.1-3.5 and batch_size 28: Num Examples 3292.0, Num Full Batches 108.000, Pad Factor 12.168.
2023-12-06 13:28:55,513 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 5 with boundary 3.5-3.9 and batch_size 25: Num Examples 3156.0, Num Full Batches 116.000, Pad Factor 10.443.
2023-12-06 13:28:55,513 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 6 with boundary 3.9-4.3 and batch_size 23: Num Examples 3158.0, Num Full Batches 128.000, Pad Factor 9.328.
2023-12-06 13:28:55,513 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 7 with boundary 4.3-4.6 and batch_size 21: Num Examples 3035.0, Num Full Batches 135.000, Pad Factor 8.411.
2023-12-06 13:28:55,513 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 8 with boundary 4.6-5.0 and batch_size 19: Num Examples 3010.0, Num Full Batches 145.000, Pad Factor 7.650.
2023-12-06 13:28:55,513 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 9 with boundary 5.0-5.4 and batch_size 18: Num Examples 3119.0, Num Full Batches 162.000, Pad Factor 7.284.
2023-12-06 13:28:55,513 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 10 with boundary 5.4-5.8 and batch_size 17: Num Examples 3126.0, Num Full Batches 175.000, Pad Factor 6.786.
2023-12-06 13:28:55,513 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 11 with boundary 5.8-6.2 and batch_size 16: Num Examples 3051.0, Num Full Batches 182.000, Pad Factor 6.432.
2023-12-06 13:28:55,513 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 12 with boundary 6.2-6.6 and batch_size 15: Num Examples 3091.0, Num Full Batches 197.000, Pad Factor 6.192.
2023-12-06 13:28:55,513 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 13 with boundary 6.6-7.0 and batch_size 14: Num Examples 3048.0, Num Full Batches 206.000, Pad Factor 5.893.
2023-12-06 13:28:55,513 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 14 with boundary 7.0-7.4 and batch_size 13: Num Examples 3288.0, Num Full Batches 236.000, Pad Factor 5.700.
2023-12-06 13:28:55,513 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 15 with boundary 7.4-7.8 and batch_size 12: Num Examples 3300.0, Num Full Batches 251.000, Pad Factor 5.514.
2023-12-06 13:28:55,513 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 16 with boundary 7.8-8.3 and batch_size 12: Num Examples 3438.0, Num Full Batches 276.000, Pad Factor 5.406.
2023-12-06 13:28:55,513 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 17 with boundary 8.3-8.7 and batch_size 11: Num Examples 3599.0, Num Full Batches 305.000, Pad Factor 5.299.
2023-12-06 13:28:55,513 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 18 with boundary 8.7-9.2 and batch_size 10: Num Examples 3901.0, Num Full Batches 349.000, Pad Factor 5.189.
2023-12-06 13:28:55,513 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 19 with boundary 9.2-9.7 and batch_size 10: Num Examples 4113.0, Num Full Batches 388.000, Pad Factor 5.087.
2023-12-06 13:28:55,513 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 20 with boundary 9.7-10.2 and batch_size 9: Num Examples 4692.0, Num Full Batches 465.000, Pad Factor 4.987.
2023-12-06 13:28:55,513 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 21 with boundary 10.2-10.7 and batch_size 9: Num Examples 5324.0, Num Full Batches 556.000, Pad Factor 4.978.
2023-12-06 13:28:55,514 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 22 with boundary 10.7-11.2 and batch_size 8: Num Examples 6379.0, Num Full Batches 700.000, Pad Factor 4.917.
2023-12-06 13:28:55,514 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 23 with boundary 11.2-11.8 and batch_size 8: Num Examples 8176.0, Num Full Batches 943.000, Pad Factor 4.894.
2023-12-06 13:28:55,514 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 24 with boundary 11.8-12.4 and batch_size 8: Num Examples 11428.0, Num Full Batches 1386.000, Pad Factor 4.865.
2023-12-06 13:28:55,514 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 25 with boundary 12.4-13.0 and batch_size 7: Num Examples 16056.0, Num Full Batches 2045.000, Pad Factor 4.866.
2023-12-06 13:28:55,514 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 26 with boundary 13.0-13.7 and batch_size 7: Num Examples 23408.0, Num Full Batches 3133.000, Pad Factor 4.893.
2023-12-06 13:28:55,514 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 27 with boundary 13.7-14.4 and batch_size 6: Num Examples 33287.0, Num Full Batches 4679.000, Pad Factor 4.874.
2023-12-06 13:28:55,514 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 28 with boundary 14.4-15.1 and batch_size 6: Num Examples 43150.0, Num Full Batches 6370.000, Pad Factor 4.946.
2023-12-06 13:28:55,514 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 29 with boundary 15.1-15.9 and batch_size 6: Num Examples 46934.0, Num Full Batches 7275.000, Pad Factor 4.968.
2023-12-06 13:28:55,514 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 30 with boundary 15.9-16.7 and batch_size 5: Num Examples 18846.0, Num Full Batches 3051.000, Pad Factor 5.095.
2023-12-06 13:28:55,514 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 31 with boundary 16.7-17.6 and batch_size 5: Num Examples 2283.0, Num Full Batches 385.000, Pad Factor 5.001.
2023-12-06 13:28:55,514 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 32 with boundary 17.6-18.6 and batch_size 5: Num Examples 24.0, Num Full Batches 4.000, Pad Factor 4.747.
2023-12-06 13:28:55,514 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 33 with boundary 18.6-19.6 and batch_size 5: Num Examples 23.0, Num Full Batches 4.000, Pad Factor 4.870.
2023-12-06 13:28:55,514 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 34 with boundary 19.6-20.7 and batch_size 4: Num Examples 26.0, Num Full Batches 5.000, Pad Factor 5.180.
2023-12-06 13:28:55,514 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 35 with boundary 20.7-21.9 and batch_size 4: Num Examples 15.0, Num Full Batches 3.000, Pad Factor 4.735.
2023-12-06 13:28:55,514 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 36 with boundary 21.9-23.2 and batch_size 4: Num Examples 11.0, Num Full Batches 2.000, Pad Factor 4.155.
2023-12-06 13:28:55,514 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 37 with boundary 23.2-24.6 and batch_size 4: Num Examples 7.0, Num Full Batches 1.000, Pad Factor 4.739.
2023-12-06 13:28:55,514 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 38 with boundary 24.6-26.2 and batch_size 3: Num Examples 6.0, Num Full Batches 1.000, Pad Factor 4.438.
2023-12-06 13:28:55,514 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 39 with boundary 26.2-27.9 and batch_size 3: Num Examples 4.0, Num Full Batches 1.000, Pad Factor 6.346.
2023-12-06 13:28:55,514 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 40 with boundary 27.9-29.9 and batch_size 3: Num Examples 1.0, Num Full Batches 0.000, Pad Factor 0.000.
2023-12-06 13:28:55,514 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 41 with boundary 29.9-32.2 and batch_size 3: Num Examples 0.0, Num Full Batches 0.000, Pad Factor 0.000.
2023-12-06 13:28:55,514 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 42 with boundary 32.2-34.8 and batch_size 2: Num Examples 0.0, Num Full Batches 0.000, Pad Factor 0.000.
2023-12-06 13:28:55,515 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 43 with boundary 34.8-37.9 and batch_size 2: Num Examples 0.0, Num Full Batches 0.000, Pad Factor 0.000.
2023-12-06 13:28:55,515 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 44 with boundary 37.9-41.7 and batch_size 2: Num Examples 0.0, Num Full Batches 0.000, Pad Factor 0.000.
2023-12-06 13:28:55,515 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 45 with boundary 41.7-46.3 and batch_size 2: Num Examples 0.0, Num Full Batches 0.000, Pad Factor 0.000.
2023-12-06 13:28:55,515 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 46 with boundary 46.3-52.4 and batch_size 1: Num Examples 0.0, Num Full Batches 0.000, Pad Factor 0.000.
2023-12-06 13:28:55,515 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 47 with boundary 52.4-60.8 and batch_size 1: Num Examples 0.0, Num Full Batches 0.000, Pad Factor 0.000.
2023-12-06 13:28:55,515 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 48 with boundary 60.8-73.9 and batch_size 1: Num Examples 0.0, Num Full Batches 0.000, Pad Factor 0.000.
2023-12-06 13:28:55,515 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 49 with boundary 73.9-100.0 and batch_size 1: Num Examples 0.0, Num Full Batches 0.000, Pad Factor 0.000.
2023-12-06 13:28:55,516 - speechbrain.core - INFO - Info: test_only arg overridden by command line input to: False
2023-12-06 13:28:55,517 - speechbrain.core - INFO - Info: debug arg overridden by command line input to: False
2023-12-06 13:28:55,517 - speechbrain.core - INFO - Info: debug_batches arg overridden by command line input to: 2
2023-12-06 13:28:55,517 - speechbrain.core - INFO - Info: debug_epochs arg overridden by command line input to: 2
2023-12-06 13:28:55,517 - speechbrain.core - INFO - Info: debug_persistently arg overridden by command line input to: False
2023-12-06 13:28:55,517 - speechbrain.core - INFO - Info: device arg overridden by command line input to: cuda:0
2023-12-06 13:28:55,517 - speechbrain.core - INFO - Info: data_parallel_backend arg overridden by command line input to: False
2023-12-06 13:28:55,517 - speechbrain.core - INFO - Info: distributed_backend arg overridden by command line input to: nccl
2023-12-06 13:28:55,517 - speechbrain.core - INFO - Info: find_unused_parameters arg overridden by command line input to: True
2023-12-06 13:28:55,517 - speechbrain.core - INFO - Info: jit arg overridden by command line input to: False
2023-12-06 13:28:55,517 - speechbrain.core - INFO - Info: compile arg overridden by command line input to: False
2023-12-06 13:28:55,517 - speechbrain.core - INFO - Info: auto_mix_prec arg from hparam file is used
2023-12-06 13:28:55,517 - speechbrain.core - INFO - Info: bfloat16_mix_prec arg from hparam file is used
2023-12-06 13:28:55,517 - speechbrain.core - INFO - Info: max_grad_norm arg from hparam file is used
2023-12-06 13:28:55,517 - speechbrain.core - INFO - Info: optimizer_step_limit arg from hparam file is used
2023-12-06 13:28:55,517 - speechbrain.core - INFO - Info: tqdm_colored_bar arg overridden by command line input to: False
2023-12-06 13:28:55,517 - speechbrain.core - INFO - Info: remove_vector_weight_decay arg overridden by command line input to: False
2023-12-06 13:28:55,666 - speechbrain.core - INFO - 143.3M trainable parameters in BestRQBrain
2023-12-06 13:28:55,765 - speechbrain.utils.checkpoints - INFO - Would load a checkpoint here, but none found yet.
2023-12-06 13:28:55,765 - speechbrain.utils.epoch_loop - INFO - Going into epoch 1
2023-12-06 13:28:55,767 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-06 13:28:56,603 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-06 13:31:48,323 - speechbrain.utils.train_logger - INFO - steps: 500, lr: 1.60e-05, avg_loss: 7.32
2023-12-06 13:34:32,255 - speechbrain.utils.train_logger - INFO - steps: 1000, lr: 3.20e-05, avg_loss: 6.56, run_time: 1.64e+02
2023-12-06 13:38:26,791 - speechbrain.utils.train_logger - INFO - steps: 1500, lr: 4.80e-05, avg_loss: 6.06, run_time: 1.59e+02
2023-12-06 13:41:12,912 - speechbrain.utils.train_logger - INFO - steps: 2000, lr: 6.40e-05, avg_loss: 5.71, run_time: 2.42e+02
2023-12-06 13:43:51,993 - speechbrain.utils.train_logger - INFO - steps: 2500, lr: 8.00e-05, avg_loss: 5.46, run_time: 1.59e+02
2023-12-06 13:46:43,554 - speechbrain.utils.train_logger - INFO - steps: 3000, lr: 9.60e-05, avg_loss: 5.27, run_time: 1.72e+02
2023-12-06 13:49:22,627 - speechbrain.utils.train_logger - INFO - steps: 3500, lr: 1.12e-04, avg_loss: 5.13, run_time: 1.59e+02
2023-12-06 13:52:01,818 - speechbrain.utils.train_logger - INFO - steps: 4000, lr: 1.28e-04, avg_loss: 5.01, run_time: 1.59e+02
2023-12-06 13:54:41,064 - speechbrain.utils.train_logger - INFO - steps: 4500, lr: 1.44e-04, avg_loss: 4.91, run_time: 1.59e+02
2023-12-06 13:57:07,050 - speechbrain.utils.train_logger - INFO - epoch: 1, steps: 4832, lr: 1.55e-04 - train loss: 4.85 - valid loss: 4.53, valid accuracy: 1.43e-01
2023-12-06 13:57:08,742 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/bestrq/5000/save/CKPT+2023-12-06+13-57-07+00
2023-12-06 13:57:08,744 - speechbrain.utils.epoch_loop - INFO - Going into epoch 2
2023-12-06 13:57:08,746 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-06 13:57:09,587 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-06 13:58:04,417 - speechbrain.utils.train_logger - INFO - steps: 5000, lr: 1.60e-04, avg_loss: 4.09, run_time: 2.03e+02
2023-12-06 14:00:43,273 - speechbrain.utils.train_logger - INFO - steps: 5500, lr: 1.76e-04, avg_loss: 4.07, run_time: 1.59e+02
2023-12-06 14:03:22,113 - speechbrain.utils.train_logger - INFO - steps: 6000, lr: 1.92e-04, avg_loss: 4.05, run_time: 1.59e+02
2023-12-06 14:06:01,211 - speechbrain.utils.train_logger - INFO - steps: 6500, lr: 2.08e-04, avg_loss: 4.03, run_time: 1.59e+02
2023-12-06 14:08:40,358 - speechbrain.utils.train_logger - INFO - steps: 7000, lr: 2.24e-04, avg_loss: 4.02, run_time: 1.59e+02
2023-12-06 14:11:19,523 - speechbrain.utils.train_logger - INFO - steps: 7500, lr: 2.40e-04, avg_loss: 4.01, run_time: 1.59e+02
2023-12-06 14:13:58,671 - speechbrain.utils.train_logger - INFO - steps: 8000, lr: 2.56e-04, avg_loss: 4.00, run_time: 1.59e+02
2023-12-06 14:16:38,127 - speechbrain.utils.train_logger - INFO - steps: 8500, lr: 2.72e-04, avg_loss: 3.99, run_time: 1.59e+02
2023-12-06 14:19:17,141 - speechbrain.utils.train_logger - INFO - steps: 9000, lr: 2.88e-04, avg_loss: 3.98, run_time: 1.59e+02
2023-12-06 14:21:55,949 - speechbrain.utils.train_logger - INFO - steps: 9500, lr: 3.04e-04, avg_loss: 3.97, run_time: 1.59e+02
2023-12-06 14:23:27,399 - speechbrain.utils.train_logger - INFO - epoch: 2, steps: 9664, lr: 3.09e-04 - train loss: 3.97 - valid loss: 4.26, valid accuracy: 1.61e-01
2023-12-06 14:23:29,064 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/bestrq/5000/save/CKPT+2023-12-06+14-23-27+00
2023-12-06 14:23:29,069 - speechbrain.utils.epoch_loop - INFO - Going into epoch 3
2023-12-06 14:23:29,071 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-06 14:23:30,041 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-06 14:25:18,417 - speechbrain.utils.train_logger - INFO - steps: 10000, lr: 3.20e-04, avg_loss: 3.89, run_time: 2.02e+02
2023-12-06 14:27:57,448 - speechbrain.utils.train_logger - INFO - steps: 10500, lr: 3.36e-04, avg_loss: 3.86, run_time: 1.59e+02
2023-12-06 14:30:36,412 - speechbrain.utils.train_logger - INFO - steps: 11000, lr: 3.52e-04, avg_loss: 3.86, run_time: 1.59e+02
2023-12-06 14:33:15,352 - speechbrain.utils.train_logger - INFO - steps: 11500, lr: 3.68e-04, avg_loss: 3.85, run_time: 1.59e+02
2023-12-06 14:35:54,425 - speechbrain.utils.train_logger - INFO - steps: 12000, lr: 3.84e-04, avg_loss: 3.85, run_time: 1.59e+02
2023-12-06 14:38:33,357 - speechbrain.utils.train_logger - INFO - steps: 12500, lr: 4.00e-04, avg_loss: 3.85, run_time: 1.59e+02
2023-12-06 14:41:12,495 - speechbrain.utils.train_logger - INFO - steps: 13000, lr: 4.16e-04, avg_loss: 3.84, run_time: 1.59e+02
2023-12-06 14:43:51,593 - speechbrain.utils.train_logger - INFO - steps: 13500, lr: 4.32e-04, avg_loss: 3.83, run_time: 1.59e+02
2023-12-06 14:46:30,868 - speechbrain.utils.train_logger - INFO - steps: 14000, lr: 4.48e-04, avg_loss: 3.83, run_time: 1.59e+02
2023-12-06 14:49:48,370 - speechbrain.utils.train_logger - INFO - epoch: 3, steps: 14496, lr: 4.64e-04 - train loss: 3.82 - valid loss: 4.05, valid accuracy: 1.82e-01
2023-12-06 14:49:50,078 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/bestrq/5000/save/CKPT+2023-12-06+14-49-48+00
2023-12-06 14:49:50,087 - speechbrain.utils.epoch_loop - INFO - Going into epoch 4
2023-12-06 14:49:50,089 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-06 14:49:50,958 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-06 14:49:53,666 - speechbrain.utils.train_logger - INFO - steps: 14500, lr: 4.64e-04, avg_loss: 3.62, run_time: 2.03e+02
2023-12-06 14:52:32,341 - speechbrain.utils.train_logger - INFO - steps: 15000, lr: 4.80e-04, avg_loss: 3.78, run_time: 1.59e+02
2023-12-06 14:55:10,881 - speechbrain.utils.train_logger - INFO - steps: 15500, lr: 4.96e-04, avg_loss: 3.76, run_time: 1.59e+02
2023-12-06 14:57:49,495 - speechbrain.utils.train_logger - INFO - steps: 16000, lr: 5.12e-04, avg_loss: 3.75, run_time: 1.59e+02
2023-12-06 15:00:28,385 - speechbrain.utils.train_logger - INFO - steps: 16500, lr: 5.28e-04, avg_loss: 3.75, run_time: 1.59e+02
2023-12-06 15:03:08,208 - speechbrain.utils.train_logger - INFO - steps: 17000, lr: 5.44e-04, avg_loss: 3.75, run_time: 1.60e+02
2023-12-06 15:05:48,139 - speechbrain.utils.train_logger - INFO - steps: 17500, lr: 5.60e-04, avg_loss: 3.74, run_time: 1.60e+02
2023-12-06 15:08:27,811 - speechbrain.utils.train_logger - INFO - steps: 18000, lr: 5.76e-04, avg_loss: 3.74, run_time: 1.60e+02
2023-12-06 15:11:06,776 - speechbrain.utils.train_logger - INFO - steps: 18500, lr: 5.92e-04, avg_loss: 3.73, run_time: 1.59e+02
2023-12-06 15:13:46,240 - speechbrain.utils.train_logger - INFO - steps: 19000, lr: 6.08e-04, avg_loss: 3.73, run_time: 1.59e+02
2023-12-06 15:16:10,342 - speechbrain.utils.train_logger - INFO - epoch: 4, steps: 19328, lr: 6.18e-04 - train loss: 3.73 - valid loss: 4.02, valid accuracy: 1.82e-01
2023-12-06 15:16:11,957 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/bestrq/5000/save/CKPT+2023-12-06+15-16-10+00
2023-12-06 15:16:11,970 - speechbrain.utils.epoch_loop - INFO - Going into epoch 5
2023-12-06 15:16:11,972 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-06 15:16:13,032 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-06 15:17:09,243 - speechbrain.utils.train_logger - INFO - steps: 19500, lr: 6.24e-04, avg_loss: 3.70, run_time: 2.03e+02
2023-12-06 15:19:48,065 - speechbrain.utils.train_logger - INFO - steps: 20000, lr: 6.40e-04, avg_loss: 3.68, run_time: 1.59e+02
2023-12-06 15:24:28,031 - speechbrain.utils.train_logger - INFO - steps: 20500, lr: 6.56e-04, avg_loss: 3.68, run_time: 1.59e+02
2023-12-06 15:27:06,311 - speechbrain.utils.train_logger - INFO - steps: 21000, lr: 6.72e-04, avg_loss: 3.68, run_time: 2.79e+02
2023-12-06 15:29:45,142 - speechbrain.utils.train_logger - INFO - steps: 21500, lr: 6.88e-04, avg_loss: 3.68, run_time: 1.59e+02
2023-12-06 15:32:24,216 - speechbrain.utils.train_logger - INFO - steps: 22000, lr: 7.04e-04, avg_loss: 3.68, run_time: 1.59e+02
2023-12-06 15:36:42,261 - speechbrain.utils.train_logger - INFO - steps: 22500, lr: 7.20e-04, avg_loss: 3.67, run_time: 2.58e+02
2023-12-06 15:39:21,158 - speechbrain.utils.train_logger - INFO - steps: 23000, lr: 7.36e-04, avg_loss: 3.67, run_time: 1.59e+02
2023-12-06 15:42:35,247 - speechbrain.utils.train_logger - INFO - steps: 23500, lr: 7.52e-04, avg_loss: 3.67, run_time: 1.64e+02
2023-12-06 15:45:14,920 - speechbrain.utils.train_logger - INFO - steps: 24000, lr: 7.68e-04, avg_loss: 3.66, run_time: 1.90e+02
2023-12-06 15:47:01,664 - speechbrain.utils.train_logger - INFO - epoch: 5, steps: 24160, lr: 7.73e-04 - train loss: 3.66 - valid loss: 4.00, valid accuracy: 1.85e-01
2023-12-06 15:47:14,557 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/bestrq/5000/save/CKPT+2023-12-06+15-47-01+00
2023-12-06 15:47:14,579 - speechbrain.utils.epoch_loop - INFO - Going into epoch 6
2023-12-06 15:47:14,581 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-06 15:47:15,337 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-06 15:50:50,869 - speechbrain.utils.train_logger - INFO - steps: 24500, lr: 7.84e-04, avg_loss: 3.64, run_time: 2.45e+02
2023-12-06 15:53:29,159 - speechbrain.utils.train_logger - INFO - steps: 25000, lr: 8.00e-04, avg_loss: 3.64, run_time: 2.50e+02
2023-12-06 15:56:08,154 - speechbrain.utils.train_logger - INFO - steps: 25500, lr: 7.92e-04, avg_loss: 3.64, run_time: 1.59e+02
2023-12-06 15:58:47,520 - speechbrain.utils.train_logger - INFO - steps: 26000, lr: 7.84e-04, avg_loss: 3.63, run_time: 1.59e+02
2023-12-06 16:01:27,168 - speechbrain.utils.train_logger - INFO - steps: 26500, lr: 7.77e-04, avg_loss: 3.63, run_time: 1.60e+02
2023-12-06 16:04:06,565 - speechbrain.utils.train_logger - INFO - steps: 27000, lr: 7.70e-04, avg_loss: 3.62, run_time: 1.59e+02
2023-12-06 16:06:45,941 - speechbrain.utils.train_logger - INFO - steps: 27500, lr: 7.63e-04, avg_loss: 3.62, run_time: 1.59e+02
2023-12-06 16:09:25,335 - speechbrain.utils.train_logger - INFO - steps: 28000, lr: 7.56e-04, avg_loss: 3.62, run_time: 1.59e+02
2023-12-06 16:12:04,783 - speechbrain.utils.train_logger - INFO - steps: 28500, lr: 7.49e-04, avg_loss: 3.61, run_time: 1.59e+02
2023-12-06 16:15:21,245 - speechbrain.utils.train_logger - INFO - epoch: 6, steps: 28992, lr: 7.43e-04 - train loss: 3.61 - valid loss: 3.93, valid accuracy: 1.91e-01
2023-12-06 16:15:24,569 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/bestrq/5000/save/CKPT+2023-12-06+16-15-21+00
2023-12-06 16:15:24,597 - speechbrain.utils.epoch_loop - INFO - Going into epoch 7
2023-12-06 16:15:24,599 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-06 16:15:25,376 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-06 16:15:29,317 - speechbrain.utils.train_logger - INFO - steps: 29000, lr: 7.43e-04, avg_loss: 3.67, run_time: 2.05e+02
2023-12-06 16:18:08,158 - speechbrain.utils.train_logger - INFO - steps: 29500, lr: 7.36e-04, avg_loss: 3.56, run_time: 1.59e+02
2023-12-06 16:20:47,239 - speechbrain.utils.train_logger - INFO - steps: 30000, lr: 7.30e-04, avg_loss: 3.54, run_time: 1.59e+02
2023-12-06 16:23:26,428 - speechbrain.utils.train_logger - INFO - steps: 30500, lr: 7.24e-04, avg_loss: 3.55, run_time: 1.59e+02
2023-12-06 16:26:05,201 - speechbrain.utils.train_logger - INFO - steps: 31000, lr: 7.18e-04, avg_loss: 3.54, run_time: 1.59e+02
2023-12-06 16:28:44,319 - speechbrain.utils.train_logger - INFO - steps: 31500, lr: 7.13e-04, avg_loss: 3.54, run_time: 1.59e+02
2023-12-06 16:31:23,797 - speechbrain.utils.train_logger - INFO - steps: 32000, lr: 7.07e-04, avg_loss: 3.54, run_time: 1.59e+02
2023-12-06 16:34:02,696 - speechbrain.utils.train_logger - INFO - steps: 32500, lr: 7.02e-04, avg_loss: 3.54, run_time: 1.59e+02
2023-12-06 16:36:42,876 - speechbrain.utils.train_logger - INFO - steps: 33000, lr: 6.96e-04, avg_loss: 3.53, run_time: 1.60e+02
2023-12-06 16:39:21,764 - speechbrain.utils.train_logger - INFO - steps: 33500, lr: 6.91e-04, avg_loss: 3.53, run_time: 1.59e+02
2023-12-06 16:41:44,153 - speechbrain.utils.train_logger - INFO - epoch: 7, steps: 33824, lr: 6.88e-04 - train loss: 3.53 - valid loss: 3.85, valid accuracy: 2.00e-01
2023-12-06 16:41:45,779 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/bestrq/5000/save/CKPT+2023-12-06+16-41-44+00
2023-12-06 16:41:45,815 - speechbrain.utils.epoch_loop - INFO - Going into epoch 8
2023-12-06 16:41:45,817 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-06 16:41:46,698 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-06 16:42:44,216 - speechbrain.utils.train_logger - INFO - steps: 34000, lr: 6.86e-04, avg_loss: 3.48, run_time: 2.02e+02
2023-12-06 16:45:23,228 - speechbrain.utils.train_logger - INFO - steps: 34500, lr: 6.81e-04, avg_loss: 3.51, run_time: 1.59e+02
2023-12-06 16:48:02,541 - speechbrain.utils.train_logger - INFO - steps: 35000, lr: 6.76e-04, avg_loss: 3.51, run_time: 1.59e+02
2023-12-06 16:50:41,846 - speechbrain.utils.train_logger - INFO - steps: 35500, lr: 6.71e-04, avg_loss: 3.50, run_time: 1.59e+02
2023-12-06 16:53:21,268 - speechbrain.utils.train_logger - INFO - steps: 36000, lr: 6.67e-04, avg_loss: 3.50, run_time: 1.59e+02
2023-12-06 16:56:00,406 - speechbrain.utils.train_logger - INFO - steps: 36500, lr: 6.62e-04, avg_loss: 3.50, run_time: 1.59e+02
2023-12-06 16:58:39,569 - speechbrain.utils.train_logger - INFO - steps: 37000, lr: 6.58e-04, avg_loss: 3.50, run_time: 1.59e+02
2023-12-06 17:01:19,165 - speechbrain.utils.train_logger - INFO - steps: 37500, lr: 6.53e-04, avg_loss: 3.50, run_time: 1.60e+02
2023-12-06 17:03:58,612 - speechbrain.utils.train_logger - INFO - steps: 38000, lr: 6.49e-04, avg_loss: 3.49, run_time: 1.59e+02
2023-12-06 17:06:37,917 - speechbrain.utils.train_logger - INFO - steps: 38500, lr: 6.45e-04, avg_loss: 3.49, run_time: 1.59e+02
2023-12-06 17:08:07,395 - speechbrain.utils.train_logger - INFO - epoch: 8, steps: 38656, lr: 6.43e-04 - train loss: 3.49 - valid loss: 3.82, valid accuracy: 2.02e-01
2023-12-06 17:08:09,136 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/bestrq/5000/save/CKPT+2023-12-06+17-08-07+00
2023-12-06 17:08:09,184 - speechbrain.utils.epoch_loop - INFO - Going into epoch 9
2023-12-06 17:08:09,186 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-06 17:08:10,076 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-06 17:10:01,467 - speechbrain.utils.train_logger - INFO - steps: 39000, lr: 6.41e-04, avg_loss: 3.47, run_time: 2.04e+02
2023-12-06 17:12:43,322 - speechbrain.utils.train_logger - INFO - steps: 39500, lr: 6.36e-04, avg_loss: 3.47, run_time: 1.62e+02
2023-12-06 17:15:22,501 - speechbrain.utils.train_logger - INFO - steps: 40000, lr: 6.32e-04, avg_loss: 3.47, run_time: 1.59e+02
2023-12-06 17:18:01,781 - speechbrain.utils.train_logger - INFO - steps: 40500, lr: 6.29e-04, avg_loss: 3.47, run_time: 1.59e+02
2023-12-06 17:20:41,428 - speechbrain.utils.train_logger - INFO - steps: 41000, lr: 6.25e-04, avg_loss: 3.46, run_time: 1.60e+02
2023-12-06 17:23:20,849 - speechbrain.utils.train_logger - INFO - steps: 41500, lr: 6.21e-04, avg_loss: 3.46, run_time: 1.59e+02
2023-12-06 17:26:00,304 - speechbrain.utils.train_logger - INFO - steps: 42000, lr: 6.17e-04, avg_loss: 3.46, run_time: 1.59e+02
2023-12-06 17:28:39,942 - speechbrain.utils.train_logger - INFO - steps: 42500, lr: 6.14e-04, avg_loss: 3.46, run_time: 1.60e+02
2023-12-06 17:31:19,965 - speechbrain.utils.train_logger - INFO - steps: 43000, lr: 6.10e-04, avg_loss: 3.46, run_time: 1.60e+02
2023-12-06 17:34:35,127 - speechbrain.utils.train_logger - INFO - epoch: 9, steps: 43488, lr: 6.07e-04 - train loss: 3.46 - valid loss: 3.80, valid accuracy: 2.01e-01
2023-12-06 17:34:37,117 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/bestrq/5000/save/CKPT+2023-12-06+17-34-35+00
2023-12-06 17:34:37,177 - speechbrain.utils.epoch_loop - INFO - Going into epoch 10
2023-12-06 17:34:37,203 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-06 17:34:38,127 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-06 17:34:43,122 - speechbrain.utils.train_logger - INFO - steps: 43500, lr: 6.06e-04, avg_loss: 3.48, run_time: 2.03e+02
2023-12-06 17:37:22,136 - speechbrain.utils.train_logger - INFO - steps: 44000, lr: 6.03e-04, avg_loss: 3.42, run_time: 1.59e+02
2023-12-06 17:40:01,215 - speechbrain.utils.train_logger - INFO - steps: 44500, lr: 6.00e-04, avg_loss: 3.44, run_time: 1.59e+02
2023-12-06 17:42:40,485 - speechbrain.utils.train_logger - INFO - steps: 45000, lr: 5.96e-04, avg_loss: 3.43, run_time: 1.59e+02
2023-12-06 17:45:19,409 - speechbrain.utils.train_logger - INFO - steps: 45500, lr: 5.93e-04, avg_loss: 3.43, run_time: 1.59e+02
2023-12-06 17:47:58,364 - speechbrain.utils.train_logger - INFO - steps: 46000, lr: 5.90e-04, avg_loss: 3.43, run_time: 1.59e+02
2023-12-06 17:50:37,336 - speechbrain.utils.train_logger - INFO - steps: 46500, lr: 5.87e-04, avg_loss: 3.43, run_time: 1.59e+02
2023-12-06 17:53:16,390 - speechbrain.utils.train_logger - INFO - steps: 47000, lr: 5.83e-04, avg_loss: 3.43, run_time: 1.59e+02
2023-12-06 17:55:55,012 - speechbrain.utils.train_logger - INFO - steps: 47500, lr: 5.80e-04, avg_loss: 3.43, run_time: 1.59e+02
2023-12-06 17:58:33,917 - speechbrain.utils.train_logger - INFO - steps: 48000, lr: 5.77e-04, avg_loss: 3.43, run_time: 1.59e+02
2023-12-06 18:00:55,093 - speechbrain.utils.train_logger - INFO - epoch: 10, steps: 48320, lr: 5.75e-04 - train loss: 3.43 - valid loss: 3.79, valid accuracy: 2.05e-01
2023-12-06 18:00:58,242 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/bestrq/5000/save/CKPT+2023-12-06+18-00-55+00
2023-12-06 18:00:58,316 - speechbrain.utils.epoch_loop - INFO - Going into epoch 11
2023-12-06 18:00:58,317 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-06 18:00:59,183 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-06 18:01:57,857 - speechbrain.utils.train_logger - INFO - steps: 48500, lr: 5.74e-04, avg_loss: 3.40, run_time: 2.04e+02
2023-12-06 18:04:36,672 - speechbrain.utils.train_logger - INFO - steps: 49000, lr: 5.71e-04, avg_loss: 3.41, run_time: 1.59e+02
2023-12-06 18:07:15,269 - speechbrain.utils.train_logger - INFO - steps: 49500, lr: 5.69e-04, avg_loss: 3.41, run_time: 1.59e+02
2023-12-06 18:09:54,016 - speechbrain.utils.train_logger - INFO - steps: 50000, lr: 5.66e-04, avg_loss: 3.41, run_time: 1.59e+02
2023-12-06 18:12:32,827 - speechbrain.utils.train_logger - INFO - steps: 50500, lr: 5.63e-04, avg_loss: 3.41, run_time: 1.59e+02
2023-12-06 18:15:11,902 - speechbrain.utils.train_logger - INFO - steps: 51000, lr: 5.60e-04, avg_loss: 3.41, run_time: 1.59e+02
2023-12-06 18:17:50,781 - speechbrain.utils.train_logger - INFO - steps: 51500, lr: 5.57e-04, avg_loss: 3.41, run_time: 1.59e+02
2023-12-06 18:20:29,694 - speechbrain.utils.train_logger - INFO - steps: 52000, lr: 5.55e-04, avg_loss: 3.41, run_time: 1.59e+02
2023-12-06 18:23:08,774 - speechbrain.utils.train_logger - INFO - steps: 52500, lr: 5.52e-04, avg_loss: 3.41, run_time: 1.59e+02
2023-12-06 18:25:47,712 - speechbrain.utils.train_logger - INFO - steps: 53000, lr: 5.49e-04, avg_loss: 3.41, run_time: 1.59e+02
2023-12-06 18:27:15,556 - speechbrain.utils.train_logger - INFO - epoch: 11, steps: 53152, lr: 5.49e-04 - train loss: 3.41 - valid loss: 3.75, valid accuracy: 2.09e-01
2023-12-06 18:27:43,793 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/bestrq/5000/save/CKPT+2023-12-06+18-27-15+00
2023-12-06 18:27:43,915 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/bestrq/5000/save/CKPT+2023-12-06+13-57-07+00
2023-12-06 18:27:43,916 - speechbrain.utils.epoch_loop - INFO - Going into epoch 12
2023-12-06 18:27:43,918 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-06 18:27:44,883 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-06 18:29:37,181 - speechbrain.utils.train_logger - INFO - steps: 53500, lr: 5.47e-04, avg_loss: 3.39, run_time: 2.29e+02
2023-12-06 18:32:16,144 - speechbrain.utils.train_logger - INFO - steps: 54000, lr: 5.44e-04, avg_loss: 3.39, run_time: 1.59e+02
2023-12-06 18:34:55,449 - speechbrain.utils.train_logger - INFO - steps: 54500, lr: 5.42e-04, avg_loss: 3.39, run_time: 1.59e+02
2023-12-06 18:37:34,471 - speechbrain.utils.train_logger - INFO - steps: 55000, lr: 5.39e-04, avg_loss: 3.39, run_time: 1.59e+02
2023-12-06 18:40:13,717 - speechbrain.utils.train_logger - INFO - steps: 55500, lr: 5.37e-04, avg_loss: 3.39, run_time: 1.59e+02
2023-12-06 18:42:53,055 - speechbrain.utils.train_logger - INFO - steps: 56000, lr: 5.35e-04, avg_loss: 3.39, run_time: 1.59e+02
2023-12-06 18:45:32,210 - speechbrain.utils.train_logger - INFO - steps: 56500, lr: 5.32e-04, avg_loss: 3.39, run_time: 1.59e+02
2023-12-06 18:48:11,282 - speechbrain.utils.train_logger - INFO - steps: 57000, lr: 5.30e-04, avg_loss: 3.39, run_time: 1.59e+02
2023-12-06 18:50:50,337 - speechbrain.utils.train_logger - INFO - steps: 57500, lr: 5.28e-04, avg_loss: 3.39, run_time: 1.59e+02
2023-12-06 18:54:03,856 - speechbrain.utils.train_logger - INFO - epoch: 12, steps: 57984, lr: 5.25e-04 - train loss: 3.39 - valid loss: 3.76, valid accuracy: 2.09e-01
2023-12-06 18:55:19,582 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/bestrq/5000/save/CKPT+2023-12-06+18-54-03+00
2023-12-06 18:55:19,731 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/bestrq/5000/save/CKPT+2023-12-06+14-23-27+00
2023-12-06 18:55:19,732 - speechbrain.utils.epoch_loop - INFO - Going into epoch 13
2023-12-06 18:55:19,733 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-06 18:55:20,504 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-06 18:55:27,225 - speechbrain.utils.train_logger - INFO - steps: 58000, lr: 5.25e-04, avg_loss: 3.33, run_time: 2.77e+02
2023-12-06 18:58:06,205 - speechbrain.utils.train_logger - INFO - steps: 58500, lr: 5.23e-04, avg_loss: 3.38, run_time: 1.59e+02
2023-12-06 19:00:45,229 - speechbrain.utils.train_logger - INFO - steps: 59000, lr: 5.21e-04, avg_loss: 3.38, run_time: 1.59e+02
2023-12-06 19:03:24,315 - speechbrain.utils.train_logger - INFO - steps: 59500, lr: 5.19e-04, avg_loss: 3.37, run_time: 1.59e+02
2023-12-06 19:06:03,462 - speechbrain.utils.train_logger - INFO - steps: 60000, lr: 5.16e-04, avg_loss: 3.37, run_time: 1.59e+02
2023-12-06 19:08:42,525 - speechbrain.utils.train_logger - INFO - steps: 60500, lr: 5.14e-04, avg_loss: 3.37, run_time: 1.59e+02
2023-12-06 19:11:21,447 - speechbrain.utils.train_logger - INFO - steps: 61000, lr: 5.12e-04, avg_loss: 3.37, run_time: 1.59e+02
2023-12-06 19:14:00,502 - speechbrain.utils.train_logger - INFO - steps: 61500, lr: 5.10e-04, avg_loss: 3.37, run_time: 1.59e+02
2023-12-06 19:16:39,548 - speechbrain.utils.train_logger - INFO - steps: 62000, lr: 5.08e-04, avg_loss: 3.37, run_time: 1.59e+02
2023-12-06 19:19:18,878 - speechbrain.utils.train_logger - INFO - steps: 62500, lr: 5.06e-04, avg_loss: 3.37, run_time: 1.59e+02
2023-12-06 19:21:39,612 - speechbrain.utils.train_logger - INFO - epoch: 13, steps: 62816, lr: 5.05e-04 - train loss: 3.37 - valid loss: 3.73, valid accuracy: 2.11e-01
2023-12-06 19:21:41,270 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/bestrq/5000/save/CKPT+2023-12-06+19-21-39+00
2023-12-06 19:21:41,446 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/bestrq/5000/save/CKPT+2023-12-06+14-49-48+00
2023-12-06 19:21:41,446 - speechbrain.utils.epoch_loop - INFO - Going into epoch 14
2023-12-06 19:21:41,448 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-06 19:21:42,226 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-06 19:22:42,204 - speechbrain.utils.train_logger - INFO - steps: 63000, lr: 5.04e-04, avg_loss: 3.35, run_time: 2.03e+02
2023-12-06 19:25:21,501 - speechbrain.utils.train_logger - INFO - steps: 63500, lr: 5.02e-04, avg_loss: 3.35, run_time: 1.59e+02
2023-12-06 19:28:00,622 - speechbrain.utils.train_logger - INFO - steps: 64000, lr: 5.00e-04, avg_loss: 3.36, run_time: 1.59e+02
2023-12-06 19:30:39,977 - speechbrain.utils.train_logger - INFO - steps: 64500, lr: 4.98e-04, avg_loss: 3.36, run_time: 1.59e+02
2023-12-06 19:33:18,882 - speechbrain.utils.train_logger - INFO - steps: 65000, lr: 4.96e-04, avg_loss: 3.36, run_time: 1.59e+02
2023-12-06 19:35:57,979 - speechbrain.utils.train_logger - INFO - steps: 65500, lr: 4.94e-04, avg_loss: 3.36, run_time: 1.59e+02
2023-12-06 19:38:37,109 - speechbrain.utils.train_logger - INFO - steps: 66000, lr: 4.92e-04, avg_loss: 3.36, run_time: 1.59e+02
2023-12-06 19:41:16,463 - speechbrain.utils.train_logger - INFO - steps: 66500, lr: 4.91e-04, avg_loss: 3.36, run_time: 1.59e+02
2023-12-06 19:43:55,893 - speechbrain.utils.train_logger - INFO - steps: 67000, lr: 4.89e-04, avg_loss: 3.37, run_time: 1.59e+02
2023-12-06 19:46:35,390 - speechbrain.utils.train_logger - INFO - steps: 67500, lr: 4.87e-04, avg_loss: 3.36, run_time: 1.60e+02
2023-12-06 19:48:02,363 - speechbrain.utils.train_logger - INFO - epoch: 14, steps: 67648, lr: 4.86e-04 - train loss: 3.36 - valid loss: 3.72, valid accuracy: 2.10e-01
2023-12-06 19:48:04,113 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/bestrq/5000/save/CKPT+2023-12-06+19-48-02+00
2023-12-06 19:48:04,235 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/bestrq/5000/save/CKPT+2023-12-06+15-16-10+00
2023-12-06 19:48:04,235 - speechbrain.utils.epoch_loop - INFO - Going into epoch 15
2023-12-06 19:48:04,237 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-06 19:48:05,001 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-06 19:49:58,940 - speechbrain.utils.train_logger - INFO - steps: 68000, lr: 4.85e-04, avg_loss: 3.36, run_time: 2.04e+02
2023-12-06 19:52:38,245 - speechbrain.utils.train_logger - INFO - steps: 68500, lr: 4.83e-04, avg_loss: 3.35, run_time: 1.59e+02
2023-12-06 19:55:17,725 - speechbrain.utils.train_logger - INFO - steps: 69000, lr: 4.82e-04, avg_loss: 3.35, run_time: 1.59e+02
2023-12-06 19:57:57,154 - speechbrain.utils.train_logger - INFO - steps: 69500, lr: 4.80e-04, avg_loss: 3.35, run_time: 1.59e+02
2023-12-06 20:00:36,534 - speechbrain.utils.train_logger - INFO - steps: 70000, lr: 4.78e-04, avg_loss: 3.35, run_time: 1.59e+02
2023-12-06 20:03:15,872 - speechbrain.utils.train_logger - INFO - steps: 70500, lr: 4.76e-04, avg_loss: 3.34, run_time: 1.59e+02
2023-12-06 20:05:55,202 - speechbrain.utils.train_logger - INFO - steps: 71000, lr: 4.75e-04, avg_loss: 3.34, run_time: 1.59e+02
2023-12-06 20:08:34,540 - speechbrain.utils.train_logger - INFO - steps: 71500, lr: 4.73e-04, avg_loss: 3.35, run_time: 1.59e+02
2023-12-06 20:11:13,845 - speechbrain.utils.train_logger - INFO - steps: 72000, lr: 4.71e-04, avg_loss: 3.34, run_time: 1.59e+02
2023-12-06 20:14:26,418 - speechbrain.utils.train_logger - INFO - epoch: 15, steps: 72480, lr: 4.70e-04 - train loss: 3.35 - valid loss: 3.70, valid accuracy: 2.14e-01
2023-12-06 20:15:02,190 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/bestrq/5000/save/CKPT+2023-12-06+20-14-26+00
2023-12-06 20:15:02,357 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/bestrq/5000/save/CKPT+2023-12-06+15-47-01+00
2023-12-06 20:15:02,357 - speechbrain.utils.epoch_loop - INFO - Going into epoch 16
2023-12-06 20:15:02,359 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-06 20:15:03,320 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-06 20:15:11,365 - speechbrain.utils.train_logger - INFO - steps: 72500, lr: 4.70e-04, avg_loss: 3.33, run_time: 2.38e+02
2023-12-06 20:17:50,728 - speechbrain.utils.train_logger - INFO - steps: 73000, lr: 4.68e-04, avg_loss: 3.34, run_time: 1.59e+02
2023-12-06 20:20:29,837 - speechbrain.utils.train_logger - INFO - steps: 73500, lr: 4.67e-04, avg_loss: 3.34, run_time: 1.59e+02
2023-12-06 20:23:09,317 - speechbrain.utils.train_logger - INFO - steps: 74000, lr: 4.65e-04, avg_loss: 3.33, run_time: 1.59e+02
2023-12-06 20:25:48,572 - speechbrain.utils.train_logger - INFO - steps: 74500, lr: 4.63e-04, avg_loss: 3.34, run_time: 1.59e+02
2023-12-06 20:28:28,060 - speechbrain.utils.train_logger - INFO - steps: 75000, lr: 4.62e-04, avg_loss: 3.33, run_time: 1.59e+02
2023-12-06 20:31:07,165 - speechbrain.utils.train_logger - INFO - steps: 75500, lr: 4.60e-04, avg_loss: 3.34, run_time: 1.59e+02
2023-12-06 20:33:46,182 - speechbrain.utils.train_logger - INFO - steps: 76000, lr: 4.59e-04, avg_loss: 3.34, run_time: 1.59e+02
2023-12-06 20:36:24,825 - speechbrain.utils.train_logger - INFO - steps: 76500, lr: 4.57e-04, avg_loss: 3.34, run_time: 1.59e+02
2023-12-06 20:39:03,646 - speechbrain.utils.train_logger - INFO - steps: 77000, lr: 4.56e-04, avg_loss: 3.34, run_time: 1.59e+02
2023-12-06 20:41:22,505 - speechbrain.utils.train_logger - INFO - epoch: 16, steps: 77312, lr: 4.55e-04 - train loss: 3.34 - valid loss: 3.64, valid accuracy: 2.20e-01
2023-12-06 20:41:46,646 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/bestrq/5000/save/CKPT+2023-12-06+20-41-22+00
2023-12-06 20:41:46,784 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/bestrq/5000/save/CKPT+2023-12-06+16-15-21+00
2023-12-06 20:41:46,784 - speechbrain.utils.epoch_loop - INFO - Going into epoch 17
2023-12-06 20:41:46,786 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-06 20:41:47,698 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-06 20:42:49,057 - speechbrain.utils.train_logger - INFO - steps: 77500, lr: 4.54e-04, avg_loss: 3.33, run_time: 2.25e+02
2023-12-06 20:45:28,345 - speechbrain.utils.train_logger - INFO - steps: 78000, lr: 4.53e-04, avg_loss: 3.32, run_time: 1.59e+02
2023-12-06 20:48:07,667 - speechbrain.utils.train_logger - INFO - steps: 78500, lr: 4.51e-04, avg_loss: 3.32, run_time: 1.59e+02
2023-12-06 20:50:46,896 - speechbrain.utils.train_logger - INFO - steps: 79000, lr: 4.50e-04, avg_loss: 3.32, run_time: 1.59e+02
2023-12-06 20:53:26,001 - speechbrain.utils.train_logger - INFO - steps: 79500, lr: 4.49e-04, avg_loss: 3.32, run_time: 1.59e+02
2023-12-06 20:56:05,381 - speechbrain.utils.train_logger - INFO - steps: 80000, lr: 4.47e-04, avg_loss: 3.32, run_time: 1.59e+02
2023-12-06 20:58:44,694 - speechbrain.utils.train_logger - INFO - steps: 80500, lr: 4.46e-04, avg_loss: 3.32, run_time: 1.59e+02
2023-12-06 21:01:24,041 - speechbrain.utils.train_logger - INFO - steps: 81000, lr: 4.44e-04, avg_loss: 3.33, run_time: 1.59e+02
2023-12-06 21:04:04,255 - speechbrain.utils.train_logger - INFO - steps: 81500, lr: 4.43e-04, avg_loss: 3.33, run_time: 1.60e+02
2023-12-06 21:06:43,675 - speechbrain.utils.train_logger - INFO - steps: 82000, lr: 4.42e-04, avg_loss: 3.33, run_time: 1.59e+02
2023-12-06 21:08:09,111 - speechbrain.utils.train_logger - INFO - epoch: 17, steps: 82144, lr: 4.41e-04 - train loss: 3.33 - valid loss: 3.68, valid accuracy: 2.15e-01
2023-12-06 21:08:10,652 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/bestrq/5000/save/CKPT+2023-12-06+21-08-09+00
2023-12-06 21:08:10,803 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/bestrq/5000/save/CKPT+2023-12-06+16-41-44+00
2023-12-06 21:08:10,804 - speechbrain.utils.epoch_loop - INFO - Going into epoch 18
2023-12-06 21:08:10,806 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-06 21:08:11,720 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-06 21:10:06,851 - speechbrain.utils.train_logger - INFO - steps: 82500, lr: 4.40e-04, avg_loss: 3.32, run_time: 2.03e+02
2023-12-06 21:12:46,788 - speechbrain.utils.train_logger - INFO - steps: 83000, lr: 4.39e-04, avg_loss: 3.33, run_time: 1.60e+02
2023-12-06 21:15:26,452 - speechbrain.utils.train_logger - INFO - steps: 83500, lr: 4.38e-04, avg_loss: 3.32, run_time: 1.60e+02
2023-12-06 21:18:05,648 - speechbrain.utils.train_logger - INFO - steps: 84000, lr: 4.36e-04, avg_loss: 3.32, run_time: 1.59e+02
2023-12-06 21:20:44,711 - speechbrain.utils.train_logger - INFO - steps: 84500, lr: 4.35e-04, avg_loss: 3.32, run_time: 1.59e+02
2023-12-06 21:23:24,291 - speechbrain.utils.train_logger - INFO - steps: 85000, lr: 4.34e-04, avg_loss: 3.32, run_time: 1.60e+02
2023-12-06 21:26:04,096 - speechbrain.utils.train_logger - INFO - steps: 85500, lr: 4.33e-04, avg_loss: 3.32, run_time: 1.60e+02
2023-12-06 21:28:43,592 - speechbrain.utils.train_logger - INFO - steps: 86000, lr: 4.31e-04, avg_loss: 3.32, run_time: 1.60e+02
2023-12-06 21:31:23,163 - speechbrain.utils.train_logger - INFO - steps: 86500, lr: 4.30e-04, avg_loss: 3.32, run_time: 1.60e+02
2023-12-06 21:34:34,741 - speechbrain.utils.train_logger - INFO - epoch: 18, steps: 86976, lr: 4.29e-04 - train loss: 3.32 - valid loss: 3.67, valid accuracy: 2.15e-01
2023-12-06 21:36:31,489 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/bestrq/5000/save/CKPT+2023-12-06+21-34-34+00
2023-12-06 21:36:31,650 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/bestrq/5000/save/CKPT+2023-12-06+17-08-07+00
2023-12-06 21:36:31,650 - speechbrain.utils.epoch_loop - INFO - Going into epoch 19
2023-12-06 21:36:31,652 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-06 21:36:32,492 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-06 21:36:41,473 - speechbrain.utils.train_logger - INFO - steps: 87000, lr: 4.29e-04, avg_loss: 3.30, run_time: 3.18e+02
2023-12-06 21:39:20,345 - speechbrain.utils.train_logger - INFO - steps: 87500, lr: 4.28e-04, avg_loss: 3.30, run_time: 1.59e+02
2023-12-06 21:41:59,058 - speechbrain.utils.train_logger - INFO - steps: 88000, lr: 4.26e-04, avg_loss: 3.31, run_time: 1.59e+02
2023-12-06 21:44:38,021 - speechbrain.utils.train_logger - INFO - steps: 88500, lr: 4.25e-04, avg_loss: 3.31, run_time: 1.59e+02
2023-12-06 21:47:17,176 - speechbrain.utils.train_logger - INFO - steps: 89000, lr: 4.24e-04, avg_loss: 3.31, run_time: 1.59e+02
2023-12-06 21:49:57,447 - speechbrain.utils.train_logger - INFO - steps: 89500, lr: 4.23e-04, avg_loss: 3.31, run_time: 1.60e+02
2023-12-06 21:52:37,243 - speechbrain.utils.train_logger - INFO - steps: 90000, lr: 4.22e-04, avg_loss: 3.31, run_time: 1.60e+02
2023-12-06 21:55:17,098 - speechbrain.utils.train_logger - INFO - steps: 90500, lr: 4.20e-04, avg_loss: 3.31, run_time: 1.60e+02
2023-12-06 21:57:56,644 - speechbrain.utils.train_logger - INFO - steps: 91000, lr: 4.19e-04, avg_loss: 3.31, run_time: 1.60e+02
2023-12-06 22:00:36,741 - speechbrain.utils.train_logger - INFO - steps: 91500, lr: 4.18e-04, avg_loss: 3.31, run_time: 1.60e+02
2023-12-06 22:02:54,989 - speechbrain.utils.train_logger - INFO - epoch: 19, steps: 91808, lr: 4.17e-04 - train loss: 3.31 - valid loss: 3.68, valid accuracy: 2.17e-01
2023-12-06 22:06:19,325 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/bestrq/5000/save/CKPT+2023-12-06+22-02-54+00
2023-12-06 22:06:19,507 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/bestrq/5000/save/CKPT+2023-12-06+17-34-35+00
2023-12-06 22:06:19,508 - speechbrain.utils.epoch_loop - INFO - Going into epoch 20
2023-12-06 22:06:19,510 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-06 22:06:20,297 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-06 22:07:22,392 - speechbrain.utils.train_logger - INFO - steps: 92000, lr: 4.17e-04, avg_loss: 3.30, run_time: 4.06e+02
2023-12-06 22:10:01,805 - speechbrain.utils.train_logger - INFO - steps: 92500, lr: 4.16e-04, avg_loss: 3.30, run_time: 1.59e+02
2023-12-06 22:12:40,885 - speechbrain.utils.train_logger - INFO - steps: 93000, lr: 4.15e-04, avg_loss: 3.30, run_time: 1.59e+02
2023-12-06 22:15:20,548 - speechbrain.utils.train_logger - INFO - steps: 93500, lr: 4.14e-04, avg_loss: 3.30, run_time: 1.60e+02
2023-12-06 22:18:00,137 - speechbrain.utils.train_logger - INFO - steps: 94000, lr: 4.13e-04, avg_loss: 3.30, run_time: 1.60e+02
2023-12-06 22:20:39,858 - speechbrain.utils.train_logger - INFO - steps: 94500, lr: 4.11e-04, avg_loss: 3.30, run_time: 1.60e+02
2023-12-06 22:23:19,413 - speechbrain.utils.train_logger - INFO - steps: 95000, lr: 4.10e-04, avg_loss: 3.30, run_time: 1.60e+02
2023-12-06 22:25:59,342 - speechbrain.utils.train_logger - INFO - steps: 95500, lr: 4.09e-04, avg_loss: 3.30, run_time: 1.60e+02
2023-12-06 22:28:38,839 - speechbrain.utils.train_logger - INFO - steps: 96000, lr: 4.08e-04, avg_loss: 3.30, run_time: 1.59e+02
2023-12-06 22:31:18,260 - speechbrain.utils.train_logger - INFO - steps: 96500, lr: 4.07e-04, avg_loss: 3.30, run_time: 1.59e+02
2023-12-06 22:32:42,371 - speechbrain.utils.train_logger - INFO - epoch: 20, steps: 96640, lr: 4.07e-04 - train loss: 3.30 - valid loss: 3.65, valid accuracy: 2.17e-01
2023-12-06 22:32:44,129 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/bestrq/5000/save/CKPT+2023-12-06+22-32-42+00
2023-12-06 22:32:44,337 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/bestrq/5000/save/CKPT+2023-12-06+18-00-55+00
2023-12-06 22:32:44,337 - speechbrain.utils.epoch_loop - INFO - Going into epoch 21
2023-12-06 22:32:44,339 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-06 22:32:45,117 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-06 22:34:41,244 - speechbrain.utils.train_logger - INFO - steps: 97000, lr: 4.06e-04, avg_loss: 3.31, run_time: 2.03e+02
2023-12-06 22:37:20,366 - speechbrain.utils.train_logger - INFO - steps: 97500, lr: 4.05e-04, avg_loss: 3.29, run_time: 1.59e+02
2023-12-06 22:39:59,388 - speechbrain.utils.train_logger - INFO - steps: 98000, lr: 4.04e-04, avg_loss: 3.30, run_time: 1.59e+02
2023-12-06 22:42:39,152 - speechbrain.utils.train_logger - INFO - steps: 98500, lr: 4.03e-04, avg_loss: 3.29, run_time: 1.60e+02
2023-12-06 22:45:18,439 - speechbrain.utils.train_logger - INFO - steps: 99000, lr: 4.02e-04, avg_loss: 3.29, run_time: 1.59e+02
2023-12-06 22:47:57,902 - speechbrain.utils.train_logger - INFO - steps: 99500, lr: 4.01e-04, avg_loss: 3.29, run_time: 1.59e+02
2023-12-06 22:50:37,415 - speechbrain.utils.train_logger - INFO - steps: 100000, lr: 4.00e-04, avg_loss: 3.29, run_time: 1.60e+02
2023-12-06 22:53:17,220 - speechbrain.utils.train_logger - INFO - steps: 100500, lr: 3.99e-04, avg_loss: 3.29, run_time: 1.60e+02
2023-12-06 22:55:56,974 - speechbrain.utils.train_logger - INFO - steps: 101000, lr: 3.98e-04, avg_loss: 3.29, run_time: 1.60e+02
2023-12-06 22:59:07,284 - speechbrain.utils.train_logger - INFO - epoch: 21, steps: 101472, lr: 3.97e-04 - train loss: 3.30 - valid loss: 3.66, valid accuracy: 2.17e-01
2023-12-06 23:00:52,825 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/bestrq/5000/save/CKPT+2023-12-06+22-59-07+00
2023-12-06 23:00:53,046 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/bestrq/5000/save/CKPT+2023-12-06+18-27-15+00
2023-12-06 23:00:53,046 - speechbrain.utils.epoch_loop - INFO - Going into epoch 22
2023-12-06 23:00:53,048 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-06 23:00:53,824 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-06 23:01:04,462 - speechbrain.utils.train_logger - INFO - steps: 101500, lr: 3.97e-04, avg_loss: 3.25, run_time: 3.07e+02
2023-12-06 23:03:44,234 - speechbrain.utils.train_logger - INFO - steps: 102000, lr: 3.96e-04, avg_loss: 3.30, run_time: 1.60e+02
2023-12-06 23:06:24,138 - speechbrain.utils.train_logger - INFO - steps: 102500, lr: 3.95e-04, avg_loss: 3.29, run_time: 1.60e+02
2023-12-06 23:09:03,993 - speechbrain.utils.train_logger - INFO - steps: 103000, lr: 3.94e-04, avg_loss: 3.29, run_time: 1.60e+02
2023-12-06 23:11:44,056 - speechbrain.utils.train_logger - INFO - steps: 103500, lr: 3.93e-04, avg_loss: 3.29, run_time: 1.60e+02
2023-12-06 23:14:24,153 - speechbrain.utils.train_logger - INFO - steps: 104000, lr: 3.92e-04, avg_loss: 3.29, run_time: 1.60e+02
2023-12-06 23:17:04,232 - speechbrain.utils.train_logger - INFO - steps: 104500, lr: 3.91e-04, avg_loss: 3.29, run_time: 1.60e+02
2023-12-06 23:19:44,794 - speechbrain.utils.train_logger - INFO - steps: 105000, lr: 3.90e-04, avg_loss: 3.29, run_time: 1.61e+02
2023-12-06 23:22:24,824 - speechbrain.utils.train_logger - INFO - steps: 105500, lr: 3.89e-04, avg_loss: 3.29, run_time: 1.60e+02
2023-12-06 23:25:04,695 - speechbrain.utils.train_logger - INFO - steps: 106000, lr: 3.89e-04, avg_loss: 3.28, run_time: 1.60e+02
2023-12-06 23:27:21,760 - speechbrain.utils.train_logger - INFO - epoch: 22, steps: 106304, lr: 3.88e-04 - train loss: 3.28 - valid loss: 3.63, valid accuracy: 2.19e-01
2023-12-06 23:30:55,188 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/bestrq/5000/save/CKPT+2023-12-06+23-27-21+00
2023-12-06 23:30:55,429 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/bestrq/5000/save/CKPT+2023-12-06+18-54-03+00
2023-12-06 23:30:55,430 - speechbrain.utils.epoch_loop - INFO - Going into epoch 23
2023-12-06 23:30:55,432 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-06 23:30:56,377 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-06 23:32:00,435 - speechbrain.utils.train_logger - INFO - steps: 106500, lr: 3.88e-04, avg_loss: 3.29, run_time: 4.16e+02
2023-12-06 23:34:39,823 - speechbrain.utils.train_logger - INFO - steps: 107000, lr: 3.87e-04, avg_loss: 3.29, run_time: 1.59e+02
2023-12-06 23:37:19,375 - speechbrain.utils.train_logger - INFO - steps: 107500, lr: 3.86e-04, avg_loss: 3.28, run_time: 1.60e+02
2023-12-06 23:39:58,770 - speechbrain.utils.train_logger - INFO - steps: 108000, lr: 3.85e-04, avg_loss: 3.29, run_time: 1.59e+02
2023-12-06 23:42:38,288 - speechbrain.utils.train_logger - INFO - steps: 108500, lr: 3.84e-04, avg_loss: 3.29, run_time: 1.60e+02
2023-12-06 23:45:18,026 - speechbrain.utils.train_logger - INFO - steps: 109000, lr: 3.83e-04, avg_loss: 3.29, run_time: 1.60e+02
2023-12-06 23:47:57,547 - speechbrain.utils.train_logger - INFO - steps: 109500, lr: 3.82e-04, avg_loss: 3.29, run_time: 1.60e+02
2023-12-06 23:50:37,344 - speechbrain.utils.train_logger - INFO - steps: 110000, lr: 3.81e-04, avg_loss: 3.28, run_time: 1.60e+02
2023-12-06 23:53:17,149 - speechbrain.utils.train_logger - INFO - steps: 110500, lr: 3.81e-04, avg_loss: 3.28, run_time: 1.60e+02
2023-12-06 23:55:56,603 - speechbrain.utils.train_logger - INFO - steps: 111000, lr: 3.80e-04, avg_loss: 3.28, run_time: 1.59e+02
2023-12-06 23:57:19,672 - speechbrain.utils.train_logger - INFO - epoch: 23, steps: 111136, lr: 3.79e-04 - train loss: 3.28 - valid loss: 3.65, valid accuracy: 2.19e-01
2023-12-06 23:58:17,532 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/bestrq/5000/save/CKPT+2023-12-06+23-57-19+00
2023-12-06 23:58:17,786 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/bestrq/5000/save/CKPT+2023-12-06+19-21-39+00
2023-12-06 23:58:17,786 - speechbrain.utils.epoch_loop - INFO - Going into epoch 24
2023-12-06 23:58:17,788 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-06 23:58:18,702 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-07 00:00:16,323 - speechbrain.utils.train_logger - INFO - steps: 111500, lr: 3.79e-04, avg_loss: 3.27, run_time: 2.60e+02
2023-12-07 00:02:55,926 - speechbrain.utils.train_logger - INFO - steps: 112000, lr: 3.78e-04, avg_loss: 3.27, run_time: 1.60e+02
2023-12-07 00:05:35,672 - speechbrain.utils.train_logger - INFO - steps: 112500, lr: 3.77e-04, avg_loss: 3.27, run_time: 1.60e+02
2023-12-07 00:08:15,527 - speechbrain.utils.train_logger - INFO - steps: 113000, lr: 3.76e-04, avg_loss: 3.28, run_time: 1.60e+02
2023-12-07 00:10:55,723 - speechbrain.utils.train_logger - INFO - steps: 113500, lr: 3.75e-04, avg_loss: 3.28, run_time: 1.60e+02
2023-12-07 00:13:35,928 - speechbrain.utils.train_logger - INFO - steps: 114000, lr: 3.75e-04, avg_loss: 3.28, run_time: 1.60e+02
2023-12-07 00:16:15,858 - speechbrain.utils.train_logger - INFO - steps: 114500, lr: 3.74e-04, avg_loss: 3.28, run_time: 1.60e+02
2023-12-07 00:18:55,721 - speechbrain.utils.train_logger - INFO - steps: 115000, lr: 3.73e-04, avg_loss: 3.28, run_time: 1.60e+02
2023-12-07 00:21:35,867 - speechbrain.utils.train_logger - INFO - steps: 115500, lr: 3.72e-04, avg_loss: 3.28, run_time: 1.60e+02
2023-12-07 00:24:44,684 - speechbrain.utils.train_logger - INFO - epoch: 24, steps: 115968, lr: 3.71e-04 - train loss: 3.28 - valid loss: 3.66, valid accuracy: 2.19e-01
2023-12-07 00:25:53,149 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/bestrq/5000/save/CKPT+2023-12-07+00-24-44+00
2023-12-07 00:25:53,382 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/bestrq/5000/save/CKPT+2023-12-06+19-48-02+00
2023-12-07 00:25:53,383 - speechbrain.utils.epoch_loop - INFO - Going into epoch 25
2023-12-07 00:25:53,384 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-07 00:25:54,245 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-07 00:26:05,749 - speechbrain.utils.train_logger - INFO - steps: 116000, lr: 3.71e-04, avg_loss: 3.25, run_time: 2.70e+02
2023-12-07 00:28:44,687 - speechbrain.utils.train_logger - INFO - steps: 116500, lr: 3.71e-04, avg_loss: 3.27, run_time: 1.59e+02
2023-12-07 00:31:23,384 - speechbrain.utils.train_logger - INFO - steps: 117000, lr: 3.70e-04, avg_loss: 3.28, run_time: 1.59e+02
2023-12-07 00:34:02,272 - speechbrain.utils.train_logger - INFO - steps: 117500, lr: 3.69e-04, avg_loss: 3.28, run_time: 1.59e+02
2023-12-07 00:36:41,227 - speechbrain.utils.train_logger - INFO - steps: 118000, lr: 3.68e-04, avg_loss: 3.28, run_time: 1.59e+02
2023-12-07 00:39:20,290 - speechbrain.utils.train_logger - INFO - steps: 118500, lr: 3.67e-04, avg_loss: 3.28, run_time: 1.59e+02
2023-12-07 00:41:59,695 - speechbrain.utils.train_logger - INFO - steps: 119000, lr: 3.67e-04, avg_loss: 3.28, run_time: 1.59e+02
2023-12-07 00:44:39,241 - speechbrain.utils.train_logger - INFO - steps: 119500, lr: 3.66e-04, avg_loss: 3.27, run_time: 1.60e+02
2023-12-07 00:47:18,896 - speechbrain.utils.train_logger - INFO - steps: 120000, lr: 3.65e-04, avg_loss: 3.27, run_time: 1.60e+02
2023-12-07 00:49:58,701 - speechbrain.utils.train_logger - INFO - steps: 120500, lr: 3.64e-04, avg_loss: 3.27, run_time: 1.60e+02
2023-12-07 00:52:14,051 - speechbrain.utils.train_logger - INFO - epoch: 25, steps: 120800, lr: 3.64e-04 - train loss: 3.27 - valid loss: 3.67, valid accuracy: 2.18e-01
2023-12-07 00:56:13,935 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/bestrq/5000/save/CKPT+2023-12-07+00-52-14+00
2023-12-07 00:56:14,164 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/bestrq/5000/save/CKPT+2023-12-06+20-14-26+00
2023-12-07 00:56:14,164 - speechbrain.utils.epoch_loop - INFO - Going into epoch 26
2023-12-07 00:56:14,166 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-07 00:56:15,129 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-07 00:57:20,301 - speechbrain.utils.train_logger - INFO - steps: 121000, lr: 3.64e-04, avg_loss: 3.24, run_time: 4.42e+02
2023-12-07 00:59:59,514 - speechbrain.utils.train_logger - INFO - steps: 121500, lr: 3.63e-04, avg_loss: 3.26, run_time: 1.59e+02
2023-12-07 01:02:39,352 - speechbrain.utils.train_logger - INFO - steps: 122000, lr: 3.62e-04, avg_loss: 3.26, run_time: 1.60e+02
2023-12-07 01:05:19,032 - speechbrain.utils.train_logger - INFO - steps: 122500, lr: 3.61e-04, avg_loss: 3.26, run_time: 1.60e+02
2023-12-07 01:07:58,795 - speechbrain.utils.train_logger - INFO - steps: 123000, lr: 3.61e-04, avg_loss: 3.26, run_time: 1.60e+02
2023-12-07 01:10:38,274 - speechbrain.utils.train_logger - INFO - steps: 123500, lr: 3.60e-04, avg_loss: 3.26, run_time: 1.59e+02
2023-12-07 01:13:17,837 - speechbrain.utils.train_logger - INFO - steps: 124000, lr: 3.59e-04, avg_loss: 3.26, run_time: 1.60e+02
2023-12-07 01:15:57,217 - speechbrain.utils.train_logger - INFO - steps: 124500, lr: 3.58e-04, avg_loss: 3.27, run_time: 1.59e+02
2023-12-07 01:18:36,639 - speechbrain.utils.train_logger - INFO - steps: 125000, lr: 3.58e-04, avg_loss: 3.26, run_time: 1.59e+02
2023-12-07 01:21:16,352 - speechbrain.utils.train_logger - INFO - steps: 125500, lr: 3.57e-04, avg_loss: 3.26, run_time: 1.60e+02
2023-12-07 01:22:37,943 - speechbrain.utils.train_logger - INFO - epoch: 26, steps: 125632, lr: 3.57e-04 - train loss: 3.27 - valid loss: 3.65, valid accuracy: 2.18e-01
2023-12-07 01:24:26,640 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/bestrq/5000/save/CKPT+2023-12-07+01-22-37+00
2023-12-07 01:24:26,888 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/bestrq/5000/save/CKPT+2023-12-06+20-41-22+00
2023-12-07 01:24:26,889 - speechbrain.utils.epoch_loop - INFO - Going into epoch 27
2023-12-07 01:24:26,891 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-07 01:24:27,648 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-07 01:26:26,347 - speechbrain.utils.train_logger - INFO - steps: 126000, lr: 3.56e-04, avg_loss: 3.27, run_time: 3.10e+02
2023-12-07 01:29:05,219 - speechbrain.utils.train_logger - INFO - steps: 126500, lr: 3.56e-04, avg_loss: 3.27, run_time: 1.59e+02
2023-12-07 01:31:44,590 - speechbrain.utils.train_logger - INFO - steps: 127000, lr: 3.55e-04, avg_loss: 3.27, run_time: 1.59e+02
2023-12-07 01:34:24,229 - speechbrain.utils.train_logger - INFO - steps: 127500, lr: 3.54e-04, avg_loss: 3.26, run_time: 1.60e+02
2023-12-07 01:37:04,108 - speechbrain.utils.train_logger - INFO - steps: 128000, lr: 3.54e-04, avg_loss: 3.26, run_time: 1.60e+02
2023-12-07 01:39:43,579 - speechbrain.utils.train_logger - INFO - steps: 128500, lr: 3.53e-04, avg_loss: 3.26, run_time: 1.60e+02
2023-12-07 01:42:22,636 - speechbrain.utils.train_logger - INFO - steps: 129000, lr: 3.52e-04, avg_loss: 3.26, run_time: 1.59e+02
2023-12-07 01:45:01,772 - speechbrain.utils.train_logger - INFO - steps: 129500, lr: 3.51e-04, avg_loss: 3.26, run_time: 1.59e+02
2023-12-07 01:47:41,040 - speechbrain.utils.train_logger - INFO - steps: 130000, lr: 3.51e-04, avg_loss: 3.26, run_time: 1.59e+02
2023-12-07 01:50:48,551 - speechbrain.utils.train_logger - INFO - epoch: 27, steps: 130464, lr: 3.50e-04 - train loss: 3.26 - valid loss: 3.65, valid accuracy: 2.18e-01
2023-12-07 01:53:46,080 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/bestrq/5000/save/CKPT+2023-12-07+01-50-48+00
2023-12-07 01:53:46,357 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/bestrq/5000/save/CKPT+2023-12-06+21-08-09+00
2023-12-07 01:53:46,357 - speechbrain.utils.epoch_loop - INFO - Going into epoch 28
2023-12-07 01:53:46,359 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-07 01:53:47,076 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-07 01:54:00,147 - speechbrain.utils.train_logger - INFO - steps: 130500, lr: 3.50e-04, avg_loss: 3.22, run_time: 3.79e+02
2023-12-07 01:56:38,961 - speechbrain.utils.train_logger - INFO - steps: 131000, lr: 3.49e-04, avg_loss: 3.25, run_time: 1.59e+02
2023-12-07 01:59:17,908 - speechbrain.utils.train_logger - INFO - steps: 131500, lr: 3.49e-04, avg_loss: 3.25, run_time: 1.59e+02
2023-12-07 02:01:56,706 - speechbrain.utils.train_logger - INFO - steps: 132000, lr: 3.48e-04, avg_loss: 3.25, run_time: 1.59e+02
2023-12-07 02:04:35,994 - speechbrain.utils.train_logger - INFO - steps: 132500, lr: 3.47e-04, avg_loss: 3.25, run_time: 1.59e+02
2023-12-07 02:07:15,325 - speechbrain.utils.train_logger - INFO - steps: 133000, lr: 3.47e-04, avg_loss: 3.26, run_time: 1.59e+02
2023-12-07 02:09:54,797 - speechbrain.utils.train_logger - INFO - steps: 133500, lr: 3.46e-04, avg_loss: 3.26, run_time: 1.59e+02
2023-12-07 02:12:34,411 - speechbrain.utils.train_logger - INFO - steps: 134000, lr: 3.46e-04, avg_loss: 3.26, run_time: 1.60e+02
2023-12-07 02:15:13,766 - speechbrain.utils.train_logger - INFO - steps: 134500, lr: 3.45e-04, avg_loss: 3.26, run_time: 1.59e+02
2023-12-07 02:17:53,133 - speechbrain.utils.train_logger - INFO - steps: 135000, lr: 3.44e-04, avg_loss: 3.26, run_time: 1.59e+02
2023-12-07 02:20:07,174 - speechbrain.utils.train_logger - INFO - epoch: 28, steps: 135296, lr: 3.44e-04 - train loss: 3.26 - valid loss: 3.63, valid accuracy: 2.20e-01
2023-12-07 02:21:23,978 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/bestrq/5000/save/CKPT+2023-12-07+02-20-07+00
2023-12-07 02:21:24,257 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/bestrq/5000/save/CKPT+2023-12-06+21-34-34+00
2023-12-07 02:21:24,257 - speechbrain.utils.epoch_loop - INFO - Going into epoch 29
2023-12-07 02:21:24,259 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-07 02:21:24,978 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-07 02:22:31,428 - speechbrain.utils.train_logger - INFO - steps: 135500, lr: 3.44e-04, avg_loss: 3.24, run_time: 2.78e+02
2023-12-07 02:25:10,575 - speechbrain.utils.train_logger - INFO - steps: 136000, lr: 3.43e-04, avg_loss: 3.25, run_time: 1.59e+02
2023-12-07 02:27:50,130 - speechbrain.utils.train_logger - INFO - steps: 136500, lr: 3.42e-04, avg_loss: 3.26, run_time: 1.60e+02
2023-12-07 02:30:29,436 - speechbrain.utils.train_logger - INFO - steps: 137000, lr: 3.42e-04, avg_loss: 3.25, run_time: 1.59e+02
2023-12-07 02:33:09,025 - speechbrain.utils.train_logger - INFO - steps: 137500, lr: 3.41e-04, avg_loss: 3.26, run_time: 1.60e+02
2023-12-07 02:35:48,572 - speechbrain.utils.train_logger - INFO - steps: 138000, lr: 3.41e-04, avg_loss: 3.25, run_time: 1.60e+02
2023-12-07 02:38:28,077 - speechbrain.utils.train_logger - INFO - steps: 138500, lr: 3.40e-04, avg_loss: 3.25, run_time: 1.60e+02
2023-12-07 02:41:07,516 - speechbrain.utils.train_logger - INFO - steps: 139000, lr: 3.39e-04, avg_loss: 3.25, run_time: 1.59e+02
2023-12-07 02:43:47,114 - speechbrain.utils.train_logger - INFO - steps: 139500, lr: 3.39e-04, avg_loss: 3.25, run_time: 1.60e+02
2023-12-07 02:46:26,369 - speechbrain.utils.train_logger - INFO - steps: 140000, lr: 3.38e-04, avg_loss: 3.25, run_time: 1.59e+02
2023-12-07 02:47:47,016 - speechbrain.utils.train_logger - INFO - epoch: 29, steps: 140128, lr: 3.38e-04 - train loss: 3.25 - valid loss: 3.63, valid accuracy: 2.21e-01
2023-12-07 02:49:44,868 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/bestrq/5000/save/CKPT+2023-12-07+02-47-47+00
2023-12-07 02:49:45,214 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/bestrq/5000/save/CKPT+2023-12-06+22-02-54+00
2023-12-07 02:49:45,215 - speechbrain.utils.epoch_loop - INFO - Going into epoch 30
2023-12-07 02:49:45,216 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-07 02:49:46,054 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-07 02:51:45,488 - speechbrain.utils.train_logger - INFO - steps: 140500, lr: 3.37e-04, avg_loss: 3.25, run_time: 3.19e+02
2023-12-07 02:54:24,635 - speechbrain.utils.train_logger - INFO - steps: 141000, lr: 3.37e-04, avg_loss: 3.25, run_time: 1.59e+02
2023-12-07 02:57:04,349 - speechbrain.utils.train_logger - INFO - steps: 141500, lr: 3.36e-04, avg_loss: 3.25, run_time: 1.60e+02
2023-12-07 02:59:44,529 - speechbrain.utils.train_logger - INFO - steps: 142000, lr: 3.36e-04, avg_loss: 3.25, run_time: 1.60e+02
2023-12-07 03:02:24,368 - speechbrain.utils.train_logger - INFO - steps: 142500, lr: 3.35e-04, avg_loss: 3.25, run_time: 1.60e+02
2023-12-07 03:05:04,282 - speechbrain.utils.train_logger - INFO - steps: 143000, lr: 3.34e-04, avg_loss: 3.25, run_time: 1.60e+02
2023-12-07 03:07:44,504 - speechbrain.utils.train_logger - INFO - steps: 143500, lr: 3.34e-04, avg_loss: 3.26, run_time: 1.60e+02
2023-12-07 03:10:24,584 - speechbrain.utils.train_logger - INFO - steps: 144000, lr: 3.33e-04, avg_loss: 3.25, run_time: 1.60e+02
2023-12-07 03:13:04,956 - speechbrain.utils.train_logger - INFO - steps: 144500, lr: 3.33e-04, avg_loss: 3.25, run_time: 1.60e+02
2023-12-07 03:16:11,863 - speechbrain.utils.train_logger - INFO - epoch: 30, steps: 144960, lr: 3.32e-04 - train loss: 3.26 - valid loss: 3.64, valid accuracy: 2.18e-01
2023-12-07 03:17:00,479 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/bestrq/5000/save/CKPT+2023-12-07+03-16-11+00
2023-12-07 03:17:00,816 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/bestrq/5000/save/CKPT+2023-12-06+22-32-42+00
2023-12-07 03:17:00,816 - speechbrain.utils.epoch_loop - INFO - Going into epoch 31
2023-12-07 03:17:00,818 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-07 03:17:01,673 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-07 03:17:16,486 - speechbrain.utils.train_logger - INFO - steps: 145000, lr: 3.32e-04, avg_loss: 3.24, run_time: 2.52e+02
2023-12-07 03:19:55,991 - speechbrain.utils.train_logger - INFO - steps: 145500, lr: 3.32e-04, avg_loss: 3.24, run_time: 1.59e+02
2023-12-07 03:22:35,347 - speechbrain.utils.train_logger - INFO - steps: 146000, lr: 3.31e-04, avg_loss: 3.24, run_time: 1.59e+02
2023-12-07 03:25:15,119 - speechbrain.utils.train_logger - INFO - steps: 146500, lr: 3.30e-04, avg_loss: 3.24, run_time: 1.60e+02
2023-12-07 03:27:55,044 - speechbrain.utils.train_logger - INFO - steps: 147000, lr: 3.30e-04, avg_loss: 3.25, run_time: 1.60e+02
2023-12-07 03:30:35,116 - speechbrain.utils.train_logger - INFO - steps: 147500, lr: 3.29e-04, avg_loss: 3.24, run_time: 1.60e+02
2023-12-07 03:33:15,185 - speechbrain.utils.train_logger - INFO - steps: 148000, lr: 3.29e-04, avg_loss: 3.25, run_time: 1.60e+02
2023-12-07 03:35:55,516 - speechbrain.utils.train_logger - INFO - steps: 148500, lr: 3.28e-04, avg_loss: 3.25, run_time: 1.60e+02
2023-12-07 03:38:35,246 - speechbrain.utils.train_logger - INFO - steps: 149000, lr: 3.28e-04, avg_loss: 3.25, run_time: 1.60e+02
2023-12-07 03:41:14,734 - speechbrain.utils.train_logger - INFO - steps: 149500, lr: 3.27e-04, avg_loss: 3.25, run_time: 1.60e+02
2023-12-07 03:43:27,712 - speechbrain.utils.train_logger - INFO - epoch: 31, steps: 149792, lr: 3.27e-04 - train loss: 3.24 - valid loss: 3.63, valid accuracy: 2.22e-01
2023-12-07 03:43:50,475 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/bestrq/5000/save/CKPT+2023-12-07+03-43-27+00
2023-12-07 03:43:50,769 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/bestrq/5000/save/CKPT+2023-12-06+22-59-07+00
2023-12-07 03:43:50,770 - speechbrain.utils.epoch_loop - INFO - Going into epoch 32
2023-12-07 03:43:50,772 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-07 03:43:51,740 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-07 03:44:59,764 - speechbrain.utils.train_logger - INFO - steps: 150000, lr: 3.27e-04, avg_loss: 3.23, run_time: 2.25e+02
2023-12-07 03:47:39,177 - speechbrain.utils.train_logger - INFO - steps: 150500, lr: 3.26e-04, avg_loss: 3.24, run_time: 1.59e+02
2023-12-07 03:50:18,466 - speechbrain.utils.train_logger - INFO - steps: 151000, lr: 3.26e-04, avg_loss: 3.24, run_time: 1.59e+02
2023-12-07 03:52:58,097 - speechbrain.utils.train_logger - INFO - steps: 151500, lr: 3.25e-04, avg_loss: 3.24, run_time: 1.60e+02
2023-12-07 03:55:37,985 - speechbrain.utils.train_logger - INFO - steps: 152000, lr: 3.24e-04, avg_loss: 3.24, run_time: 1.60e+02
2023-12-07 03:58:17,449 - speechbrain.utils.train_logger - INFO - steps: 152500, lr: 3.24e-04, avg_loss: 3.24, run_time: 1.59e+02
2023-12-07 04:00:57,246 - speechbrain.utils.train_logger - INFO - steps: 153000, lr: 3.23e-04, avg_loss: 3.24, run_time: 1.60e+02
2023-12-07 04:03:37,185 - speechbrain.utils.train_logger - INFO - steps: 153500, lr: 3.23e-04, avg_loss: 3.24, run_time: 1.60e+02
2023-12-07 04:06:16,757 - speechbrain.utils.train_logger - INFO - steps: 154000, lr: 3.22e-04, avg_loss: 3.24, run_time: 1.60e+02
2023-12-07 04:08:56,679 - speechbrain.utils.train_logger - INFO - steps: 154500, lr: 3.22e-04, avg_loss: 3.24, run_time: 1.60e+02
2023-12-07 04:10:15,721 - speechbrain.utils.train_logger - INFO - epoch: 32, steps: 154624, lr: 3.22e-04 - train loss: 3.24 - valid loss: 3.61, valid accuracy: 2.19e-01
2023-12-07 04:11:23,958 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/bestrq/5000/save/CKPT+2023-12-07+04-10-15+00
2023-12-07 04:11:24,368 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/bestrq/5000/save/CKPT+2023-12-06+23-27-21+00
2023-12-07 04:11:24,368 - speechbrain.utils.epoch_loop - INFO - Going into epoch 33
2023-12-07 04:11:24,370 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-07 04:11:25,184 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-07 04:13:26,770 - speechbrain.utils.train_logger - INFO - steps: 155000, lr: 3.21e-04, avg_loss: 3.24, run_time: 2.70e+02
2023-12-07 04:16:06,234 - speechbrain.utils.train_logger - INFO - steps: 155500, lr: 3.21e-04, avg_loss: 3.23, run_time: 1.59e+02
2023-12-07 04:18:45,881 - speechbrain.utils.train_logger - INFO - steps: 156000, lr: 3.20e-04, avg_loss: 3.24, run_time: 1.60e+02
2023-12-07 04:21:25,895 - speechbrain.utils.train_logger - INFO - steps: 156500, lr: 3.20e-04, avg_loss: 3.24, run_time: 1.60e+02
2023-12-07 04:24:05,648 - speechbrain.utils.train_logger - INFO - steps: 157000, lr: 3.19e-04, avg_loss: 3.24, run_time: 1.60e+02
2023-12-07 04:26:45,631 - speechbrain.utils.train_logger - INFO - steps: 157500, lr: 3.19e-04, avg_loss: 3.24, run_time: 1.60e+02
2023-12-07 04:29:25,253 - speechbrain.utils.train_logger - INFO - steps: 158000, lr: 3.18e-04, avg_loss: 3.24, run_time: 1.60e+02
2023-12-07 04:32:05,233 - speechbrain.utils.train_logger - INFO - steps: 158500, lr: 3.18e-04, avg_loss: 3.24, run_time: 1.60e+02
2023-12-07 04:34:44,905 - speechbrain.utils.train_logger - INFO - steps: 159000, lr: 3.17e-04, avg_loss: 3.24, run_time: 1.60e+02
2023-12-07 04:37:50,045 - speechbrain.utils.train_logger - INFO - epoch: 33, steps: 159456, lr: 3.17e-04 - train loss: 3.24 - valid loss: 3.62, valid accuracy: 2.18e-01
2023-12-07 04:38:51,794 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/bestrq/5000/save/CKPT+2023-12-07+04-37-50+00
2023-12-07 04:38:52,111 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/bestrq/5000/save/CKPT+2023-12-06+23-57-19+00
2023-12-07 04:38:52,112 - speechbrain.utils.epoch_loop - INFO - Going into epoch 34
2023-12-07 04:38:52,113 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-07 04:38:52,896 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-07 04:39:08,224 - speechbrain.utils.train_logger - INFO - steps: 159500, lr: 3.17e-04, avg_loss: 3.26, run_time: 2.63e+02
2023-12-07 04:41:47,605 - speechbrain.utils.train_logger - INFO - steps: 160000, lr: 3.16e-04, avg_loss: 3.24, run_time: 1.59e+02
2023-12-07 04:44:27,368 - speechbrain.utils.train_logger - INFO - steps: 160500, lr: 3.16e-04, avg_loss: 3.24, run_time: 1.60e+02
2023-12-07 04:47:06,834 - speechbrain.utils.train_logger - INFO - steps: 161000, lr: 3.15e-04, avg_loss: 3.24, run_time: 1.59e+02
2023-12-07 04:49:46,347 - speechbrain.utils.train_logger - INFO - steps: 161500, lr: 3.15e-04, avg_loss: 3.24, run_time: 1.60e+02
2023-12-07 04:52:26,060 - speechbrain.utils.train_logger - INFO - steps: 162000, lr: 3.14e-04, avg_loss: 3.23, run_time: 1.60e+02
2023-12-07 04:55:05,624 - speechbrain.utils.train_logger - INFO - steps: 162500, lr: 3.14e-04, avg_loss: 3.23, run_time: 1.60e+02
2023-12-07 04:57:45,449 - speechbrain.utils.train_logger - INFO - steps: 163000, lr: 3.13e-04, avg_loss: 3.23, run_time: 1.60e+02
2023-12-07 05:00:25,263 - speechbrain.utils.train_logger - INFO - steps: 163500, lr: 3.13e-04, avg_loss: 3.23, run_time: 1.60e+02
2023-12-07 05:03:04,686 - speechbrain.utils.train_logger - INFO - steps: 164000, lr: 3.12e-04, avg_loss: 3.24, run_time: 1.59e+02
2023-12-07 05:05:16,279 - speechbrain.utils.train_logger - INFO - epoch: 34, steps: 164288, lr: 3.12e-04 - train loss: 3.23 - valid loss: 3.62, valid accuracy: 2.24e-01
2023-12-07 05:06:05,331 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/bestrq/5000/save/CKPT+2023-12-07+05-05-16+00
2023-12-07 05:06:05,636 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/bestrq/5000/save/CKPT+2023-12-07+00-24-44+00
2023-12-07 05:06:05,637 - speechbrain.utils.epoch_loop - INFO - Going into epoch 35
2023-12-07 05:06:05,638 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-07 05:06:06,415 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-07 05:07:15,196 - speechbrain.utils.train_logger - INFO - steps: 164500, lr: 3.12e-04, avg_loss: 3.23, run_time: 2.51e+02
2023-12-07 05:09:54,917 - speechbrain.utils.train_logger - INFO - steps: 165000, lr: 3.11e-04, avg_loss: 3.24, run_time: 1.60e+02
2023-12-07 05:12:34,805 - speechbrain.utils.train_logger - INFO - steps: 165500, lr: 3.11e-04, avg_loss: 3.23, run_time: 1.60e+02
2023-12-07 05:15:14,902 - speechbrain.utils.train_logger - INFO - steps: 166000, lr: 3.10e-04, avg_loss: 3.24, run_time: 1.60e+02
2023-12-07 05:17:55,013 - speechbrain.utils.train_logger - INFO - steps: 166500, lr: 3.10e-04, avg_loss: 3.24, run_time: 1.60e+02
2023-12-07 05:20:35,001 - speechbrain.utils.train_logger - INFO - steps: 167000, lr: 3.10e-04, avg_loss: 3.23, run_time: 1.60e+02
2023-12-07 05:23:14,960 - speechbrain.utils.train_logger - INFO - steps: 167500, lr: 3.09e-04, avg_loss: 3.24, run_time: 1.60e+02
2023-12-07 05:25:54,816 - speechbrain.utils.train_logger - INFO - steps: 168000, lr: 3.09e-04, avg_loss: 3.24, run_time: 1.60e+02
2023-12-07 05:28:34,532 - speechbrain.utils.train_logger - INFO - steps: 168500, lr: 3.08e-04, avg_loss: 3.24, run_time: 1.60e+02
2023-12-07 05:31:14,293 - speechbrain.utils.train_logger - INFO - steps: 169000, lr: 3.08e-04, avg_loss: 3.23, run_time: 1.60e+02
2023-12-07 05:32:32,205 - speechbrain.utils.train_logger - INFO - epoch: 35, steps: 169120, lr: 3.08e-04 - train loss: 3.23 - valid loss: 3.59, valid accuracy: 2.24e-01
2023-12-07 05:32:54,440 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/bestrq/5000/save/CKPT+2023-12-07+05-32-32+00
2023-12-07 05:32:54,752 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/bestrq/5000/save/CKPT+2023-12-07+00-52-14+00
2023-12-07 05:32:54,752 - speechbrain.utils.epoch_loop - INFO - Going into epoch 36
2023-12-07 05:32:54,754 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-07 05:32:55,644 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-07 05:34:58,254 - speechbrain.utils.train_logger - INFO - steps: 169500, lr: 3.07e-04, avg_loss: 3.25, run_time: 2.24e+02
2023-12-07 05:37:37,896 - speechbrain.utils.train_logger - INFO - steps: 170000, lr: 3.07e-04, avg_loss: 3.24, run_time: 1.60e+02
2023-12-07 05:40:17,816 - speechbrain.utils.train_logger - INFO - steps: 170500, lr: 3.06e-04, avg_loss: 3.24, run_time: 1.60e+02
2023-12-07 05:42:57,773 - speechbrain.utils.train_logger - INFO - steps: 171000, lr: 3.06e-04, avg_loss: 3.24, run_time: 1.60e+02
2023-12-07 05:45:37,427 - speechbrain.utils.train_logger - INFO - steps: 171500, lr: 3.05e-04, avg_loss: 3.23, run_time: 1.60e+02
2023-12-07 05:48:17,283 - speechbrain.utils.train_logger - INFO - steps: 172000, lr: 3.05e-04, avg_loss: 3.23, run_time: 1.60e+02
2023-12-07 05:50:56,947 - speechbrain.utils.train_logger - INFO - steps: 172500, lr: 3.05e-04, avg_loss: 3.23, run_time: 1.60e+02
2023-12-07 05:53:36,463 - speechbrain.utils.train_logger - INFO - steps: 173000, lr: 3.04e-04, avg_loss: 3.23, run_time: 1.60e+02
2023-12-07 05:56:16,347 - speechbrain.utils.train_logger - INFO - steps: 173500, lr: 3.04e-04, avg_loss: 3.23, run_time: 1.60e+02
2023-12-07 05:59:20,505 - speechbrain.utils.train_logger - INFO - epoch: 36, steps: 173952, lr: 3.03e-04 - train loss: 3.23 - valid loss: 3.57, valid accuracy: 2.27e-01
2023-12-07 06:00:26,268 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/bestrq/5000/save/CKPT+2023-12-07+05-59-20+00
2023-12-07 06:00:26,625 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/bestrq/5000/save/CKPT+2023-12-07+01-22-37+00
2023-12-07 06:00:26,626 - speechbrain.utils.epoch_loop - INFO - Going into epoch 37
2023-12-07 06:00:26,627 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-07 06:00:27,524 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-07 06:00:44,100 - speechbrain.utils.train_logger - INFO - steps: 174000, lr: 3.03e-04, avg_loss: 3.24, run_time: 2.68e+02
2023-12-07 06:03:23,303 - speechbrain.utils.train_logger - INFO - steps: 174500, lr: 3.03e-04, avg_loss: 3.22, run_time: 1.59e+02
2023-12-07 06:06:02,769 - speechbrain.utils.train_logger - INFO - steps: 175000, lr: 3.02e-04, avg_loss: 3.22, run_time: 1.59e+02
2023-12-07 06:08:42,006 - speechbrain.utils.train_logger - INFO - steps: 175500, lr: 3.02e-04, avg_loss: 3.22, run_time: 1.59e+02
2023-12-07 06:11:22,131 - speechbrain.utils.train_logger - INFO - steps: 176000, lr: 3.02e-04, avg_loss: 3.23, run_time: 1.60e+02
2023-12-07 06:14:01,989 - speechbrain.utils.train_logger - INFO - steps: 176500, lr: 3.01e-04, avg_loss: 3.22, run_time: 1.60e+02
2023-12-07 06:16:42,049 - speechbrain.utils.train_logger - INFO - steps: 177000, lr: 3.01e-04, avg_loss: 3.22, run_time: 1.60e+02
2023-12-07 06:19:21,890 - speechbrain.utils.train_logger - INFO - steps: 177500, lr: 3.00e-04, avg_loss: 3.22, run_time: 1.60e+02
2023-12-07 06:22:01,842 - speechbrain.utils.train_logger - INFO - steps: 178000, lr: 3.00e-04, avg_loss: 3.22, run_time: 1.60e+02
2023-12-07 06:24:41,525 - speechbrain.utils.train_logger - INFO - steps: 178500, lr: 2.99e-04, avg_loss: 3.23, run_time: 1.60e+02
2023-12-07 06:26:52,241 - speechbrain.utils.train_logger - INFO - epoch: 37, steps: 178784, lr: 2.99e-04 - train loss: 3.23 - valid loss: 3.62, valid accuracy: 2.21e-01
2023-12-07 06:28:14,479 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/bestrq/5000/save/CKPT+2023-12-07+06-26-52+00
2023-12-07 06:28:14,817 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/bestrq/5000/save/CKPT+2023-12-07+01-50-48+00
2023-12-07 06:28:14,818 - speechbrain.utils.epoch_loop - INFO - Going into epoch 38
2023-12-07 06:28:14,820 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-07 06:28:15,584 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-07 06:29:26,420 - speechbrain.utils.train_logger - INFO - steps: 179000, lr: 2.99e-04, avg_loss: 3.23, run_time: 2.85e+02
2023-12-07 06:32:05,639 - speechbrain.utils.train_logger - INFO - steps: 179500, lr: 2.99e-04, avg_loss: 3.21, run_time: 1.59e+02
2023-12-07 06:34:45,136 - speechbrain.utils.train_logger - INFO - steps: 180000, lr: 2.98e-04, avg_loss: 3.22, run_time: 1.60e+02
2023-12-07 06:37:24,677 - speechbrain.utils.train_logger - INFO - steps: 180500, lr: 2.98e-04, avg_loss: 3.22, run_time: 1.60e+02
2023-12-07 06:40:04,490 - speechbrain.utils.train_logger - INFO - steps: 181000, lr: 2.97e-04, avg_loss: 3.22, run_time: 1.60e+02
2023-12-07 06:42:43,879 - speechbrain.utils.train_logger - INFO - steps: 181500, lr: 2.97e-04, avg_loss: 3.22, run_time: 1.59e+02
2023-12-07 06:45:23,690 - speechbrain.utils.train_logger - INFO - steps: 182000, lr: 2.96e-04, avg_loss: 3.22, run_time: 1.60e+02
2023-12-07 06:48:03,323 - speechbrain.utils.train_logger - INFO - steps: 182500, lr: 2.96e-04, avg_loss: 3.22, run_time: 1.60e+02
2023-12-07 06:50:43,297 - speechbrain.utils.train_logger - INFO - steps: 183000, lr: 2.96e-04, avg_loss: 3.22, run_time: 1.60e+02
2023-12-07 06:53:23,737 - speechbrain.utils.train_logger - INFO - steps: 183500, lr: 2.95e-04, avg_loss: 3.22, run_time: 1.61e+02
2023-12-07 06:54:40,945 - speechbrain.utils.train_logger - INFO - epoch: 38, steps: 183616, lr: 2.95e-04 - train loss: 3.22 - valid loss: 3.61, valid accuracy: 2.23e-01
2023-12-07 06:55:11,271 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/bestrq/5000/save/CKPT+2023-12-07+06-54-40+00
2023-12-07 06:55:11,628 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/bestrq/5000/save/CKPT+2023-12-07+02-20-07+00
2023-12-07 06:55:11,629 - speechbrain.utils.epoch_loop - INFO - Going into epoch 39
2023-12-07 06:55:11,630 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-07 06:55:12,351 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-07 06:57:16,490 - speechbrain.utils.train_logger - INFO - steps: 184000, lr: 2.95e-04, avg_loss: 3.22, run_time: 2.33e+02
2023-12-07 06:59:55,953 - speechbrain.utils.train_logger - INFO - steps: 184500, lr: 2.94e-04, avg_loss: 3.22, run_time: 1.60e+02
2023-12-07 07:02:34,976 - speechbrain.utils.train_logger - INFO - steps: 185000, lr: 2.94e-04, avg_loss: 3.22, run_time: 1.59e+02
2023-12-07 07:05:14,282 - speechbrain.utils.train_logger - INFO - steps: 185500, lr: 2.94e-04, avg_loss: 3.22, run_time: 1.59e+02
2023-12-07 07:07:53,405 - speechbrain.utils.train_logger - INFO - steps: 186000, lr: 2.93e-04, avg_loss: 3.22, run_time: 1.59e+02
2023-12-07 07:10:32,704 - speechbrain.utils.train_logger - INFO - steps: 186500, lr: 2.93e-04, avg_loss: 3.22, run_time: 1.59e+02
2023-12-07 07:13:12,232 - speechbrain.utils.train_logger - INFO - steps: 187000, lr: 2.93e-04, avg_loss: 3.22, run_time: 1.59e+02
2023-12-07 07:15:51,946 - speechbrain.utils.train_logger - INFO - steps: 187500, lr: 2.92e-04, avg_loss: 3.22, run_time: 1.60e+02
2023-12-07 07:18:31,550 - speechbrain.utils.train_logger - INFO - steps: 188000, lr: 2.92e-04, avg_loss: 3.22, run_time: 1.60e+02
2023-12-07 07:21:33,763 - speechbrain.utils.train_logger - INFO - epoch: 39, steps: 188448, lr: 2.91e-04 - train loss: 3.22 - valid loss: 3.60, valid accuracy: 2.22e-01
2023-12-07 07:22:14,241 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/bestrq/5000/save/CKPT+2023-12-07+07-21-33+00
2023-12-07 07:22:14,580 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/bestrq/5000/save/CKPT+2023-12-07+02-47-47+00
2023-12-07 07:22:14,580 - speechbrain.utils.epoch_loop - INFO - Going into epoch 40
2023-12-07 07:22:14,582 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-07 07:22:15,391 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-07 07:22:33,389 - speechbrain.utils.train_logger - INFO - steps: 188500, lr: 2.91e-04, avg_loss: 3.24, run_time: 2.42e+02
2023-12-07 07:25:13,109 - speechbrain.utils.train_logger - INFO - steps: 189000, lr: 2.91e-04, avg_loss: 3.20, run_time: 1.60e+02
2023-12-07 07:27:53,108 - speechbrain.utils.train_logger - INFO - steps: 189500, lr: 2.91e-04, avg_loss: 3.21, run_time: 1.60e+02
2023-12-07 07:30:33,070 - speechbrain.utils.train_logger - INFO - steps: 190000, lr: 2.90e-04, avg_loss: 3.21, run_time: 1.60e+02
2023-12-07 07:33:12,984 - speechbrain.utils.train_logger - INFO - steps: 190500, lr: 2.90e-04, avg_loss: 3.21, run_time: 1.60e+02
2023-12-07 07:35:53,081 - speechbrain.utils.train_logger - INFO - steps: 191000, lr: 2.89e-04, avg_loss: 3.21, run_time: 1.60e+02
2023-12-07 07:38:33,261 - speechbrain.utils.train_logger - INFO - steps: 191500, lr: 2.89e-04, avg_loss: 3.21, run_time: 1.60e+02
2023-12-07 07:41:13,463 - speechbrain.utils.train_logger - INFO - steps: 192000, lr: 2.89e-04, avg_loss: 3.22, run_time: 1.60e+02
2023-12-07 07:43:53,499 - speechbrain.utils.train_logger - INFO - steps: 192500, lr: 2.88e-04, avg_loss: 3.22, run_time: 1.60e+02
2023-12-07 07:46:33,727 - speechbrain.utils.train_logger - INFO - steps: 193000, lr: 2.88e-04, avg_loss: 3.22, run_time: 1.60e+02
2023-12-07 07:48:43,067 - speechbrain.utils.train_logger - INFO - epoch: 40, steps: 193280, lr: 2.88e-04 - train loss: 3.22 - valid loss: 3.57, valid accuracy: 2.26e-01
2023-12-07 07:50:15,365 - speechbrain.core - ERROR - Exception:
Traceback (most recent call last):
  File "/gpfsdswork/projects/rech/nkp/uaj64gk/bestrqexp/bestrq/train.py", line 381, in <module>
    main()
  File "/gpfsdswork/projects/rech/nkp/uaj64gk/bestrqexp/bestrq/train.py", line 371, in main
    brain.fit(
  File "/gpfsdswork/projects/rech/nkp/uaj64gk/bestrqexp/speechbrain/speechbrain/core.py", line 1367, in fit
    self._fit_valid(valid_set=valid_set, epoch=epoch, enable=enable)
  File "/gpfsdswork/projects/rech/nkp/uaj64gk/bestrqexp/speechbrain/speechbrain/core.py", line 1281, in _fit_valid
    self.on_stage_end(Stage.VALID, avg_valid_loss, epoch)
  File "/gpfsdswork/projects/rech/nkp/uaj64gk/bestrqexp/bestrq/train.py", line 239, in on_stage_end
    self.checkpointer.save_and_keep_only(
  File "/gpfsdswork/projects/rech/nkp/uaj64gk/bestrqexp/speechbrain/speechbrain/utils/checkpoints.py", line 683, in save_and_keep_only
    self.save_checkpoint(
  File "/gpfsdswork/projects/rech/nkp/uaj64gk/bestrqexp/speechbrain/speechbrain/utils/checkpoints.py", line 607, in save_checkpoint
    default_hook(obj, savepath)
  File "/gpfsdswork/projects/rech/nkp/uaj64gk/bestrqexp/speechbrain/speechbrain/utils/distributed.py", line 99, in main_proc_wrapped_func
    result = function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfsdswork/projects/rech/nkp/uaj64gk/bestrqexp/speechbrain/speechbrain/nnet/schedulers.py", line 447, in save
    torch.save(data, path)
  File "/linkhome/rech/genzjn01/uaj64gk/.local/lib/python3.11/site-packages/torch/serialization.py", line 440, in save
    with _open_zipfile_writer(f) as opened_zipfile:
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/linkhome/rech/genzjn01/uaj64gk/.local/lib/python3.11/site-packages/torch/serialization.py", line 315, in _open_zipfile_writer
    return container(name_or_buffer)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/linkhome/rech/genzjn01/uaj64gk/.local/lib/python3.11/site-packages/torch/serialization.py", line 288, in __init__
    super().__init__(torch._C.PyTorchFileWriter(str(name)))
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: File results/bestrq/5000/save/CKPT+2023-12-07+07-48-43+00/noam_scheduler.ckpt cannot be opened.
2023-12-07 09:35:50,022 - speechbrain.core - INFO - Beginning experiment!
2023-12-07 09:35:50,039 - speechbrain.core - INFO - Experiment folder: results/bestrq/5000
2023-12-07 09:35:56,457 - speechbrain.utils.superpowers - DEBUG - appdirs==1.4.4
attrs==23.1.0
black==19.10b0
certifi==2023.11.17
cfgv==3.4.0
charset-normalizer==3.3.2
click==8.0.4
cmake==3.27.7
distlib==0.3.7
entrypoints==0.3
filelock==3.13.1
flake8==3.7.9
fsspec==2023.10.0
huggingface-hub==0.19.4
HyperPyYAML==1.2.2
hypothesis==6.91.0
identify==2.5.32
idna==3.6
iniconfig==2.0.0
Jinja2==3.1.2
joblib==1.3.2
kenlm==0.2.0
lit==17.0.6
MarkupSafe==2.1.3
mccabe==0.6.1
mpmath==1.3.0
networkx==3.2.1
nodeenv==1.8.0
numpy==1.26.2
nvidia-cublas-cu11==11.10.3.66
nvidia-cublas-cu12==12.1.3.1
nvidia-cuda-cupti-cu11==11.7.101
nvidia-cuda-cupti-cu12==12.1.105
nvidia-cuda-nvrtc-cu11==11.7.99
nvidia-cuda-nvrtc-cu12==12.1.105
nvidia-cuda-runtime-cu11==11.7.99
nvidia-cuda-runtime-cu12==12.1.105
nvidia-cudnn-cu11==8.5.0.96
nvidia-cudnn-cu12==8.9.2.26
nvidia-cufft-cu11==10.9.0.58
nvidia-cufft-cu12==11.0.2.54
nvidia-curand-cu11==10.2.10.91
nvidia-curand-cu12==10.3.2.106
nvidia-cusolver-cu11==11.4.0.1
nvidia-cusolver-cu12==11.4.5.107
nvidia-cusparse-cu11==11.7.4.91
nvidia-cusparse-cu12==12.1.0.106
nvidia-nccl-cu11==2.14.3
nvidia-nccl-cu12==2.18.1
nvidia-nvjitlink-cu12==12.3.101
nvidia-nvtx-cu11==11.7.91
nvidia-nvtx-cu12==12.1.105
packaging==23.2
pandas==2.1.3
pathspec==0.11.2
platformdirs==4.0.0
pluggy==1.3.0
pre-commit==3.5.0
pycodestyle==2.5.0
pyctcdecode==0.5.0
pyflakes==2.1.1
pygtrie==2.5.0
pytest==7.4.0
python-dateutil==2.8.2
pytz==2023.3.post1
PyYAML==6.0.1
regex==2023.10.3
requests==2.31.0
ruamel.yaml==0.18.5
ruamel.yaml.clib==0.2.8
safetensors==0.4.1
scipy==1.11.4
sentencepiece==0.1.99
six==1.16.0
sortedcontainers==2.4.0
-e /gpfsdswork/projects/rech/nkp/uaj64gk/bestrqexp/speechbrain
sympy==1.12
tokenizers==0.15.0
toml==0.10.2
torch==2.0.1
torchaudio==2.0.2
tqdm==4.66.1
transformers==4.35.2
triton==2.0.0
typed-ast==1.5.5
typing_extensions==4.8.0
tzdata==2023.3
urllib3==2.1.0
virtualenv==20.24.7
yamllint==1.23.0

ERROR: Error [Errno 2] No such file or directory: 'git' while executing command git config --get-regexp 'remote\..*\.url'
WARNING: cannot determine version of editable source in /gpfsdswork/projects/rech/nkp/uaj64gk/bestrqexp/speechbrain (git command not found in path)

2023-12-07 09:36:01,204 - speechbrain.dataio.sampler - INFO - Batch quantisation in latent space
2023-12-07 09:36:01,205 - speechbrain.dataio.sampler - DEBUG - Latent bucket boundary - buckets: ['1.62', '2.19', '2.66', '3.09', '3.49', '3.88', '4.27', '4.65', '5.02', '5.41', '5.79', '6.18', '6.58', '6.99', '7.40', '7.83', '8.27', '8.72', '9.19', '9.68', '10.18', '10.70', '11.25', '11.82', '12.41', '13.04', '13.70', '14.39', '15.12', '15.90', '16.73', '17.61', '18.55', '19.57', '20.67', '21.86', '23.16', '24.59', '26.17', '27.94', '29.93', '32.21', '34.84', '37.94', '41.68', '46.34', '52.40', '60.82', '73.93', '100.00'] - length multipliers: ['1.35', '1.22', '1.16', '1.13', '1.11', '1.10', '1.09', '1.08', '1.08', '1.07', '1.07', '1.06', '1.06', '1.06', '1.06', '1.06', '1.05', '1.05', '1.05', '1.05', '1.05', '1.05', '1.05', '1.05', '1.05', '1.05', '1.05', '1.05', '1.05', '1.05', '1.05', '1.05', '1.05', '1.06', '1.06', '1.06', '1.06', '1.06', '1.07', '1.07', '1.08', '1.08', '1.09', '1.10', '1.11', '1.13', '1.16', '1.22', '1.35']
2023-12-07 09:36:01,205 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-07 09:36:01,893 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 0 with boundary 0.0-1.6 and batch_size 61: Num Examples 0.0, Num Full Batches 0.000, Pad Factor 0.000.
2023-12-07 09:36:01,893 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 1 with boundary 1.6-2.2 and batch_size 45: Num Examples 906.0, Num Full Batches 19.000, Pad Factor 8.810.
2023-12-07 09:36:01,893 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 2 with boundary 2.2-2.7 and batch_size 37: Num Examples 3456.0, Num Full Batches 84.000, Pad Factor 19.315.
2023-12-07 09:36:01,893 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 3 with boundary 2.7-3.1 and batch_size 32: Num Examples 3364.0, Num Full Batches 96.000, Pad Factor 14.604.
2023-12-07 09:36:01,893 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 4 with boundary 3.1-3.5 and batch_size 28: Num Examples 3292.0, Num Full Batches 108.000, Pad Factor 12.168.
2023-12-07 09:36:01,893 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 5 with boundary 3.5-3.9 and batch_size 25: Num Examples 3156.0, Num Full Batches 116.000, Pad Factor 10.443.
2023-12-07 09:36:01,893 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 6 with boundary 3.9-4.3 and batch_size 23: Num Examples 3158.0, Num Full Batches 128.000, Pad Factor 9.328.
2023-12-07 09:36:01,893 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 7 with boundary 4.3-4.6 and batch_size 21: Num Examples 3035.0, Num Full Batches 135.000, Pad Factor 8.411.
2023-12-07 09:36:01,893 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 8 with boundary 4.6-5.0 and batch_size 19: Num Examples 3010.0, Num Full Batches 145.000, Pad Factor 7.650.
2023-12-07 09:36:01,894 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 9 with boundary 5.0-5.4 and batch_size 18: Num Examples 3119.0, Num Full Batches 162.000, Pad Factor 7.284.
2023-12-07 09:36:01,894 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 10 with boundary 5.4-5.8 and batch_size 17: Num Examples 3126.0, Num Full Batches 175.000, Pad Factor 6.786.
2023-12-07 09:36:01,894 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 11 with boundary 5.8-6.2 and batch_size 16: Num Examples 3051.0, Num Full Batches 182.000, Pad Factor 6.432.
2023-12-07 09:36:01,894 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 12 with boundary 6.2-6.6 and batch_size 15: Num Examples 3091.0, Num Full Batches 197.000, Pad Factor 6.192.
2023-12-07 09:36:01,894 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 13 with boundary 6.6-7.0 and batch_size 14: Num Examples 3048.0, Num Full Batches 206.000, Pad Factor 5.893.
2023-12-07 09:36:01,894 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 14 with boundary 7.0-7.4 and batch_size 13: Num Examples 3288.0, Num Full Batches 236.000, Pad Factor 5.700.
2023-12-07 09:36:01,894 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 15 with boundary 7.4-7.8 and batch_size 12: Num Examples 3300.0, Num Full Batches 251.000, Pad Factor 5.514.
2023-12-07 09:36:01,894 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 16 with boundary 7.8-8.3 and batch_size 12: Num Examples 3438.0, Num Full Batches 276.000, Pad Factor 5.406.
2023-12-07 09:36:01,894 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 17 with boundary 8.3-8.7 and batch_size 11: Num Examples 3599.0, Num Full Batches 305.000, Pad Factor 5.299.
2023-12-07 09:36:01,894 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 18 with boundary 8.7-9.2 and batch_size 10: Num Examples 3901.0, Num Full Batches 349.000, Pad Factor 5.189.
2023-12-07 09:36:01,894 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 19 with boundary 9.2-9.7 and batch_size 10: Num Examples 4113.0, Num Full Batches 388.000, Pad Factor 5.087.
2023-12-07 09:36:01,894 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 20 with boundary 9.7-10.2 and batch_size 9: Num Examples 4692.0, Num Full Batches 465.000, Pad Factor 4.987.
2023-12-07 09:36:01,894 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 21 with boundary 10.2-10.7 and batch_size 9: Num Examples 5324.0, Num Full Batches 556.000, Pad Factor 4.978.
2023-12-07 09:36:01,894 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 22 with boundary 10.7-11.2 and batch_size 8: Num Examples 6379.0, Num Full Batches 700.000, Pad Factor 4.917.
2023-12-07 09:36:01,894 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 23 with boundary 11.2-11.8 and batch_size 8: Num Examples 8176.0, Num Full Batches 943.000, Pad Factor 4.894.
2023-12-07 09:36:01,894 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 24 with boundary 11.8-12.4 and batch_size 8: Num Examples 11428.0, Num Full Batches 1386.000, Pad Factor 4.865.
2023-12-07 09:36:01,894 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 25 with boundary 12.4-13.0 and batch_size 7: Num Examples 16056.0, Num Full Batches 2045.000, Pad Factor 4.866.
2023-12-07 09:36:01,894 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 26 with boundary 13.0-13.7 and batch_size 7: Num Examples 23408.0, Num Full Batches 3133.000, Pad Factor 4.893.
2023-12-07 09:36:01,894 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 27 with boundary 13.7-14.4 and batch_size 6: Num Examples 33287.0, Num Full Batches 4679.000, Pad Factor 4.874.
2023-12-07 09:36:01,894 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 28 with boundary 14.4-15.1 and batch_size 6: Num Examples 43150.0, Num Full Batches 6370.000, Pad Factor 4.946.
2023-12-07 09:36:01,894 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 29 with boundary 15.1-15.9 and batch_size 6: Num Examples 46934.0, Num Full Batches 7275.000, Pad Factor 4.968.
2023-12-07 09:36:01,894 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 30 with boundary 15.9-16.7 and batch_size 5: Num Examples 18846.0, Num Full Batches 3051.000, Pad Factor 5.095.
2023-12-07 09:36:01,894 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 31 with boundary 16.7-17.6 and batch_size 5: Num Examples 2283.0, Num Full Batches 385.000, Pad Factor 5.001.
2023-12-07 09:36:01,894 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 32 with boundary 17.6-18.6 and batch_size 5: Num Examples 24.0, Num Full Batches 4.000, Pad Factor 4.747.
2023-12-07 09:36:01,894 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 33 with boundary 18.6-19.6 and batch_size 5: Num Examples 23.0, Num Full Batches 4.000, Pad Factor 4.870.
2023-12-07 09:36:01,894 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 34 with boundary 19.6-20.7 and batch_size 4: Num Examples 26.0, Num Full Batches 5.000, Pad Factor 5.180.
2023-12-07 09:36:01,894 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 35 with boundary 20.7-21.9 and batch_size 4: Num Examples 15.0, Num Full Batches 3.000, Pad Factor 4.735.
2023-12-07 09:36:01,894 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 36 with boundary 21.9-23.2 and batch_size 4: Num Examples 11.0, Num Full Batches 2.000, Pad Factor 4.155.
2023-12-07 09:36:01,894 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 37 with boundary 23.2-24.6 and batch_size 4: Num Examples 7.0, Num Full Batches 1.000, Pad Factor 4.739.
2023-12-07 09:36:01,894 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 38 with boundary 24.6-26.2 and batch_size 3: Num Examples 6.0, Num Full Batches 1.000, Pad Factor 4.438.
2023-12-07 09:36:01,894 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 39 with boundary 26.2-27.9 and batch_size 3: Num Examples 4.0, Num Full Batches 1.000, Pad Factor 6.346.
2023-12-07 09:36:01,894 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 40 with boundary 27.9-29.9 and batch_size 3: Num Examples 1.0, Num Full Batches 0.000, Pad Factor 0.000.
2023-12-07 09:36:01,894 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 41 with boundary 29.9-32.2 and batch_size 3: Num Examples 0.0, Num Full Batches 0.000, Pad Factor 0.000.
2023-12-07 09:36:01,894 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 42 with boundary 32.2-34.8 and batch_size 2: Num Examples 0.0, Num Full Batches 0.000, Pad Factor 0.000.
2023-12-07 09:36:01,894 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 43 with boundary 34.8-37.9 and batch_size 2: Num Examples 0.0, Num Full Batches 0.000, Pad Factor 0.000.
2023-12-07 09:36:01,894 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 44 with boundary 37.9-41.7 and batch_size 2: Num Examples 0.0, Num Full Batches 0.000, Pad Factor 0.000.
2023-12-07 09:36:01,894 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 45 with boundary 41.7-46.3 and batch_size 2: Num Examples 0.0, Num Full Batches 0.000, Pad Factor 0.000.
2023-12-07 09:36:01,894 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 46 with boundary 46.3-52.4 and batch_size 1: Num Examples 0.0, Num Full Batches 0.000, Pad Factor 0.000.
2023-12-07 09:36:01,894 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 47 with boundary 52.4-60.8 and batch_size 1: Num Examples 0.0, Num Full Batches 0.000, Pad Factor 0.000.
2023-12-07 09:36:01,894 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 48 with boundary 60.8-73.9 and batch_size 1: Num Examples 0.0, Num Full Batches 0.000, Pad Factor 0.000.
2023-12-07 09:36:01,894 - speechbrain.dataio.sampler - DEBUG - DynamicBatchSampler: Bucket 49 with boundary 73.9-100.0 and batch_size 1: Num Examples 0.0, Num Full Batches 0.000, Pad Factor 0.000.
2023-12-07 09:36:01,896 - speechbrain.core - INFO - Info: test_only arg overridden by command line input to: False
2023-12-07 09:36:01,896 - speechbrain.core - INFO - Info: debug arg overridden by command line input to: False
2023-12-07 09:36:01,896 - speechbrain.core - INFO - Info: debug_batches arg overridden by command line input to: 2
2023-12-07 09:36:01,896 - speechbrain.core - INFO - Info: debug_epochs arg overridden by command line input to: 2
2023-12-07 09:36:01,896 - speechbrain.core - INFO - Info: debug_persistently arg overridden by command line input to: False
2023-12-07 09:36:01,896 - speechbrain.core - INFO - Info: device arg overridden by command line input to: cuda:0
2023-12-07 09:36:01,896 - speechbrain.core - INFO - Info: data_parallel_backend arg overridden by command line input to: False
2023-12-07 09:36:01,896 - speechbrain.core - INFO - Info: distributed_backend arg overridden by command line input to: nccl
2023-12-07 09:36:01,896 - speechbrain.core - INFO - Info: find_unused_parameters arg overridden by command line input to: True
2023-12-07 09:36:01,896 - speechbrain.core - INFO - Info: jit arg overridden by command line input to: False
2023-12-07 09:36:01,896 - speechbrain.core - INFO - Info: compile arg overridden by command line input to: False
2023-12-07 09:36:01,896 - speechbrain.core - INFO - Info: auto_mix_prec arg from hparam file is used
2023-12-07 09:36:01,896 - speechbrain.core - INFO - Info: bfloat16_mix_prec arg from hparam file is used
2023-12-07 09:36:01,896 - speechbrain.core - INFO - Info: max_grad_norm arg from hparam file is used
2023-12-07 09:36:01,896 - speechbrain.core - INFO - Info: optimizer_step_limit arg from hparam file is used
2023-12-07 09:36:01,897 - speechbrain.core - INFO - Info: tqdm_colored_bar arg overridden by command line input to: False
2023-12-07 09:36:01,897 - speechbrain.core - INFO - Info: remove_vector_weight_decay arg overridden by command line input to: False
2023-12-07 09:36:02,079 - speechbrain.core - INFO - 143.3M trainable parameters in BestRQBrain
2023-12-07 09:36:02,429 - speechbrain.utils.checkpoints - INFO - Loading a checkpoint from results/bestrq/5000/save/CKPT+2023-12-07+07-21-33+00
2023-12-07 09:36:10,282 - speechbrain.utils.epoch_loop - INFO - Going into epoch 40
2023-12-07 09:36:10,284 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-07 09:36:11,103 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-07 09:36:32,584 - speechbrain.utils.train_logger - INFO - steps: 188500, lr: 2.91e-04, avg_loss: 3.22
2023-12-07 09:39:16,580 - speechbrain.utils.train_logger - INFO - steps: 189000, lr: 2.91e-04, avg_loss: 3.21, run_time: 1.64e+02
2023-12-07 09:42:01,590 - speechbrain.utils.train_logger - INFO - steps: 189500, lr: 2.91e-04, avg_loss: 3.21, run_time: 1.65e+02
2023-12-07 09:44:46,769 - speechbrain.utils.train_logger - INFO - steps: 190000, lr: 2.90e-04, avg_loss: 3.21, run_time: 1.65e+02
2023-12-07 09:47:32,083 - speechbrain.utils.train_logger - INFO - steps: 190500, lr: 2.90e-04, avg_loss: 3.21, run_time: 1.65e+02
2023-12-07 09:50:16,810 - speechbrain.utils.train_logger - INFO - steps: 191000, lr: 2.89e-04, avg_loss: 3.21, run_time: 1.65e+02
2023-12-07 09:53:01,708 - speechbrain.utils.train_logger - INFO - steps: 191500, lr: 2.89e-04, avg_loss: 3.21, run_time: 1.65e+02
2023-12-07 09:55:46,587 - speechbrain.utils.train_logger - INFO - steps: 192000, lr: 2.89e-04, avg_loss: 3.21, run_time: 1.65e+02
2023-12-07 09:58:31,593 - speechbrain.utils.train_logger - INFO - steps: 192500, lr: 2.88e-04, avg_loss: 3.21, run_time: 1.65e+02
2023-12-07 10:01:17,078 - speechbrain.utils.train_logger - INFO - steps: 193000, lr: 2.88e-04, avg_loss: 3.21, run_time: 1.65e+02
2023-12-07 10:03:29,065 - speechbrain.utils.train_logger - INFO - epoch: 40, steps: 193280, lr: 2.88e-04 - train loss: 3.21 - valid loss: 3.58, valid accuracy: 2.23e-01
2023-12-07 10:03:30,619 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/bestrq/5000/save/CKPT+2023-12-07+10-03-29+00
2023-12-07 10:03:30,628 - speechbrain.utils.epoch_loop - INFO - Going into epoch 41
2023-12-07 10:03:30,630 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-07 10:03:31,612 - speechbrain.dataio.sampler - INFO - DynamicBatchSampler: Generating dynamic batches
2023-12-07 10:04:45,518 - speechbrain.utils.train_logger - INFO - steps: 193500, lr: 2.88e-04, avg_loss: 3.22, run_time: 2.08e+02
